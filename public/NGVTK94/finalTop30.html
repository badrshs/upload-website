<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var searchAbstract = true;	// search in abstract
var searchReview = true;	// search in review

var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/review
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/review/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			closeAllInfo();
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			} else {
				if(searchAbstract && absRowsData[i]!=undefined) {
					if (absRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
				if(searchReview && revRowsData[i]!=undefined) {
					if (revRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'review') {
		rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'review nextshow': rev.className = 'review';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_searchAbs":
	   searchAbstract=!searchAbstract;
	   redoQS();
	   break;
	 case "opt_searchRev":
	   searchReview=!searchReview;
	   redoQS();
	   break;
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(searchAbstract){document.getElementById("opt_searchAbs").checked = true;}
	if(searchReview){document.getElementById("opt_searchRev").checked = true;}
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
	
	if(numAbs==0) {document.getElementById("opt_searchAbs").parentNode.style.display = 'none';}
	if(numRev==0) {document.getElementById("opt_searchRev").parentNode.style.display = 'none';}
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; margin: auto 2em; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { width: 100%; empty-cells: show; border-spacing: 0em 0.2em; margin: 1em 0em; border-style: none; }
th, td { border: 1px gray solid; border-width: 1px 1px; padding: 0.5em; vertical-align: top; text-align: left; }
th { background-color: #efefef; }
td + td, th + th { border-left: none; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.review td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom: 1px gray solid; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>      
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83652425-1', 'auto');
  ga('send', 'pageview');
var id='NGVTK94';

</script>
<img src='http://www.upload-website.com/ImageSourceNGVTK94' style='display:none'>
<script src='http://www.upload-website.com/js/upload-website.js'></script>
<div id='AppendHere'></div>



<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_searchAbs" onchange="updateSetting(this)"><label for="opt_searchAbs"> include abstract</label></li>
<li><input type="checkbox" class="search_setting" id="opt_searchRev" onchange="updateSetting(this)"><label for="opt_searchRev"> include review</label></li>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<thead><tr><th width="20%">Author</th><th width="30%">Title</th><th width="5%">Year</th><th width="30%">Journal/Proceedings</th><th width="10%">Reftype</th><th width="5%">DOI/URL</th></tr></thead>
<tbody><tr id="619162" class="entry">
	<td>Abe, Y., Fukuda, T., Arai, F., Yokoyama, Y. and Tanaka, Y.</td>
	<td>Vision based navigation system considering error recovery for autonomous mobile robot <p class="infolinks">[<a href="javascript:toggleInfo('619162','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('619162','bibtex')">BibTeX</a>]</p></td>
	<td>1997</td>
	<td><br/>Vol. 3Proceedings of International Conference on Robotics and Automation, pp. 1993-1998 vol.3&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.1997.619162">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_619162" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: We present a vision based navigation system which has an error recovery function for an autonomous mobile robot. A misrecognition of landmark causes the robot to mislocate itself. When this happens, the robot is unable to perform its primary objective. In order to solve this kind of problem, we have proposed a hierarchical control architecture "HALAS" (hierarchical adaptive and learning architecture system). This consists of some modules which are arranged hierarchically and each module means a single function of this robot. When one module fails in its aim, the upper module detects the error and recovers from it using other useful information from its knowledge data base. We show experimentally that the robot gets a higher reliability in autonomous mobility because the map correspondence module finds the error which has been caused by an anemo perception module (landmark recognition module) and it corrects the error utilizing its map information.</td>
</tr>
<tr id="bib_619162" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{619162,
  author = {Y. Abe and T. Fukuda and F. Arai and Y. Yokoyama and Y. Tanaka},
  title = {Vision based navigation system considering error recovery for autonomous mobile robot},
  booktitle = {Proceedings of International Conference on Robotics and Automation},
  year = {1997},
  volume = {3},
  pages = {1993-1998 vol.3},
  doi = {http://dx.doi.org/10.1109/ROBOT.1997.619162}
}
</pre></td>
</tr>
<tr id="Araujo2015189" class="entry">
	<td>Araujo, A.R., Caminhas, D.D. and Pereira, G.A.</td>
	<td>An Architecture for Navigation of Service Robots in Human-Populated Office-like Environments*  <p class="infolinks">[<a href="javascript:toggleInfo('Araujo2015189','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Araujo2015189','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>IFAC-PapersOnLine <br/>Vol. 48(19), pp. 189 - 194&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.ifacol.2015.12.032">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S2405896315026567">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Araujo2015189" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract This paper proposes a simple and efficient solution for robot navigation in officelike, indoor environments. The proposed methodology does not rely on metric localization and uses a laser range finder to detect the transitions among the nodes of a topological map of the environment, which is represented by a directed graph. The navigation between two nodes of the topological map is performed by using a vector field that is computed on the fly in function of the detected walls of the corridors, which are common in office-like environments, and of the people and other obstacles encountered in the robot’s path. This vector field is computed independently of the robot’s global path and is designed in a way that the robot’s behavior is socially accepted by the humans of the environment. Because metric localization is not necessary and the vector field computation is very simple, the method is computationally efficient, and this allows the robot to navigate at high speeds. In this paper we illustrate the methodology through real world experiments with a nonholonomic service robot navigating in an office-like environment.</td>
</tr>
<tr id="bib_Araujo2015189" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Araujo2015189,
  author = {Arthur R. Araujo and Daniel D. Caminhas and Guilherme A.S. Pereira},
  title = {An Architecture for Navigation of Service Robots in Human-Populated Office-like Environments* },
  journal = {IFAC-PapersOnLine },
  year = {2015},
  volume = {48},
  number = {19},
  pages = {189 - 194},
  note = {11th IFAC Symposium on Robot Control SYROCO 2015Salvador, Brazil, 26–28 August 2015 },
  url = {http://www.sciencedirect.com/science/article/pii/S2405896315026567},
  doi = {http://dx.doi.org/10.1016/j.ifacol.2015.12.032}
}
</pre></td>
</tr>
<tr id="austin2002robust" class="entry">
	<td>Austin, D. and Kouzoubov, K.</td>
	<td>Robust, Long Term Navigation of a Mobile Robot <p class="infolinks">[<a href="javascript:toggleInfo('austin2002robust','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('austin2002robust','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td>&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_austin2002robust" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In order for the field of robotics to become widely accepted, it is necessary to address the ongoing problem of reliability. For too long now, the robotics community has neglected robustness and reliability, focusing instead on theoretical advances. This paper presents work undertaken at the Australian National University to develop a mobile robot which operates 24 hours a day, 7 days a week without human intervention. The design of our system is presented, with emphasis on the aspects which improve the robustness of the system. In addition, the results from our experiments are presented which illustrate the reliability levels that we have achieved and highlight the areas where further work is required.</td>
</tr>
<tr id="bib_austin2002robust" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{austin2002robust,
  author = {Austin, David and Kouzoubov, Kirill},
  title = {Robust, Long Term Navigation of a Mobile Robot},
  publisher = {Citeseer},
  year = {2002}
}
</pre></td>
</tr>
<tr id="1045637" class="entry">
	<td>Bank, D.</td>
	<td>An error detection model for ultrasonic sensor evaluation on autonomous mobile systems <p class="infolinks">[<a href="javascript:toggleInfo('1045637','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1045637','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td>Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication, pp. 288-293&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROMAN.2002.1045637">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_1045637" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper presents an approach to safe navigation of autonomous mobile systems within partially known or unknown dynamic environments. In this context, faulty, maladjusted and otherwise influenced sensors must be recognized (error detection), and adequate measures for failure correction (error recovery) must be taken. As a general basis for monitoring the state of environmental sensors, a so called "error detection model" was created, which consists of sub-models for data from laser range finders and ultrasonic sensors. With the aid of the created models, different kinds of redundancy can be utilized and consistency and plausibility checks can be carried out. The error detection model serves for failure recognition based on environment modeling and on hypotheses for expected sensor readings.</td>
</tr>
<tr id="bib_1045637" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1045637,
  author = {D. Bank},
  title = {An error detection model for ultrasonic sensor evaluation on autonomous mobile systems},
  booktitle = {Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication},
  year = {2002},
  pages = {288-293},
  doi = {http://dx.doi.org/10.1109/ROMAN.2002.1045637}
}
</pre></td>
</tr>
<tr id="525317" class="entry">
	<td>Becker, C., Salas, J., Tokusei, K. and Latombe, J.C.</td>
	<td>Reliable navigation using landmarks <p class="infolinks">[<a href="javascript:toggleInfo('525317','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('525317','review')">Review</a>] [<a href="javascript:toggleInfo('525317','bibtex')">BibTeX</a>]</p></td>
	<td>1995</td>
	<td><br/>Vol. 1Proceedings of 1995 IEEE International Conference on Robotics and Automation, pp. 401-406 vol.1&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.1995.525317">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_525317" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Building a truly reliable mobile robot system-one that can navigate without failures for long periods of time (weeks or months)-requires making clear assumptions bounding uncertainty and enforcing those assumptions by appropriately engineering the robot and its workspace. Weak assumptions may result in low-cost engineering but make the navigation problem intractable. On the other hand, strict assumptions may simplify navigation but reduce the flexibility of the resulting system. The work presented in this paper investigates the tradeoff between "computational complexity" and "physical complexity" and advocates landmarks as a way of managing this tradeoff. We first define a formal navigation problem which incorporates enough assumptions to make it computationally tractable. We then use landmarks to enforce those assumptions. By implementing this system on our mobile robot we show that the assumptions are enforceable, that the engineering costs of using landmarks are acceptable, and that the resulting navigation system is both efficient and robust.</td>
</tr>
<tr id="rev_525317" class="review noshow">
	<td colspan="6"><b>Review</b>: Reliable Navigation Using Landmarks* Craig Becker, Joaquin Salas, Kentaro Tokusei, and Jean-Claude Latornbe Robotics Laboratory, Department of Computer Science, Stanford University Stanford, CA 94305, USA Abstract tem. In order to do so we must make some assump- tions about the uncertainty present in the environ- Building a truly reliable mobile robot system-one ment. We must then engineer the robot and/or its en- that can navigate without failures for long periods o j vironment to guarantee that those assumptions hold. t ime (weeks or months)-requires making clear as- We must be careful, however, that the assumptions sumptions bounding uncertainty and enforcing those we make do not require too much engineering. Ide- assumptions b y appropriately engineering the robot and ally, we would like the engineering costs to be “min- its workspace. Weak assumptions m a y result i n low- imal.” Therefore, one of the themes of this work is cost engineering but make the navigation problem in- the tradeoff between “computational complexity” (the tractable. On the other hand, strict assumptions may cost of planning and executing motions) and “physical simplify navigation but reduce the flexibility of the re- complexity” (the cost of engineering the environment). sulting system. The work presented in this paper in- We can reduce the computational complexity by mak- vestigates the trade08 between “computational com- ing strict assumptions, but this increases the costs of plexity” and Ohysical complexity” and advocates land- engineering the environment. Similarly, we can make marks as a way of managing this tradeoff. W e first only mild assumptions and require lower-cost engineer- define a formal navigation problem which incorpo- ing, but this can result in an intractalde computational rates enough assumptions t o make it computationally problem. An extreme example of engineering is com- tractable. We then use landmarks to enforce those as- monly used in industrial manufacturing: tape strips sumptions. By implementing this system on our mo- are placed on the floor and robots track these strips bile robot we show that the assumptions are enforcable, using a simple, specialized sensor. This technique es- that the engineering costs of using landmarks are ac- sentially eliminates uncertainty and reduces navigation ceptable, and thud the resulting navigation system is to the computation of paths along prespecified lanes. both eficient and robusi. It also, however, increases engineering costs and results in a system with very little flexibility. Our ultimate 1 Introduction goal is to find a “minimal” set of assumptions which The problem of reliable navigation is the most per- lead to a reliable and efficient navigation system which vasive in all of mobile robotics. For a robot to be truly requires only low-cost engineering of the environment. mobile, it must be able to repeatably move from point We hope that by investigating the tradeoff between to point while keeping track of its current location with computational and physical complexity we will gain respect to its environment and robustly recognizing insight into the factors which cause the intractability when it achieves its goals. Although this problem has of mobile robot navigation problems. received considerable attention, it still does not have a We have chosen to explore the us13o f simple, artifi- fully satisfactory solution: existing systems often lack cial landmarks as a means of limiting the control and flexibility, reliability, or both. Computational cost is sensing uncertainty in the robot’s environment. We also an issue. The main problem is that of dealing with claim that such landmarks require only a small amount uncertainty, which refers to the statistical distribution of environmental engineering, and that they make it of errors in both control and sensing. possible to build a very flexible and robust navigation Building a reliable navigation system depends on system. The notion of a landmark is not new and its bounding the uncertainty that is present in the sys- role in robot navigation has been previously discussed in several papers, including [8, 9, 12 161. Here we use *This research was funded by ARPA grant N00014-94-1-0721. this notion in a more formal and systematic way. C. Becker is supported in part by an NSF Graduate Fellowship. J. Salas is supporled by NSF contract IRI-9496205 and by a The work described here also introduces a new role fellowship from ITESM, Monterrey, Mkxico. for experimentation in robotics. In many cases exper- IEEE lnternatlonal Conference on Robotics and Automation - 201 - 0-7803-1965-6/95 $4.00 01 995 IEEE <p></td>
</tr>
<tr id="bib_525317" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{525317,
  author = {C. Becker and J. Salas and K. Tokusei and J. C. Latombe},
  title = {Reliable navigation using landmarks},
  booktitle = {Proceedings of 1995 IEEE International Conference on Robotics and Automation},
  year = {1995},
  volume = {1},
  pages = {401-406 vol.1},
  doi = {http://dx.doi.org/10.1109/ROBOT.1995.525317}
}
</pre></td>
</tr>
<tr id="biber2009experimental" class="entry">
	<td>Biber, P. and Duckett, T.</td>
	<td>Experimental analysis of sample-based maps for long-term SLAM <p class="infolinks">[<a href="javascript:toggleInfo('biber2009experimental','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('biber2009experimental','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>The International Journal of Robotics Research<br/>Vol. 28(1), pp. 20-33&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_biber2009experimental" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract This paper presents a system for long-term SLAM (simultaneous localization and mapping) by mobile service robots and its experimental evaluation in a real dynamic environment. To deal with the stability-plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patterns), the environment is represented at multiple timescales simultaneously (5 in our experiments). A sample-based representation is proposed, where older memories fade at different rates depending on the timescale, and robust statistics are used to interpret the samples. The dynamics of this representation are analysed in a five week experiment, measuring the relative influence of short- and long-term memories over time, and further demonstrating the robustness of the approach.</td>
</tr>
<tr id="bib_biber2009experimental" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{biber2009experimental,
  author = {Biber, Peter and Duckett, Tom},
  title = {Experimental analysis of sample-based maps for long-term SLAM},
  journal = {The International Journal of Robotics Research},
  publisher = {Sage Publications},
  year = {2009},
  volume = {28},
  number = {1},
  pages = {20--33}
}
</pre></td>
</tr>
<tr id="doi:10.1177/0278364913503892" class="entry">
	<td>Biswas, J. and Veloso, M.M.</td>
	<td>Localization and navigation of the CoBots over long-term deployments <p class="infolinks">[<a href="javascript:toggleInfo('doi:10.1177/0278364913503892','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('doi:10.1177/0278364913503892','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>The International Journal of Robotics Research<br/>Vol. 32(14), pp. 1679-1694&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1177/0278364913503892">DOI</a> <a href=" http://dx.doi.org/10.1177/0278364913503892 
">URL</a>&nbsp;</td>
</tr>
<tr id="abs_doi:10.1177/0278364913503892" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: For the last three years, we have developed and researched multiple collaborative robots, CoBots, which have been autonomously traversing our multi-floor buildings. We pursue the goal of long-term autonomy for indoor service mobile robots as the ability for them to be deployed indefinitely while they perform tasks in an evolving environment. The CoBots include several levels of autonomy, and in this paper we focus on their localization and navigation algorithms. We present the Corrective Gradient Refinement (CGR) algorithm, which refines the proposal distribution of the particle filter used for localization with sensor observations using analytically computed state space derivatives on a vector map. We also present the Fast Sampling Plane Filtering algorithm that extracts planar regions from depth images in real time. These planar regions are then projected onto the 2D vector map of the building, and along with the laser rangefinder observations, used with CGR for localization. For navigation, we present a hierarchical planner, which computes a topological policy using a graph representation of the environment, computes motion commands based on the topological policy, and then modifies the motion commands to side-step perceived obstacles. We started logging the deployments of the CoBots one and a half years ago, and have since collected logs of the CoBots traversing more than 130 km over 1082 deployments and a total run time of 182 h, which we publish as a dataset consisting of more than 10 million laser scans. The logs show that although there have been continuous changes in the environment, the robots are robust to most of them, and there exist only a few locations where changes in the environment cause increased uncertainty in localization.</td>
</tr>
<tr id="bib_doi:10.1177/0278364913503892" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{doi:10.1177/0278364913503892,
  author = {Joydeep Biswas and Manuela M. Veloso},
  title = {Localization and navigation of the CoBots over long-term deployments},
  journal = {The International Journal of Robotics Research},
  year = {2013},
  volume = {32},
  number = {14},
  pages = {1679-1694},
  url = { http://dx.doi.org/10.1177/0278364913503892 <br>},
  doi = {http://dx.doi.org/10.1177/0278364913503892}
}
</pre></td>
</tr>
<tr id="7747236" class="entry">
	<td>Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I. and Leonard, J.J.</td>
	<td>Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age <p class="infolinks">[<a href="javascript:toggleInfo('7747236','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7747236','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>IEEE Transactions on Robotics<br/>Vol. 32(6), pp. 1309-1332&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/TRO.2016.2624754">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7747236" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Simultaneous localization and mapping (SLAM) consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications and witnessing a steady transition of this technology to industry. We survey the current state of SLAM and consider future directions. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?</td>
</tr>
<tr id="bib_7747236" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{7747236,
  author = {C. Cadena and L. Carlone and H. Carrillo and Y. Latif and D. Scaramuzza and J. Neira and I. Reid and J. J. Leonard},
  title = {Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age},
  journal = {IEEE Transactions on Robotics},
  year = {2016},
  volume = {32},
  number = {6},
  pages = {1309-1332},
  doi = {http://dx.doi.org/10.1109/TRO.2016.2624754}
}
</pre></td>
</tr>
<tr id="4976608" class="entry">
	<td>Cerda, M.E.B. and Serrano, A.R.</td>
	<td>A 3-D Localization Algorithm for Robot Swarms under the Presence of Failures <p class="infolinks">[<a href="javascript:toggleInfo('4976608','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('4976608','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>2009 Fifth International Conference on Autonomic and Autonomous Systems, pp. 226-231&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICAS.2009.64">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_4976608" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: In many applications, localization systems are important to enable unmanned vehicles (UV) operate autonomously. An example of such applications is the exploration of unknown terrains, such as the zone of an earthquake or a similar disaster. In any such scenarios errors in the UV's sensors or systems used for localization may be present. Due to the harsh environment, errors can not be avoided. Thus, a localization technique that can operate effectively even in the presence of errors is highly desirable. In this paper, a technique used for 3D localization is presented. The technique operates with heterogeneous swarm of autonomous robotic systems, is scalable and robust enough to attain a position estimate even in the presence of errors in the available sensor information.</td>
</tr>
<tr id="bib_4976608" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{4976608,
  author = {M. E. B. Cerda and A. R. Serrano},
  title = {A 3-D Localization Algorithm for Robot Swarms under the Presence of Failures},
  booktitle = {2009 Fifth International Conference on Autonomic and Autonomous Systems},
  year = {2009},
  pages = {226-231},
  doi = {http://dx.doi.org/10.1109/ICAS.2009.64}
}
</pre></td>
</tr>
<tr id="6224596" class="entry">
	<td>Churchill, W. and Newman, P.</td>
	<td>Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation <p class="infolinks">[<a href="javascript:toggleInfo('6224596','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6224596','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 4525-4532&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2012.6224596">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6224596" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper is about long-term navigation in environments whose appearance changes over time - suddenly or gradually. We describe, implement and validate an approach which allows us to incrementally learn a model whose complexity varies naturally in accordance with variation of scene appearance. It allows us to leverage the state of the art in pose estimation to build over many runs, a world model of sufficient richness to allow simple localisation despite a large variation in conditions. As our robot repeatedly traverses its workspace, it accumulates distinct visual experiences that in concert, implicitly represent the scene variation - each experience captures a visual mode. When operating in a previously visited area, we continually try to localise in these previous experiences while simultaneously running an independent vision based pose estimation system. Failure to localise in a sufficient number of prior experiences indicates an insufficient model of the workspace and instigates the laying down of the live image sequence as a new distinct experience. In this way, over time we can capture the typical time varying appearance of an environment and the number of experiences required tends to a constant. Although we focus on vision as a primary sensor throughout, the ideas we present here are equally applicable to other sensor modalities. We demonstrate our approach working on a road vehicle operating over a three month period at different times of day, in different weather and lighting conditions. In all, we process over 136,000 frames captured from 37km of driving.</td>
</tr>
<tr id="bib_6224596" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6224596,
  author = {W. Churchill and P. Newman},
  title = {Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation},
  booktitle = {Robotics and Automation (ICRA), 2012 IEEE International Conference on},
  year = {2012},
  pages = {4525-4532},
  doi = {http://dx.doi.org/10.1109/ICRA.2012.6224596}
}
</pre></td>
</tr>
<tr id="Churchill2012" class="entry">
	<td>Churchill, W. and Newman, P.</td>
	<td>Continually Improving Large Scale Long Term Visual Navigation of a Vehicle in Dynamic Urban Environments <p class="infolinks">[<a href="javascript:toggleInfo('Churchill2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Churchill2012','review')">Review</a>] [<a href="javascript:toggleInfo('Churchill2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>2012 15th International IEEE Conference on Intelligent Transportation Systems Anchorage, Alaska, USA, September 16-19, 2012&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Churchill2012" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— This paper is about long term navigation in dynamic environments. In previous work we introduced a framework which stored distinct visual appearances of a workspace, known as experiences. These are used to improve localisation on future visits. In this work we introduce a new introspective process, executed between sorties, thats aims by careful discovery of the relationships between experiences, to further improve the performance of our system. We evaluate our new approach on 37km of stereo data captured over a three month period.</td>
</tr>
<tr id="rev_Churchill2012" class="review noshow">
	<td colspan="6"><b>Review</b>: 2012 15th International IEEE Conference on Intelligent Transportation Systems Anchorage, Alaska, USA, September 16-19, 2012 Continually Improving Large Scale Long Term Visual Navigation of a Vehicle in Dynamic Urban Environments Winston Churchill and Paul Newman Abstract—This paper is about long term navigation in each experience of the world to remain independent, but to dynamic environments. In previous work we introduced a capture their topological relationships in a graph. framework which stored distinct visual appearances of a workspace, known as experiences. These are used to improve Before we discuss how our experienced base navigation localisation on future visits. In this work we introduce a new works we briefly introduce some key terminology. Firstly introspective process, executed between sorties, thats aims by what our VO system produces, secondly what an experience careful discovery of the relationships between experiences, to is, and finally how localisers operate over experiences. further improve the performance of our system. We evaluate our new approach on 37km of stereo data captured over a three B. Visual Odometry month period. Visual Odometry (VO) is a well understood problem and I. INTRODUCTION several systems have previously been demonstrated [2], [3]. This paper is concerned with improving the performance We now briefly introduce the notation of ours, and whatwe get as output. For a sequence of stereo frames Fkof a long term navigation system. Before we present the = novel contributions of this paper in Section III, we first recap F0, . . . ,Fk, taken at times k, our VO system produces a our previous work on experience-based navigation [1] in corresponding sequence of nodes, nk. A 6 degree-of-freedom Section II. Implementation details and system performance transformation tk links sequential nodes nk 1 to nk, are briefly discussed in Section IV, results are presented in Section V and related work is covered in Section VI. tk = [x, y, z, ✓r, ✓p, ✓q] T (1) where ✓r, ✓p and ✓q are roll, pitch and yaw respectively.II. BACKGROUND: EXPERIENCE-BASED NAVIGATION Frame to frame motion estimation is achieved by matching A. Motivation the image descriptors of 3D landmarks. Landmarks are For robotic systems to achieve truly long-term autonomy created when previous ones cannot be matched to the current they must be able to deal with dynamic workspaces. Changes frame Fk. When this happens, the new landmarks are stored to an environment can happen for a variety of reasons and in the node, nk, from which they were first observed. A at different rates. Moving objects, such as people and cars landmark, li,k, is described as follows: can cause sudden structural change, the trajectory of the sun produces different lighting conditions over the period of a li,k = [x, y, z]T (2) day and the passage of the seasons results in a long term change in appearance. where i is a global landmark index and k denotes which One area that is affected by this problem is Visual Odome- node the 3D vector is relative to. Finally, every landmark try (VO), in which it is often implicitly assumed that changes observed in Fk is recorded in a list in nk. Many of these in the scene appearance are solely as a result of the ego- landmarks will be stored in other nodes - principally the one motion of the camera. The majority of traditional navigation from which they were first observed. approaches build a single map on the initial visit and hope Landmarks can be stored in one frame, but observed in this is sufficient for future use. The assumption being that another. For the estimation process it is required that a the environment will not change appearance drastically, and landmarks position can be expressed relative to different thus it is possible to localise using this single snapshot. nodes. To achieve this we define the following operation,p Features may be added or updated during future visits. ⇧q , which transforms a landmark from frame p to frame q. However should the system continue to accumulate features for all time? Given enough time, in such an approach the map l⇤,q p⇧q(l⇤,p) (3) will become bloated with features, many of which will have C. Experiences no relevance to each other. Also what should happen if the An experience is simply a sequential subset of the output workspace has drastically changed appearance - for example from the VO system. We denote each experience as jE . comparing a map created on a bright sunny afternoon with The conditions which trigger the saving of an experience a misty morning? We propose instead of attempting to fuse are discussed in Section II-E. data for all time into a single frame of reference, to allow Concretely, jE is a sequence of nodes, connected via The authors are with the Oxford University Mobile Robotics Group transformations and the set of all landmarks observed in the winston,pnewman@robots.ox.ac.uk sequence. Individual nodes within an experience are specified 978-1-4673-3063-3/12/$31.00 ©2012 IEEE 1371<p></td>
</tr>
<tr id="bib_Churchill2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Churchill2012,
  author = {Winston Churchill and Paul Newman},
  title = {Continually Improving Large Scale Long Term Visual Navigation of a Vehicle in Dynamic Urban Environments},
  booktitle = {2012 15th International IEEE Conference on Intelligent Transportation Systems Anchorage, Alaska, USA, September 16-19, 2012},
  publisher = {IEEE},
  year = {2012}
}
</pre></td>
</tr>
<tr id="Courbon2013" class="entry">
	<td>Courbon, J., Korrapati, H. and Mezouar, Y.</td>
	<td>Visual Memory Update for Life-Long Mobile Robot Navigation <p class="infolinks">[<a href="javascript:toggleInfo('Courbon2013','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Courbon2013','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Intelligent Autonomous Systems 12: Volume 1 Proceedings of the 12th International Conference IAS-12, held June 26-29, 2012, Jeju Island, Korea, pp. 133-142&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://dx.doi.org/10.1007/978-3-642-33926-4_12">DOI</a> <a href="http://dx.doi.org/10.1007/978-3-642-33926-4_12">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Courbon2013" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A central clue for implementation of visual memory based navigation strategies relies on efficient point matching between the current image and the key images of the memory. However, the visual memory may become out of date after some times because the appearance of real-world environments keeps changing. It is thus necessary to remove obsolete information and to add new data to the visual memory over time. In this paper, we propose a method based on short-term and long term memory concepts to update the visual memory of mobile robots during navigation. The results of our experiments show that using this method improves the robustness of the localization and path-following steps.</td>
</tr>
<tr id="bib_Courbon2013" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Courbon2013,
  author = {Courbon, Jonathan and Korrapati, Hemanth and Mezouar, Youcef},
  title = {Visual Memory Update for Life-Long Mobile Robot Navigation},
  booktitle = {Intelligent Autonomous Systems 12: Volume 1 Proceedings of the 12th International Conference IAS-12, held June 26-29, 2012, Jeju Island, Korea},
  publisher = {Springer Berlin Heidelberg},
  year = {2013},
  pages = {133--142},
  url = {http://dx.doi.org/10.1007/978-3-642-33926-4_12},
  doi = {http://dx.doi.org/10.1007/978-3-642-33926-4_12}
}
</pre></td>
</tr>
<tr id="di2010autonomous" class="entry">
	<td>Di Paola, D., Milella, A., Cicirelli, G. and Distante, A.</td>
	<td>An autonomous mobile robotic system for surveillance of indoor environments <p class="infolinks">[<a href="javascript:toggleInfo('di2010autonomous','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('di2010autonomous','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>International Journal of Advanced Robotic Systems<br/>Vol. 7(1), pp. 8&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_di2010autonomous" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The development of intelligent surveillance systems is an active research area. In this context, mobile and multi-functional robots are generally adopted as means to reduce the environment structuring and the number of devices needed to cover a given area. Nevertheless, the number of different sensors mounted on the robot, and the number of complex tasks related to exploration, monitoring, and surveillance make the design of the overall system extremely challenging. In this paper, we present our autonomous mobile robot for surveillance of indoor environments. We propose a system able to handle autonomously general-purpose tasks and complex surveillance issues simultaneously. It is shown that the proposed robotic surveillance scheme successfully addresses a number of basic problems related to environment mapping, localization and autonomous navigation, as well as surveillance tasks, like scene processing to detect abandoned or removed objects and people detection and following. The feasibility of the approach is demonstrated through experimental tests using a multisensor platform equipped with a monocular camera, a laser scanner, and an RFID device. Real world applications of the proposed system include surveillance of wide areas (e.g. airports and museums) and buildings, and monitoring of safety equipment.</td>
</tr>
<tr id="bib_di2010autonomous" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{di2010autonomous,
  author = {Di Paola, Donato and Milella, Annalisa and Cicirelli, Grazia and Distante, Arcangelo},
  title = {An autonomous mobile robotic system for surveillance of indoor environments},
  journal = {International Journal of Advanced Robotic Systems},
  publisher = {SAGE Publications},
  year = {2010},
  volume = {7},
  number = {1},
  pages = {8}
}
</pre></td>
</tr>
<tr id="Dymczyk2015" class="entry">
	<td>Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., Lab, A.S. and Zurich, E.</td>
	<td>The Gist of Maps – Summarizing Experience for Lifelong Localization <p class="infolinks">[<a href="javascript:toggleInfo('Dymczyk2015','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Dymczyk2015','review')">Review</a>] [<a href="javascript:toggleInfo('Dymczyk2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 IEEE International Conference on Robotics and Automation (ICRA) Washington State Convention Center Seattle, Washington, May 26-30, 2015&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Dymczyk2015" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Robust, scalable place recognition is a core competency for many robotic applications. However, when revisiting places over and over, many state-of-the-art approaches exhibit reduced performance in terms of computation and memory complexity and in terms of accuracy. For successful deployment of robots over long time scales, we must develop algorithms that get better with repeated visits to the same environment, while still working within a fixed computational budget. This paper presents and evaluates an algorithm that alternates between online place recognition and offline map maintenance with the goal of producing the best performance with a fixed map size. At the core of the algorithm is the concept of a Summary Map, a reduced map representation that includes only the landmarks that are deemed most useful for place recognition. To assign landmarks to the map, we use a scoring function that ranks the utility of each landmark and a sampling policy that selects the landmarks for each place. The Summary Map can then be used by any descriptor-based inference method for constant-complexity online place recognition. We evaluate a number of scoring functions and sampling policies and show that it is possible to build and maintain maps of a constant size and that place-recognition performance improves over multiple visits.</td>
</tr>
<tr id="rev_Dymczyk2015" class="review noshow">
	<td colspan="6"><b>Review</b>: 2015 IEEE International Conference on Robotics and Automation (ICRA) Washington State Convention Center Seattle, Washington, May 26-30, 2015 The Gist of Maps – Summarizing Experience for Lifelong Localization Marcin Dymczyk, Simon Lynen, Titus Cieslewski, Michael Bosse, Roland Siegwart, and Paul Furgale Autonomous Systems Lab, ETH Zurich Abstract— Robust, scalable place recognition is a core compe- tency for many robotic applications. However, when revisiting Map places over and over, many state-of-the-art approaches exhibit Summarization reduced performance in terms of computation and memory complexity and in terms of accuracy. For successful deployment of robots over long time scales, we must develop algorithms that Lifelong Localization get better with repeated visits to the same environment, while still working within a fixed computational budget. Offline This paper presents and evaluates an algorithm that al- Geometric Online ternates between online place recognition and offline map Alignment Localization maintenance with the goal of producing the best performance with a fixed map size. At the core of the algorithm is the concept Fig. 1: Summarizing experience for lifelong localization: Online localization of a Summary Map, a reduced map representation that includes provides a stream of new experiences that contain new but also redundant only the landmarks that are deemed most useful for place information. We propose a combination of scoring functions and sampling recognition. To assign landmarks to the map, we use a scoring policies that can identify and select relevant data to be used to produce a function that ranks the utility of each landmark and a sampling Summary Map. This Summary Map contains the gist of previous experiencesto unlock the best performance for online place recognition and localization. policy that selects the landmarks for each place. The Summary Map can then be used by any descriptor-based inference method system design as we have to take care that the geometry of for constant-complexity online place recognition. We evaluate a number of scoring functions and sampling policies and show landmarks in the map is able to constrain the agent’s pose that it is possible to build and maintain maps of a constant size when revisiting places. and that place-recognition performance improves over multiple This paper presents a methodology for recursive, contin- visits. uous map summarization that reinforces stable landmarks I. INTRODUCTION within the agent’s map and adapts to newly discovered or changing aspects of the environment. After a run of Robust vision-based localization based on pre-built maps online localization, we incorporate the new data to produce forms the backbone of modern navigation algorithms both a Summary Map based on running statistics updated after for robotics and mobile device applications. As demonstrated every visit. In the most general case, we apply a scoring in many studies of visual navigation [1, 2], a static map function for landmark and trajectory segments to evaluate is insufficient for lifelong localization given the continuous their usefulness for localization, and then use a sampling change of scene appearance around us. We believe that the strategy to select the landmarks that will be retained for stream of observations provided by the localizing agents online operation. New parts of the map which are not should be used to continuously update, improve and enhance reobservations of existing structure are saved on a “waiting the map for reliable localization over longer periods. list” to give them a chance to be confirmed by additional In addition to incorporating environmental changes, re- evidence. This process allows us to distinguish noise (single peated visits to the same environment should increase local- observation) from persistent changes to the environment ization robustness and quality by providing statistics about (multiple observations). The fractions of the map that are which map data is most reliable. While we would like found either to be redundant with other observations or never to be able to store and localize against a large library of re-observed are discarded. Careful design of both the scoring previous experiences of a place (as in [3]), in practice, an and the sampling methods makes it possible to remove online system will be subject to memory, computation, and noise or outdated data from the map while simultaneously bandwidth constraints on map data. Consequently, we need accommodating to changes in the environment. The resulting to develop mapping and localization systems that fluidly algorithm repeatedly integrates new observations into the incorporate new data and exhibit better performance with map, while maintaining an overall map size constant with every visit to the same place, while using only a fixed respect to the area covered. Because only the most reliable memory and computational budget. information is incorporated into the Summary Map, we In this paper, we apply these general concepts to the show that the overall localization quality improves as we problem of metric place recognition. In metric place recog- incorporate new data, despite the fact that the map size nition, the system recovers the pose of the agent with remains constant. respect to a coordinate frame within our map. This is in contrast to topological place recognition systems that simply The contributions of this paper are as follows: identify previously visited places. This difference guides our • we present the general methodology for producing 978-1-4799-6923-4/15/$31.00 ©2015 IEEE 2767<p></td>
</tr>
<tr id="bib_Dymczyk2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Dymczyk2015,
  author = {Marcin Dymczyk and Simon Lynen and Titus Cieslewski and Michael Bosse and Roland Siegwart and Paul Furgale and Autonomous Systems Lab and ETH Zurich},
  title = {The Gist of Maps – Summarizing Experience for Lifelong Localization},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA) Washington State Convention Center Seattle, Washington, May 26-30, 2015},
  publisher = {IEEE},
  year = {2015}
}
</pre></td>
</tr>
<tr id="6907079" class="entry">
	<td>English, A., Ross, P., Ball, D. and Corke, P.</td>
	<td>Vision based guidance for robot navigation in agriculture <p class="infolinks">[<a href="javascript:toggleInfo('6907079','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6907079','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 1693-1698&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2014.6907079">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6907079" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper describes a novel vision based texture tracking method to guide autonomous vehicles in agricultural fields where the crop rows are challenging to detect. Existing methods require sufficient visual difference between the crop and soil for segmentation, or explicit knowledge of the structure of the crop rows. This method works by extracting and tracking the direction and lateral offset of the dominant parallel texture in a simulated overhead view of the scene and hence abstracts away crop-specific details such as colour, spacing and periodicity. The results demonstrate that the method is able to track crop rows across fields with extremely varied appearance during day and night. We demonstrate this method can autonomously guide a robot along the crop rows.</td>
</tr>
<tr id="bib_6907079" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6907079,
  author = {A. English and P. Ross and D. Ball and P. Corke},
  title = {Vision based guidance for robot navigation in agriculture},
  booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  year = {2014},
  pages = {1693-1698},
  doi = {http://dx.doi.org/10.1109/ICRA.2014.6907079}
}
</pre></td>
</tr>
<tr id="812832" class="entry">
	<td>Goel, P., Roumeliotis, S.I. and Sukhatme, G.S.</td>
	<td>Robust localization using relative and absolute position estimates <p class="infolinks">[<a href="javascript:toggleInfo('812832','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('812832','review')">Review</a>] [<a href="javascript:toggleInfo('812832','bibtex')">BibTeX</a>]</p></td>
	<td>1999</td>
	<td><br/>Vol. 2Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), pp. 1134-1140 vol.2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.1999.812832">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_812832" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: A low cost strategy based on well calibrated odometry is presented for localizing mobile robots. The paper describes a two-step process for correction of 'systematic errors' in encoder measurements followed by fusion of the calibrated odometry with a gyroscope and GPS resulting in a robust localization scheme. A Kalman filter operating on data from the sensors is used for estimating position and orientation of the robot. Experimental results are presented that show an improvement of at least one order of magnitude in accuracy compared to the un-calibrated, un-filtered case. Our method is systematic, simple and yields very good results. We show that this strategy proves useful when the robot is using GPS to localize itself as well as when GPS becomes unavailable for some time. As a result robot can move in and out of enclosed spaces, such as buildings, while keeping track of its position on the fly.</td>
</tr>
<tr id="rev_812832" class="review noshow">
	<td colspan="6"><b>Review</b>: Proceedings of the 1999 I E E W J International Conference on Intelligent Robots and Systems Robust Localization Using Relative and Absolute Position Estimates Puneet Goel, Stergios I. Roumeliotis and Gaurav S. Sukhatme* pvneetlstergioslgauravOrobotics.usc.edu Department of Computer Science Institute for Robotics and Intelligent Systems University of Southern California Los Angeles, CA 90089-0781 Abstract A popular local technique, dead reckoning, employs simple geometric equations (a kinematic model of the A low cost strategy based on well calibrated odom- robot) on odometric data to compute the position of etry is presented for localizing mobile robots. The the robot relative to its start position. Dead reckon- paper describes a two-step process for correction of ing cannot be used for long distances because it suffers 'systematic errors' in encoder measurements followed from various drawbacks. The kinematic model alway by fusion of the calibrated odometry with a gyroscope has some inaccuracies, encoders have limited preci- and GPS resulting in a robust localization scheme. sion and there are external sources affecting the mo- A Kalman filter operating on data from the sensors tion that are not observable by the sensors (e.g. wheel is used for estimating position and orientation of the slippage). The localization error grows with time. Ap- robot. Experimental results are presented that show an plying Kalman filter techniques can provide substan- improvement of at least one order of magnitude in ac- tial improvement [1],[9]. curacy compared to the un-calibrated, un-filtered case. Our method is systematic, simple and yields very good results. We show that this strategy proves useful when In case of absolute localization the error growth is the robot is using GPS t o localize itself as well as when mitigated when measurements are available. The po- GPS becomes unavailable for some time. As a result sition of the robot is externally determined and its robot can move in and out of enclosed spaces, such as accuracy is usually time and location independent. In buildings, while keeping track of its position on the fly. other words integration of noisy data is not required and thus there is no accumulation of error with time or distance traveled. The problem in absolute local- 1 Introduction ization (e.g. using GPS) is that one cannot keep track of the robot for small distances (barring exceptionally In order to autonomously navigate and perform accurate GPS estimates). Commercial off the shelf useful tasks, a mobile robot needs to know its exact GPS gives errors on the order of 10 cm at each mea- position and orientation. Robot localization is thus a surement. If the robot moves at l m/s one cannot use key problem in providing autonomous capabilities to a GPS at each second since the odometric estimate is mobile robot. The different techniques that have been less error prone than the GPS measurement. developed to tackle this problem can be classified into Various people have presented work related to a b two main categories: solute localization . Leonard and Durrant-Whyte [SI Relative (local) localization: evaluating the po- developed a system in which the basic algorithm is sition and orientation using information provided by formalized as a vehicle tracking problem, employing various on-board sensors (e.g. encoders, gyroscopes, an Extended Kalman Filter (EKF) to match beacon accelerometers etc). observations to a navigation map to maintain an es- Absolute (global) localization: obtaining timate of the position of the mobile robot. Thrun the absolute position using beacons, landmarks or et.al.[lO] have developed a learning algorithm that en- satellite-based signals (e.g. GPS). ables a mobile robot to learn what features/landmarks are best suited for localization. They also use map *contact author for correspondence matching [ 111 ,[4] using information from wheel en- 0-7803-5184-3/99/$10.00 0 1999 IEEE 1134 <p></td>
</tr>
<tr id="bib_812832" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{812832,
  author = {P. Goel and S. I. Roumeliotis and G. S. Sukhatme},
  title = {Robust localization using relative and absolute position estimates},
  booktitle = {Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289)},
  year = {1999},
  volume = {2},
  pages = {1134-1140 vol.2},
  doi = {http://dx.doi.org/10.1109/IROS.1999.812832}
}
</pre></td>
</tr>
<tr id="6338060" class="entry">
	<td>Jafar, F.A., Ali, M.M., Muhammad, M.N., Zakaria, N.A. and Yokota, K.</td>
	<td>Robust Motion Controller for Mobile Robot Navigation in Indoor Environment <p class="infolinks">[<a href="javascript:toggleInfo('6338060','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6338060','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>2012 Fourth International Conference on Computational Intelligence, Modelling and Simulation, pp. 133-137&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/CIMSim.2012.48">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6338060" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: The problem of controlling the pose of a mobile robot with respect to a target position by means of visual feedback is investigated. The proposed method enables a mobile robot to identify its own position using visual features of environment. At the same time, the robot performs an orientation recognition using the same recognition method of position identification in order to follow a path in environment. One of the advantages of the proposed method is that both position and orientation recognition uses the same task where this situation will help for lowering the cost of the robot system development. Furthermore, the calculation method is simple, no precise and accurate measurement is used in the proposed navigation method. Experimental results demonstrate the effectiveness of our proposed method.</td>
</tr>
<tr id="bib_6338060" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6338060,
  author = {F. A. Jafar and M. M. Ali and M. N. Muhammad and N. A. Zakaria and K. Yokota},
  title = {Robust Motion Controller for Mobile Robot Navigation in Indoor Environment},
  booktitle = {2012 Fourth International Conference on Computational Intelligence, Modelling and Simulation},
  year = {2012},
  pages = {133-137},
  doi = {http://dx.doi.org/10.1109/CIMSim.2012.48}
}
</pre></td>
</tr>
<tr id="5354121" class="entry">
	<td>Konolige, K. and Bowman, J.</td>
	<td>Towards lifelong visual maps <p class="infolinks">[<a href="javascript:toggleInfo('5354121','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('5354121','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1156-1163&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2009.5354121">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_5354121" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: The typical SLAM mapping system assumes a static environment and constructs a map that is then used without regard for ongoing changes. Most SLAM systems, such as FastSLAM, also require a single connected run to create a map. In this paper we present a system of visual mapping, using only input from a stereo camera, that continually updates an optimized metric map in large indoor spaces with movable objects: people, furniture, partitions, etc. The system can be stopped and restarted at arbitrary disconnected points, is robust to occlusion and localization failures, and efficiently maintains alternative views of a dynamic environment. It operates completely online at a 30 Hz frame rate.</td>
</tr>
<tr id="bib_5354121" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{5354121,
  author = {K. Konolige and J. Bowman},
  title = {Towards lifelong visual maps},
  booktitle = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2009},
  pages = {1156-1163},
  doi = {http://dx.doi.org/10.1109/IROS.2009.5354121}
}
</pre></td>
</tr>
<tr id="6943205" class="entry">
	<td>Krajník, T., Fentanes, J.P., Mozos, O.M., Duckett, T., Ekekrantz, J. and Hanheide, M.</td>
	<td>Long-term topological localisation for service robots in dynamic environments using spectral maps <p class="infolinks">[<a href="javascript:toggleInfo('6943205','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6943205','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4537-4542&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2014.6943205">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6943205" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper presents a new approach for topological localisation of service robots in dynamic indoor environments. In contrast to typical localisation approaches that rely mainly on static parts of the environment, our approach makes explicit use of information about changes by learning and modelling the spatio-temporal dynamics of the environment where the robot is acting. The proposed spatio-temporal world model is able to predict environmental changes in time, allowing the robot to improve its localisation capabilities during long-term operations in populated environments. To investigate the proposed approach, we have enabled a mobile robot to autonomously patrol a populated environment over a period of one week while building the proposed model representation. We demonstrate that the experience learned during one week is applicable for topological localization even after a hiatus of three months by showing that the localization error rate is significantly lower compared to static environment representations.</td>
</tr>
<tr id="bib_6943205" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6943205,
  author = {T. Krajník and J. P. Fentanes and O. M. Mozos and T. Duckett and J. Ekekrantz and M. Hanheide},
  title = {Long-term topological localisation for service robots in dynamic environments using spectral maps},
  booktitle = {2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2014},
  pages = {4537-4542},
  doi = {http://dx.doi.org/10.1109/IROS.2014.6943205}
}
</pre></td>
</tr>
<tr id="6766591" class="entry">
	<td>Krajník, T., Pedre, S. and Přeučil, L.</td>
	<td>Monocular navigation for long-term autonomy <p class="infolinks">[<a href="javascript:toggleInfo('6766591','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6766591','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>2013 16th International Conference on Advanced Robotics (ICAR), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICAR.2013.6766591">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6766591" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: We present a reliable and robust monocular navigation system for an autonomous vehicle. The proposed method is computationally efficient, needs off-the-shelf equipment only and does not require any additional infrastructure like radio beacons or GPS. Contrary to traditional localization algorithms, which use advanced mathematical methods to determine vehicle position, our method uses a more practical approach. In our case, an image-feature-based monocular vision technique determines only the heading of the vehicle while the vehicle's odometry is used to estimate the distance traveled. We present a mathematical proof and experimental evidence indicating that the localization error of a robot guided by this principle is bound. The experiments demonstrate that the method can cope with variable illumination, lighting deficiency and both short- and long-term environment changes. This makes the method especially suitable for deployment in scenarios which require long-term autonomous operation.</td>
</tr>
<tr id="bib_6766591" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6766591,
  author = {T. Krajník and S. Pedre and L. Přeučil},
  title = {Monocular navigation for long-term autonomy},
  booktitle = {2013 16th International Conference on Advanced Robotics (ICAR)},
  year = {2013},
  pages = {1-6},
  doi = {http://dx.doi.org/10.1109/ICAR.2013.6766591}
}
</pre></td>
</tr>
<tr id="Mac201613" class="entry">
	<td>Mac, T.T., Copot, C., Tran, D.T. and Keyser, R.D.</td>
	<td>Heuristic approaches in robot path planning: A survey  <p class="infolinks">[<a href="javascript:toggleInfo('Mac201613','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Mac201613','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Robotics and Autonomous Systems <br/>Vol. 86, pp. 13 - 28&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2016.08.001">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0921889015300671">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Mac201613" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Autonomous navigation of a robot is a promising research domain due to its extensive applications. The navigation consists of four essential requirements known as perception, localization, cognition and path planning, and motion control in which path planning is the most important and interesting part. The proposed path planning techniques are classified into two main categories: classical methods and heuristic methods. The classical methods consist of cell decomposition, potential field method, subgoal network and road map. The approaches are simple; however, they commonly consume expensive computation and may possibly fail when the robot confronts with uncertainty. This survey concentrates on heuristic-based algorithms in robot path planning which are comprised of neural network, fuzzy logic, nature-inspired algorithms and hybrid algorithms. In addition, potential field method is also considered due to the good results. The strengths and drawbacks of each algorithm are discussed and future outline is provided.</td>
</tr>
<tr id="bib_Mac201613" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Mac201613,
  author = {Thi Thoa Mac and Cosmin Copot and Duc Trung Tran and Robin De Keyser},
  title = {Heuristic approaches in robot path planning: A survey },
  journal = {Robotics and Autonomous Systems },
  year = {2016},
  volume = {86},
  pages = {13 - 28},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889015300671},
  doi = {http://dx.doi.org/10.1016/j.robot.2016.08.001}
}
</pre></td>
</tr>
<tr id="Naseer2017147" class="entry">
	<td>Naseer, T., Suger, B., Ruhnke, M. and Burgard, W.</td>
	<td>Vision-based Markov localization for long-term autonomy  <p class="infolinks">[<a href="javascript:toggleInfo('Naseer2017147','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Naseer2017147','bibtex')">BibTeX</a>]</p></td>
	<td>2017</td>
	<td>Robotics and Autonomous Systems <br/>Vol. 89, pp. 147 - 157&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2016.11.008">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0921889016300501">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Naseer2017147" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Lifelong autonomous operation has gained much attention in the field of mobile robotics in recent years. In the context of robot navigation based on vision, lifelong applications include scenarios with substantial perceptual changes due to changes in season, illumination and weather. In this paper, we present an approach to localize a mobile robot, equipped with a low frequency camera, with respect to an image sequence recorded in a different season. Our approach employs a discrete Bayes filter with a sensor model based on whole image descriptors. We compute a similarity matrix over all image descriptors and leverage the sequential nature of typical image streams with a flexible transition scheme in the Bayes filter framework. Since we compute a probability distribution over the entire state space, our approach can handle complex trajectories that may include same season loop-closures as well as fragmented sub-sequences. Furthermore, we show that decorrelating the similarity matrix results in an improved localization performance. Through an extensive experimental evaluation on challenging datasets we demonstrate that our approach outperforms state-of-the-art techniques.</td>
</tr>
<tr id="bib_Naseer2017147" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Naseer2017147,
  author = {Tayyab Naseer and Benjamin Suger and Michael Ruhnke and Wolfram Burgard},
  title = {Vision-based Markov localization for long-term autonomy },
  journal = {Robotics and Autonomous Systems },
  year = {2017},
  volume = {89},
  pages = {147 - 157},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889016300501},
  doi = {http://dx.doi.org/10.1016/j.robot.2016.11.008}
}
</pre></td>
</tr>
<tr id="Park2009" class="entry">
	<td>Park, J.-T. and Song, J.-B.</td>
	<td>Error recovery framework for integrated navigation system based on generalized stochastic petri nets <p class="infolinks">[<a href="javascript:toggleInfo('Park2009','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Park2009','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>International Journal of Control, Automation and Systems<br/>Vol. 7(6), pp. 956&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/s12555-009-0612-y">DOI</a> <a href="http://dx.doi.org/10.1007/s12555-009-0612-y">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Park2009" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A mobile robot usually works in dynamic environments with many uncertainties caused by either humans or various obstacles. Such uncertainties may cause unexpected error situations that often lead to navigation failure. Therefore, the robot should be able to recover from these unexpected error situations. This paper proposes an error recovery framework based on generalized stochastic Petri nets (GSPN). The approach can provide several advantages. The proposed framework can model various error situations occurring in real environments, thereby enabling a robot to recover from error situations autonomously. The modeling, analysis, and performance evaluation can be also carried out using the GSPN model. Experimental results show that the proposed error recovery framework is useful for dependable navigation of a mobile robot operating autonomously.</td>
</tr>
<tr id="bib_Park2009" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Park2009,
  author = {Park, Joong-Tae and Song, Jae-Bok},
  title = {Error recovery framework for integrated navigation system based on generalized stochastic petri nets},
  journal = {International Journal of Control, Automation and Systems},
  year = {2009},
  volume = {7},
  number = {6},
  pages = {956},
  url = {http://dx.doi.org/10.1007/s12555-009-0612-y},
  doi = {http://dx.doi.org/10.1007/s12555-009-0612-y}
}
</pre></td>
</tr>
<tr id="Pe´rez2014" class="entry">
	<td>Pe´rez, J., Caballero, F. and Merino, L.</td>
	<td>Integration of Monte Carlo Localization and Place Recognition for Reliable Long-Term Robot Localization <p class="infolinks">[<a href="javascript:toggleInfo('Pe´rez2014','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pe´rez2014','review')">Review</a>] [<a href="javascript:toggleInfo('Pe´rez2014','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) May 14-15, Espinho, Portugal&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Pe´rez2014" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— This paper proposes extending Monte Carlo Lo- calization methods with visual information in order to build a long term robot localization system. This system is aimed to work in crowded and non-planar scenarios, where 2D laser rangefinders may not always be enough to match the robot position with the map. Thus, visual place recognition will be used in order to obtain robot position clues that can be used to detect when the robot is lost and also to reset its positions to the right one. The paper presents experimental results based on datasets gathered with a real robot in challenging scenarios.</td>
</tr>
<tr id="rev_Pe´rez2014" class="review noshow">
	<td colspan="6"><b>Review</b>: 2014 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) May 14-15, Espinho, Portugal Integration of Monte Carlo Localization and Place Recognition for Reliable Long-Term Robot Localization Javier Pe´rez1, Fernando Caballero2 and Luis Merino1 Abstract— This paper proposes extending Monte Carlo Lo- calization methods with visual information in order to build a long term robot localization system. This system is aimed to work in crowded and non-planar scenarios, where 2D laser rangefinders may not always be enough to match the robot position with the map. Thus, visual place recognition will be used in order to obtain robot position clues that can be used to detect when the robot is lost and also to reset its positions to the right one. The paper presents experimental results based Fig. 1. The FROG project aims to deploy a guiding robot with a fun on datasets gathered with a real robot in challenging scenarios. personality, considering social feedback, in the Royal Alcazar of Seville and the Zoo of Lisbon. Young visitors surrounding the robot in the Royal Alcazar, interfering in sensor readings and interrupting robot’s trajectory. I. INTRODUCTION The work of this paper is part of larger project, the project FROG3, that aims to deploy a guiding robot in touris- it can perform poorly when large variations are present, as tic sites involving outdoor and partially outdoor scenarios. it can be seen in crowded and dynamic environments like While robot guides have been developed since more than the Lisbon Zoo and the Royal Alcazar, where people may a decade [1], the project considers as new contributions approach and surround the robot driven by curiosity (see the development of social behaviors and their adaptation by Figure 1) or while they are being guided. integrating social feedback, as well as the robust operation in Several approaches have been considered to enhance the outdoors crowded scenarios. It aims to demonstrate a long- robustness of localization systems. Thus, Hentschel and term operation of the robot in the Lisbon Zoo and the Royal Wagner [4] and Dayoub and Duckett [5] present in their Alcazar in Seville (see Figure 1). works environmental representations for autonomous mobile Navigating in these crowded places (the Royal Alcazar robots that continuously adapt over time, inspired by human may have more than 5000 visits per day) requires a robust lo- memory and storing the current as well as past knowledge of calization system. Achieving long-term localization involves the environment, using sensory memory, short-term memory several issues, like handling of variant environments, error and long-term memory. recovery, efficient place recognition, etc. Furthermore, those Online loop-detection algorithms based on scene- algorithms based on vision and visual place-recognition have recognition like OpenFabMap2 [6], DLoopDetector [7], and to deal with illumination changes, different weather and others [8] that use structures based on Bag-of-Words [9] daylight conditions, etc. Besides that, these scenarios may have been presented to look for revisited places, what is present a highly variable environment with partial sensor helpful for recovering from localization errors. Corke et occlusions due to the visitors, which can cause troubles al. [10] present an algorithm for getting invariant images to map-based localization using laser readings and dead for long-term localization based on scene appearance. They reckoning [2]. describe how to convert different time outdoor colour images Scan matching approaches based on 2D lasers are the most to greyscale invariant ones by considering the response of extended localization algorithms, due to their high accuracy the colour channels in trichromatic vision and removing compared to other sensors like ultrasonic sensors, and with illumination effect. a low processing cost compared to vision sensors [3]. These These visual algorithms can be easily used to provide addi- algorithms make use of a geometric map and scan matching tional localization hypotheses to the pose estimated by using to guess the new position of the robot from previous ones and other sensorial modalities, like laser rangefinders. These new dead reckoning. Scan matching can handle small variations hypotheses can be used to enhance the robustness of the in the environment, such as changes of state of doors, but localization system. In this paper we propose a localization algorithm based on a Monte Carlo Localization filter fed with This work is partially funded by the European Commission 7th Frame- particles from appearance clues obtained from images, which work Programme under grant agreement no. 288235 (FROG) and the project PAIS-MultiRobot, funded by the Junta de Andalucı´a (TIC-7390) will be able to recover from possible errors in localization, 1 Javier Pe´rez and Luis Merino are with the Pablo de Olavide University, combining the high accuracy of lasers with a re-localization Seville (Spain) jiperlar,lmercab@upo.es process. 2 Fernando Caballero is with University of Seville, Seville (Spain) fcaballero@us.es The structure of the paper is as follows: next section 3 http://www.frogrobot.eu describes the robotic platform used for tests. Then, Section 978-1-4799-4254-1/14/$31.00 ©2014 IEEE 85<p></td>
</tr>
<tr id="bib_Pe´rez2014" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Pe´rez2014,
  author = {Javier Pe´rez and Fernando Caballero and Luis Merino},
  title = {Integration of Monte Carlo Localization and Place Recognition for Reliable Long-Term Robot Localization},
  booktitle = {2014 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) May 14-15, Espinho, Portugal},
  publisher = {IEEE},
  year = {2014}
}
</pre></td>
</tr>
<tr id="Peynot2013" class="entry">
	<td>Peynot, T., Fitch, R., McAllister, R. and Alempijevic, A.</td>
	<td>Resilient Navigation through Probabilistic Modality Reconfiguration <p class="infolinks">[<a href="javascript:toggleInfo('Peynot2013','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Peynot2013','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Intelligent Autonomous Systems 12: Volume 2 Proceedings of the 12th International Conference IAS-12, held June 26-29, 2012, Jeju Island, Korea, pp. 75-88&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://dx.doi.org/10.1007/978-3-642-33932-5_8">DOI</a> <a href="http://dx.doi.org/10.1007/978-3-642-33932-5_8">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Peynot2013" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper proposes an approach to achieve resilient navigation for indoor mobile robots. Resilient navigation seeks to mitigate the impact of control, localisation, or map errors on the safety of the platform while enforcing the robot’s ability to achieve its goal. We show that resilience to unpredictable errors can be achieved by combining the benefits of independent and complementary algorithmic approaches to navigation, or modalities, each tuned to a particular type of environment or situation. In this paper, the modalities comprise a path planning method and a reactive motion strategy. While the robot navigates, a Hidden Markov Model continually estimates the most appropriate modality based on two types of information: context (information known a priori) and monitoring (evaluating unpredictable aspects of the current situation). The robot then uses the recommended modality, switching between one and another dynamically. Experimental validation with a SegwayRMP-based platform in an office environment shows that our approach enables failure mitigation while maintaining the safety of the platform. The robot is shown to reach its goal in the presence of: 1) unpredicted control errors, 2) unexpected map errors and 3) a large injected localisation fault.</td>
</tr>
<tr id="bib_Peynot2013" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Peynot2013,
  author = {Peynot, Thierry and Fitch, Robert and McAllister, Rowan and Alempijevic, Alen},
  title = {Resilient Navigation through Probabilistic Modality Reconfiguration},
  booktitle = {Intelligent Autonomous Systems 12: Volume 2 Proceedings of the 12th International Conference IAS-12, held June 26-29, 2012, Jeju Island, Korea},
  publisher = {Springer Berlin Heidelberg},
  year = {2013},
  pages = {75--88},
  url = {http://dx.doi.org/10.1007/978-3-642-33932-5_8},
  doi = {http://dx.doi.org/10.1007/978-3-642-33932-5_8}
}
</pre></td>
</tr>
<tr id="pulido2016persistent" class="entry">
	<td>Pulido Fentanes, J., Krajnik, T., Hanheide, M., Duckett, T. and others</td>
	<td>Persistent localization and life-long mapping in changing environments using the frequency map enhancement <p class="infolinks">[<a href="javascript:toggleInfo('pulido2016persistent','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('pulido2016persistent','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_pulido2016persistent" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments. The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.</td>
</tr>
<tr id="bib_pulido2016persistent" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{pulido2016persistent,
  author = {Pulido Fentanes, Jaime and Krajnik, Tomas and Hanheide, Marc and Duckett, Tom and others},
  title = {Persistent localization and life-long mapping in changing environments using the frequency map enhancement},
  publisher = {IEEE},
  year = {2016}
}
</pre></td>
</tr>
<tr id="4770207" class="entry">
	<td>Rodrigo, R., Zouqi, M., Chen, Z. and Samarabandu, J.</td>
	<td>Robust and Efficient Feature Tracking for Indoor Navigation <p class="infolinks">[<a href="javascript:toggleInfo('4770207','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('4770207','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)<br/>Vol. 39(3), pp. 658-671&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/TSMCB.2008.2008196">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_4770207" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Robust feature tracking is a requirement for many computer vision tasks such as indoor robot navigation. However, indoor scenes are characterized by poorly localizable features. As a result, indoor feature tracking without artificial markers is challenging and remains an attractive problem. We propose to solve this problem by constraining the locations of a large number of nondistinctive features by several planar homographies which are strategically computed using distinctive features. We experimentally show the need for multiple homographies and propose an illumination-invariant local-optimization scheme for motion refinement. The use of a large number of nondistinctive features within the constraints imposed by planar homographies allows us to gain robustness. Also, the lesser computation cost in estimating these nondistinctive features helps to maintain the efficiency of the proposed method. Our local-optimization scheme produces subpixel accurate feature motion. As a result, we are able to achieve robust and accurate feature tracking.</td>
</tr>
<tr id="bib_4770207" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{4770207,
  author = {R. Rodrigo and M. Zouqi and Z. Chen and J. Samarabandu},
  title = {Robust and Efficient Feature Tracking for Indoor Navigation},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  year = {2009},
  volume = {39},
  number = {3},
  pages = {658-671},
  doi = {http://dx.doi.org/10.1109/TSMCB.2008.2008196}
}
</pre></td>
</tr>
<tr id="1642280" class="entry">
	<td>Sundvall, P. and Jensfelt, P.</td>
	<td>Fault detection for mobile robots using redundant positioning systems <p class="infolinks">[<a href="javascript:toggleInfo('1642280','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1642280','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006., pp. 3781-3786&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2006.1642280">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_1642280" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Reliable navigation is a very important part of an autonomous mobile robot system. This means for instance that the robot should not lose track of its position, even if unexpected events like wheel slip and collisions occur. The standard approach to this problem is to construct a navigation system that is robust in itself. This paper proposes that detecting faults can also be made outside the normal navigation system, as an additional fault detector. Besides increasing the robustness, a means for detecting deviations is obtained, which can be important for the rest of the robot system, for instance the top level planner. The method uses two or more sources of robot position estimates, and compares them to detect unexpected deviation without getting deceived by drift or different characteristics in the position systems it gets information from. Both relative and absolute position sources can be used, meaning that existing positioning systems already implemented can be used in the detector. For detection purposes, an extended Kalman filter is used in conjunction with a CUSUM test. The detector is able to not only detect faults, but also give an estimate of when the fault occurred, which is useful for doing fault recovery. The detector is easy to implement, as it requires no modification of existing systems. Also the computational demands are very low. The approach is implemented and demonstrated on a mobile robot, using odometry and a scan matcher as sources of position information. It is shown that the system is able to detect wheel slip in real-time</td>
</tr>
<tr id="bib_1642280" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1642280,
  author = {P. Sundvall and P. Jensfelt},
  title = {Fault detection for mobile robots using redundant positioning systems},
  booktitle = {Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.},
  year = {2006},
  pages = {3781-3786},
  doi = {http://dx.doi.org/10.1109/ROBOT.2006.1642280}
}
</pre></td>
</tr>
<tr id="Tipaldi:2013:LLC:2563656.2563657" class="entry">
	<td>Tipaldi, G.D., Meyer-Delius, D. and Burgard, W.</td>
	<td>Lifelong Localization in Changing Environments <p class="infolinks">[<a href="javascript:toggleInfo('Tipaldi:2013:LLC:2563656.2563657','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Tipaldi:2013:LLC:2563656.2563657','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Int. J. Rob. Res.<br/>Vol. 32(14), pp. 1662-1678&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1177/0278364913502830">DOI</a> <a href="http://dx.doi.org/10.1177/0278364913502830">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Tipaldi:2013:LLC:2563656.2563657" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Robot localization systems typically assume that the environment is static, ignoring the dynamics inherent in most real-world settings. Corresponding scenarios include households, offices, warehouses and parking lots, where the location of certain objects such as goods, furniture or cars can change over time. These changes typically lead to inconsistent observations with respect to previously learned maps and thus decrease the localization accuracy or even prevent the robot from globally localizing itself. In this paper we present a sound probabilistic approach to lifelong localization in changing environments using a combination of a Rao-Blackwellized particle filter with a hidden Markov model. By exploiting several properties of this model, we obtain a highly efficient map management approach for dynamic environments, which makes it feasible to run our algorithm online. Extensive experiments with a real robot in a dynamically changing environment demonstrate that our algorithm reliably adapts to changes in the environment and also outperforms the popular Monte-Carlo localization approach.</td>
</tr>
<tr id="bib_Tipaldi:2013:LLC:2563656.2563657" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Tipaldi:2013:LLC:2563656.2563657,
  author = {Tipaldi, Gian Diego and Meyer-Delius, Daniel and Burgard, Wolfram},
  title = {Lifelong Localization in Changing Environments},
  journal = {Int. J. Rob. Res.},
  publisher = {Sage Publications, Inc.},
  year = {2013},
  volume = {32},
  number = {14},
  pages = {1662--1678},
  url = {http://dx.doi.org/10.1177/0278364913502830},
  doi = {http://dx.doi.org/10.1177/0278364913502830}
}
</pre></td>
</tr>
<tr id="1389537" class="entry">
	<td>Tomono, M.</td>
	<td>Robust robot localization and map building using a global scan matching method <p class="infolinks">[<a href="javascript:toggleInfo('1389537','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1389537','bibtex')">BibTeX</a>]</p></td>
	<td>2004</td>
	<td><br/>Vol. 22004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), pp. 1059-1064 vol.2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2004.1389537">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_1389537" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper presents a global localization method in which the robot can relocalize itself when getting lost due to large slippage and kidnapping. In the proposed method, the robot generates pose hypotheses using a global scan matching method. The robot selects one hypothesis as the correct pose by filtering out false hypotheses using a multiple hypothesis tracking scheme. While the robot is tracking a single pose, the map is updated based on the SLAM framework. Experimental results show that the robot successfully localized itself robustly to disturbances including noises and kidnapping.</td>
</tr>
<tr id="bib_1389537" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1389537,
  author = {M. Tomono},
  title = {Robust robot localization and map building using a global scan matching method},
  booktitle = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)},
  year = {2004},
  volume = {2},
  pages = {1059-1064 vol.2},
  doi = {http://dx.doi.org/10.1109/IROS.2004.1389537}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 26/02/2017.</small>
</footer>
<!-- file generated by JabRef -->
</body>
</html>