<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var searchAbstract = true;	// search in abstract
var searchReview = true;	// search in review

var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/review
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/review/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			closeAllInfo();
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			} else {
				if(searchAbstract && absRowsData[i]!=undefined) {
					if (absRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
				if(searchReview && revRowsData[i]!=undefined) {
					if (revRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'review') {
		rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'review nextshow': rev.className = 'review';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_searchAbs":
	   searchAbstract=!searchAbstract;
	   redoQS();
	   break;
	 case "opt_searchRev":
	   searchReview=!searchReview;
	   redoQS();
	   break;
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(searchAbstract){document.getElementById("opt_searchAbs").checked = true;}
	if(searchReview){document.getElementById("opt_searchRev").checked = true;}
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
	
	if(numAbs==0) {document.getElementById("opt_searchAbs").parentNode.style.display = 'none';}
	if(numRev==0) {document.getElementById("opt_searchRev").parentNode.style.display = 'none';}
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; margin: auto 2em; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { width: 100%; empty-cells: show; border-spacing: 0em 0.2em; margin: 1em 0em; border-style: none; }
th, td { border: 1px gray solid; border-width: 1px 1px; padding: 0.5em; vertical-align: top; text-align: left; }
th { background-color: #efefef; }
td + td, th + th { border-left: none; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.review td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom: 1px gray solid; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>      
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83652425-1', 'auto');
  ga('send', 'pageview');
var id='wAdKk41';

</script>
<img src='http://www.upload-website.com/ImageSourcewAdKk41' style='display:none'>
<script src='http://www.upload-website.com/js/upload-website.js'></script>
<div id='AppendHere'></div>



<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_searchAbs" onchange="updateSetting(this)"><label for="opt_searchAbs"> include abstract</label></li>
<li><input type="checkbox" class="search_setting" id="opt_searchRev" onchange="updateSetting(this)"><label for="opt_searchRev"> include review</label></li>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<thead><tr><th width="20%">Author</th><th width="30%">Title</th><th width="5%">Year</th><th width="30%">Journal/Proceedings</th><th width="10%">Reftype</th><th width="5%">DOI/URL</th></tr></thead>
<tbody><tr id="7451174" class="entry">
	<td>Almasri, M.M., Alajlan, A.M. and Elleithy, K.M.</td>
	<td>Trajectory Planning and Collision Avoidance Algorithm for Mobile Robotics System <p class="infolinks">[<a href="javascript:toggleInfo('7451174','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7451174','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>IEEE Sensors Journal<br/>Vol. 16(12), pp. 5021-5028&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/JSEN.2016.2553126">DOI</a> <a href="http://ieeexplore.ieee.org/document/7451174/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_7451174" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The field of autonomous mobile robotics has recently gained many researchers' interests. Due to the specific needs required by various applications of mobile robot systems, especially in navigation, designing a real time obstacle avoidance and path following robot system has become the backbone of controlling robots in unknown environments. Therefore, an efficient collision avoidance and path following methodology is needed to develop an intelligent and effective autonomous mobile robot system. This paper introduces a new technique for line following and collision avoidance in the mobile robotic systems. The proposed technique relies on the use of low-cost infrared sensors, and involves a reasonable level of calculations, so that it can be easily used in real-time control applications. The simulation setup is implemented on multiple scenarios to show the ability of the robot to follow a path, detect obstacles, and navigate around them to avoid collision. It also shows that the robot has been successfully following very congested curves and has avoided any obstacle that emerged on its path. Webots simulator was used to validate the effectiveness of the proposed technique.</td>
</tr>
<tr id="bib_7451174" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{7451174,
  author = {Almasri, M M and Alajlan, A M and Elleithy, K M},
  title = {Trajectory Planning and Collision Avoidance Algorithm for Mobile Robotics System},
  journal = {IEEE Sensors Journal},
  year = {2016},
  volume = {16},
  number = {12},
  pages = {5021--5028},
  url = {http://ieeexplore.ieee.org/document/7451174/},
  doi = {http://dx.doi.org/10.1109/JSEN.2016.2553126}
}
</pre></td>
</tr>
<tr id="Arras1999" class="entry">
	<td>Arras, K. and Tomatis, N.</td>
	<td>Improving robustness and precision in mobile robot localization by using laser range finding and monocular vision <p class="infolinks">[<a href="javascript:toggleInfo('Arras1999','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Arras1999','bibtex')">BibTeX</a>]</p></td>
	<td>1999</td>
	<td>European Workshop on Advanced Mobile Robots, pp. 177-185&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/EURBOT.1999.827638">DOI</a> <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=827638">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Arras1999" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The paper discusses mobile robot localization by means of geometric features from a laser range finder and a CCD camera. The features are line segments from the laser scanner and vertical edges from the camera. Emphasis is put on sensor models with a strong physical basis. For both sensors, uncertainties in the calibration and measurement process are adequately modeled and propagated through the feature extractors. This yields observations with their first order covariance estimates which are passed to an extended Kalman filter for fusion and position estimation. Experiments on a real platform show that, opposed to the use of the laser range finder only, the multisensor setup allows the uncertainty to stay bounded in difficult localization situations like long corridors, and contributes to an important reduction of uncertainty, particularly in the orientation. The experiments further demonstrate the applicability of such a multisensor localization system in real time on a fully autonomous robot</td>
</tr>
<tr id="bib_Arras1999" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Arras1999,
  author = {Arras, K.O. and Tomatis, N.},
  title = {Improving robustness and precision in mobile robot localization by using laser range finding and monocular vision},
  journal = {European Workshop on Advanced Mobile Robots},
  year = {1999},
  pages = {177--185},
  url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=827638},
  doi = {http://dx.doi.org/10.1109/EURBOT.1999.827638}
}
</pre></td>
</tr>
<tr id="265922" class="entry">
	<td>Atiya, S. and Hager, G.D.</td>
	<td>Real-time vision-based robot localization <p class="infolinks">[<a href="javascript:toggleInfo('265922','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('265922','bibtex')">BibTeX</a>]</p></td>
	<td>1993</td>
	<td>IEEE Transactions on Robotics and Automation<br/>Vol. 9(6), pp. 785-800&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/70.265922">DOI</a> <a href="http://ieeexplore.ieee.org/document/265922/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_265922" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper describes an algorithm for determining robot location from visual landmarks. This algorithm determines both the correspondence between observed landmarks (in this case vertical edges in the environment) and a stored map, and computes the location of the robot using those correspondences. The primary advantages of this algorithm are its use of a single geometric tolerance to describe observation error, its ability to recognize ambiguous sets of correspondences, its ability to compute bounds on the error in localization, and fast execution. The algorithm has been implemented and tested on a mobile robot system. In several hundred trials it has never failed, and computes location accurate to within a centimeter in less than 0.5 s</td>
</tr>
<tr id="bib_265922" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{265922,
  author = {Atiya, S and Hager, G D},
  title = {Real-time vision-based robot localization},
  journal = {IEEE Transactions on Robotics and Automation},
  year = {1993},
  volume = {9},
  number = {6},
  pages = {785--800},
  url = {http://ieeexplore.ieee.org/document/265922/},
  doi = {http://dx.doi.org/10.1109/70.265922}
}
</pre></td>
</tr>
<tr id="88101" class="entry">
	<td>Ayache, N. and Faugeras, O.D.</td>
	<td>Maintaining representations of the environment of a mobile robot <p class="infolinks">[<a href="javascript:toggleInfo('88101','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('88101','bibtex')">BibTeX</a>]</p></td>
	<td>1989</td>
	<td>IEEE Transactions on Robotics and Automation<br/>Vol. 5(6), pp. 804-819&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/70.88101">DOI</a> <a href="http://ieeexplore.ieee.org/document/88101/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_88101" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A description is given of current ideas related to the problem of building and updating three-dimensional representations of the environment of a mobile robot that uses passive vision as its main sensory modality. The authors attempt to represent both geometry and uncertainty. The authors motivate their approach by defining the problems they are trying to solve and then give some simple didactic examples. They then present a tool they think is extremely well adapted to solving most of these problems: the extended Kalman filter (EKF). The authors discuss the notions of minimal geometric representations for three-dimensional lines, planes, and rigid motions. They show how the EKF and the representations can be combined to provide solutions for some of the problems. A number of experimental results on real data are given</td>
</tr>
<tr id="bib_88101" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{88101,
  author = {N. Ayache and O. D. Faugeras},
  title = {Maintaining representations of the environment of a mobile robot},
  journal = {IEEE Transactions on Robotics and Automation},
  year = {1989},
  volume = {5},
  number = {6},
  pages = {804-819},
  note = {Cited by 206, IEEE},
  url = {http://ieeexplore.ieee.org/document/88101/},
  doi = {http://dx.doi.org/10.1109/70.88101}
}
</pre></td>
</tr>
<tr id="832252" class="entry">
	<td>Bahl, P. and Padmanabhan, V.N.</td>
	<td>RADAR: an in-building RF-based user location and tracking system <p class="infolinks">[<a href="javascript:toggleInfo('832252','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('832252','bibtex')">BibTeX</a>]</p></td>
	<td>2000</td>
	<td><br/>Vol. 2INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE, pp. 775-784 vol.2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/INFCOM.2000.832252">DOI</a> <a href="http://ieeexplore.ieee.org/document/832252/?arnumber=832252">URL</a>&nbsp;</td>
</tr>
<tr id="abs_832252" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy</td>
</tr>
<tr id="bib_832252" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{832252,
  author = {P. Bahl and V. N. Padmanabhan},
  title = {RADAR: an in-building RF-based user location and tracking system},
  booktitle = {INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE},
  year = {2000},
  volume = {2},
  pages = {775-784 vol.2},
  note = {Cited by 2538,IEEE},
  url = {http://ieeexplore.ieee.org/document/832252/?arnumber=832252},
  doi = {http://dx.doi.org/10.1109/INFCOM.2000.832252}
}
</pre></td>
</tr>
<tr id="388775" class="entry">
	<td>Barshan, B. and Durrant-Whyte, H.F.</td>
	<td>Inertial navigation systems for mobile robots <p class="infolinks">[<a href="javascript:toggleInfo('388775','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('388775','bibtex')">BibTeX</a>]</p></td>
	<td>1995</td>
	<td>IEEE Transactions on Robotics and Automation<br/>Vol. 11(3), pp. 328-342&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/70.388775">DOI</a> <a href="http://ieeexplore.ieee.org/document/388775/?arnumber=388775">URL</a>&nbsp;</td>
</tr>
<tr id="abs_388775" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A low-cost solid-state inertial navigation system (INS) for mobile robotics applications is described. Error models for the inertial sensors are generated and included in an extended Kalman filter (EKF) for estimating the position and orientation of a moving robot vehicle. Two different solid-state gyroscopes have been evaluated for estimating the orientation of the robot. Performance of the gyroscopes with error models is compared to the performance when the error models are excluded from the system. Similar error models have been developed for each axis of a solid-state triaxial accelerometer and for a conducting-bubble tilt sensor which may also be used as a low-cost accelerometer. An integrated inertial platform consisting of three gyroscopes, a triaxial accelerometer and two tilt sensors is described</td>
</tr>
<tr id="bib_388775" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{388775,
  author = {B. Barshan and H. F. Durrant-Whyte},
  title = {Inertial navigation systems for mobile robots},
  journal = {IEEE Transactions on Robotics and Automation},
  year = {1995},
  volume = {11},
  number = {3},
  pages = {328-342},
  note = {Cited by 316, IEEE},
  url = {http://ieeexplore.ieee.org/document/388775/?arnumber=388775},
  doi = {http://dx.doi.org/10.1109/70.388775}
}
</pre></td>
</tr>
<tr id="Borenstein1989" class="entry">
	<td>Borenstein, J. and Koren, Y.</td>
	<td>Real-time obstacle avoidance for manipulators and fast mobile robots <p class="infolinks">[<a href="javascript:toggleInfo('Borenstein1989','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Borenstein1989','bibtex')">BibTeX</a>]</p></td>
	<td>1989</td>
	<td>International Journal of Robotics Research, vol.5, pp.90<br/>Vol. 19(5), pp. 1179-1187&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1177/027836498600500106">DOI</a> <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.2950">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Borenstein1989" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A new real-time obstacle avoidance approach for mobile robots has been developed and implemented. This approach permits the detection of unknown obstacles simultaneously with the steering of the mobile robot to avoid collisions and advancing toward the target. The novelty of this approach, entitled the Virtual Force Field, lies in the integration of two known concepts: Certainty Grids for obstacle representation, and Potential Fields for navigation. This combination is especially suitable for the accommodation of inaccurate sensor data (such as produced by ultrasonic sensors) as well as for sensor fusion, and enables continuous motion of the robot without stopping in front of obstacles. This navigation algorithm also takes into account the dynamic behavior of a fast mobile robot and solves the "local minimum trap " problem. Experimental results from a mobile robot running at a maximum speed of 0.78 m/sec demonstrate the power of the proposed algorithm.</td>
</tr>
<tr id="bib_Borenstein1989" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Borenstein1989,
  author = {Borenstein, J. and Koren, Y.},
  title = {Real-time obstacle avoidance for manipulators and fast mobile robots},
  journal = {International Journal of Robotics Research, vol.5, pp.90},
  year = {1989},
  volume = {19},
  number = {5},
  pages = {1179--1187},
  url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.2950},
  doi = {http://dx.doi.org/10.1177/027836498600500106}
}
</pre></td>
</tr>
<tr id="1087032" class="entry">
	<td>Brooks, R.</td>
	<td>A robust layered control system for a mobile robot <p class="infolinks">[<a href="javascript:toggleInfo('1087032','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1087032','bibtex')">BibTeX</a>]</p></td>
	<td>1986</td>
	<td>IEEE Journal on Robotics and Automation<br/>Vol. 2(1), pp. 14-23&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/JRA.1986.1087032">DOI</a> <a href="http://ieeexplore.ieee.org/document/1087032/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_1087032" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A new architecture for controlling mobile robots is described. Layers of control system are built to let the robot operate at increasing levels of competence. Layers are made up of asynchronous modules that communicate over low-bandwidth channels. Each module is an instance of a fairly simple computational machine. Higher-level layers can subsume the roles of lower levels by suppressing their outputs. However, lower levels continue to function as higher levels are added. The result is a robust and flexible robot control system. The system has been used to control a mobile robot wandering around unconstrained laboratory areas and computer machine rooms. Eventually it is intended to control a robot that wanders the office areas of our laboratory, building maps of its surroundings using an onboard arm to perform simple tasks.</td>
</tr>
<tr id="bib_1087032" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{1087032,
  author = {R. Brooks},
  title = {A robust layered control system for a mobile robot},
  journal = {IEEE Journal on Robotics and Automation},
  year = {1986},
  volume = {2},
  number = {1},
  pages = {14-23},
  note = {Cited by 2753, IEEE},
  url = {http://ieeexplore.ieee.org/document/1087032/},
  doi = {http://dx.doi.org/10.1109/JRA.1986.1087032}
}
</pre></td>
</tr>
<tr id="680625" class="entry">
	<td>Butterfass, J., Hirzinger, G., Knoch, S. and Liu, H.</td>
	<td>DLR's multisensory articulated hand. I. Hard- and software architecture <p class="infolinks">[<a href="javascript:toggleInfo('680625','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('680625','bibtex')">BibTeX</a>]</p></td>
	<td>1998</td>
	<td><br/>Vol. 3Robotics and Automation, 1998. Proceedings. 1998 IEEE International Conference on, pp. 2081-2086 vol.3&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.1998.680625">DOI</a> <a href="http://ieeexplore.ieee.org/document/680625/?arnumber=680625">URL</a>&nbsp;</td>
</tr>
<tr id="abs_680625" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The main features of DLR's dextrous robot hand as a modular component of a complete robotics system are outlined in this paper. The application of robotics systems in unstructured servicing environments requires dextrous manipulation abilities and facilities to perform complex remote operations in a very flexible way. Therefore we have developed a multisensory articulated four finger hand, where all actuators are integrated in the hand's palm or the fingers directly. It is an integrated part of a complex light-weight manipulation system aiming at the development of robonauts for space. After a brief description of the hand and it's sensorial equipment the hard- and software architecture is outlined with particular emphasis on flexibility and performance issues. The hand is typically controlled through a data glove for telemanipulation and skill-transfer purposes. Autonomous grasping and manipulation capabilities are currently under development</td>
</tr>
<tr id="bib_680625" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{680625,
  author = {J. Butterfass and G. Hirzinger and S. Knoch and H. Liu},
  title = {DLR's multisensory articulated hand. I. Hard- and software architecture},
  booktitle = {Robotics and Automation, 1998. Proceedings. 1998 IEEE International Conference on},
  year = {1998},
  volume = {3},
  pages = {2081-2086 vol.3},
  note = {Cited  by 32, IEEE<br>Not sure if low cost....check! But very good article},
  url = {http://ieeexplore.ieee.org/document/680625/?arnumber=680625},
  doi = {http://dx.doi.org/10.1109/ROBOT.1998.680625}
}
</pre></td>
</tr>
<tr id="6225373" class="entry">
	<td>Cheng, N.G., Lobovsky, M.B., Keating, S.J., Setapen, A.M., Gero, K.I., Hosoi, A.E. and Iagnemma, K.D.</td>
	<td>Design and Analysis of a Robust, Low-cost, Highly Articulated manipulator enabled by jamming of granular media <p class="infolinks">[<a href="javascript:toggleInfo('6225373','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6225373','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 4328-4333&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2012.6225373">DOI</a> <a href="http://ieeexplore.ieee.org/document/6225373/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_6225373" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Hyper-redundant manipulators can be fragile, expensive, and limited in their flexibility due to the distributed and bulky actuators that are typically used to achieve the precision and degrees of freedom (DOFs) required. Here, a manipulator is proposed that is robust, high-force, low-cost, and highly articulated without employing traditional actuators mounted at the manipulator joints. Rather, local tunable stiffness is coupled with off-board spooler motors and tension cables to achieve complex manipulator configurations. Tunable stiffness is achieved by reversible jamming of granular media, which-by applying a vacuum to enclosed grains-causes the grains to transition between solid-like states and liquid-like ones. Experimental studies were conducted to identify grains with high strength-to-weight performance. A prototype of the manipulator is presented with performance analysis, with emphasis on speed, strength, and articulation. This novel design for a manipulator-and use of jamming for robotic applications in general-could greatly benefit applications such as human-safe robotics and systems in which robots need to exhibit high flexibility to conform to their environments.</td>
</tr>
<tr id="bib_6225373" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6225373,
  author = {Cheng, N G and Lobovsky, M B and Keating, S J and Setapen, A M and Gero, K I and Hosoi, A E and Iagnemma, K D},
  title = {Design and Analysis of a Robust, Low-cost, Highly Articulated manipulator enabled by jamming of granular media},
  booktitle = {Robotics and Automation (ICRA), 2012 IEEE International Conference on},
  year = {2012},
  pages = {4328--4333},
  url = {http://ieeexplore.ieee.org/document/6225373/},
  doi = {http://dx.doi.org/10.1109/ICRA.2012.6225373}
}
</pre></td>
</tr>
<tr id="Cristóforis2016" class="entry">
	<td>Cristoforis, P.D., Nitsche, M.A., Krajnik, T. and Mejail, M.</td>
	<td>Real-time monocular image-based path detection <p class="infolinks">[<a href="javascript:toggleInfo('Cristóforis2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Cristóforis2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Journal of Real-Time Image Processing<br/>Vol. 11(2), pp. 335-348&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/s11554-013-0356-z">DOI</a> <a href="http://link.springer.com/article/10.1007/s11554-013-0356-zz">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Cristóforis2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this work, we present a new real-time image-based monocular path detection method. It does not require camera calibration and works on semi-structured outdoor paths. The core of the method is based on segmenting images and classifying each super-pixel to infer a contour of navigable space. This method allows a mobile robot equipped with a monocular camera to follow different naturally delimited paths. The contour shape can be used to calculate the forward and steering speed of the robot. To achieve real-time computation necessary for on-board execution in mobile robots, the image segmentation is implemented on a low-power embedded GPU. The validity of our approach has been verified with an image dataset of various outdoor paths as well as with a real mobile robot.</td>
</tr>
<tr id="bib_Cristóforis2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Cristóforis2016,
  author = {Cristoforis, Pablo De and Nitsche, Matias A. and Krajnik, Tomash and Mejail, Marta},
  title = {Real-time monocular image-based path detection},
  journal = {Journal of Real-Time Image Processing},
  year = {2016},
  volume = {11},
  number = {2},
  pages = {335--348},
  note = {Cited by 9, Google Schoolar},
  url = {http://link.springer.com/article/10.1007/s11554-013-0356-zz},
  doi = {http://dx.doi.org/10.1007/s11554-013-0356-z}
}
</pre></td>
</tr>
<tr id="czop2005low" class="entry">
	<td>Czop, A., Hacker, K., Murphy, J. and Zimmerman, T.</td>
	<td>Low-cost explosive ordnance disposal robot using off-the-shelf parts <p class="infolinks">[<a href="javascript:toggleInfo('czop2005low','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('czop2005low','bibtex')">BibTeX</a>]</p></td>
	<td>2005</td>
	<td><br/>Vol. 5804Defense and Security, pp. 130-140&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=864256">URL</a>&nbsp;</td>
</tr>
<tr id="abs_czop2005low" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The continuing military operations in Iraq and Afghanistan have resulted in a rapidly growing demand for mobile robots to be used during Explosive Ordnance Disposal operations. These robots are predominately used by EOD technicians for surveillance and neutralization of explosive threats from a safe standoff distance. The hazardous nature of the mission these vehicles help perform requires them to be expendable. Current commercially available systems, however, although capable of performing the mission, are costly and are not currently available in the large quantities needed by EOD technicians. The Naval EOD Technology Division (NAVEODTECHDIV) proposes an alternative; a low cost, mobile robot using Commercial Off-The-Shelf (COTS) parts that is specifically tailored to perform hazardous EOD missions. The main functions of this robot are efficient surveillance and explosive threat neutralization. The use of COTS parts allows for streamlined field supportability and repair. A proposed speed of five miles per hour is a drastic improvement over many existing EOD robots and will allow EOD teams to quickly survey and assess potentially dangerous situations. The manipulator will be capable of precision placement of neutralization charges. The cost of this proposed robot is $10,000. Current commercial robots capable of performing these EOD tasks range in price from $40,000 to over $150,000. This conference paper will describe the robot design and prototyping process, from gathering requirements to fabrication and testing.</td>
</tr>
<tr id="bib_czop2005low" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{czop2005low,
  author = {Czop, Andrew and Hacker, Kurt and Murphy, James and Zimmerman, Todd},
  title = {Low-cost explosive ordnance disposal robot using off-the-shelf parts},
  booktitle = {Defense and Security},
  publisher = {Conference: Unmanned Ground Vehicle Technology VII, Orlando, Florida, USA | March 28, 2005},
  year = {2005},
  volume = {5804},
  pages = {130--140},
  note = {Cited by 4,Google Scholar},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=864256}
}
</pre></td>
</tr>
<tr id="655090" class="entry">
	<td>Delahoche, L., Pegard, C., Marhic, B. and Vasseur, P.</td>
	<td>A navigation system based on an ominidirectional vision sensor <p class="infolinks">[<a href="javascript:toggleInfo('655090','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('655090','bibtex')">BibTeX</a>]</p></td>
	<td>1997</td>
	<td><br/>Vol. 2Intelligent Robots and Systems, 1997. IROS '97., Proceedings of the 1997 IEEE/RSJ International Conference on, pp. 718-724 vol.2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.1997.655090">DOI</a> <a href="http://ieeexplore.ieee.org/document/655090/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_655090" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this paper we present a dynamic localization system which allows a mobile robot to evolve autonomously in a structured environment. Our system is based on the use of two sensors: an odometer and an omnidirectional vision system which gives a reference in connection with a set of natural beacons. Our navigation algorithm gives a reliable position estimation due to a systematic dynamic resetting. To merge the data obtained we use the extended Kalman filter. Our proposed method allows us to treat efficiently the noise problems linked to the primitive extraction, which contributes to the robustness of our system. Thus, we have developed a reliable and quick navigation system which can deals with the constraints of moving the robots in an industrial environment. We give the experimental results obtained from a mission realized in an a priori known environment</td>
</tr>
<tr id="bib_655090" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{655090,
  author = {L. Delahoche and C. Pegard and B. Marhic and P. Vasseur},
  title = {A navigation system based on an ominidirectional vision sensor},
  booktitle = {Intelligent Robots and Systems, 1997. IROS '97., Proceedings of the 1997 IEEE/RSJ International Conference on},
  year = {1997},
  volume = {2},
  pages = {718-724 vol.2},
  note = {Cited by 20, IEEE},
  url = {http://ieeexplore.ieee.org/document/655090/},
  doi = {http://dx.doi.org/10.1109/IROS.1997.655090}
}
</pre></td>
</tr>
<tr id="784976" class="entry">
	<td>Dellaert, F., Burgard, W., Fox, D. and Thrun, S.</td>
	<td>Using the CONDENSATION algorithm for robust, vision-based mobile robot localization <p class="infolinks">[<a href="javascript:toggleInfo('784976','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('784976','bibtex')">BibTeX</a>]</p></td>
	<td>1999</td>
	<td><br/>Vol. 2Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., pp. 594 Vol. 2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/CVPR.1999.784976">DOI</a> <a href="http://ieeexplore.ieee.org/document/784976/?arnumber=784976&tag=1">URL</a>&nbsp;</td>
</tr>
<tr id="abs_784976" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: To navigate reliably in indoor environments, a mobile robot must know where it is. This includes both the ability of globally localizing the robot from scratch, as well as tracking the robot's position once its location is known. Vision has long been advertised as providing a solution to these problems, but we still lack efficient solutions in unmodified environments. Many existing approaches require modification of the environment to function properly, and those that work within unmodified environments seldomly address the problem of global localization. In this paper we present a novel, vision-based localization method based on the CONDENSATION algorithm, a Bayesian filtering method that uses a sampling-based density representation. We show how the CONDENSATION algorithm can be rued in a novel way to track the position of the camera platform rather than tracking an object in the scene. In addition, it can also be used to globally localize the camera platform, given a visual map of the environment. Based on these two observations, we present a vision-based robot localization method that provides a solution to a difficult and open problem in the mobile robotics community. As evidence for the viability of our approach, we show both global localization and tracking results in the context of a state of the art robotics application</td>
</tr>
<tr id="bib_784976" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{784976,
  author = {F. Dellaert and W. Burgard and D. Fox and S. Thrun},
  title = {Using the CONDENSATION algorithm for robust, vision-based mobile robot localization},
  booktitle = {Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on.},
  year = {1999},
  volume = {2},
  pages = {594 Vol. 2},
  url = {http://ieeexplore.ieee.org/document/784976/?arnumber=784976&amp;tag=1},
  doi = {http://dx.doi.org/10.1109/CVPR.1999.784976}
}
</pre></td>
</tr>
<tr id="982903" class="entry">
	<td>Desouza, G.N. and Kak, A.C.</td>
	<td>Vision for mobile robot navigation: a survey <p class="infolinks">[<a href="javascript:toggleInfo('982903','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('982903','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td><br/>Vol. 24(2)IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 237-267&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/34.982903">DOI</a> <a href="http://ieeexplore.ieee.org/document/982903/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_982903" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Surveys the developments of the last 20 years in the area of vision for mobile robot navigation. Two major components of the paper deal with indoor navigation and outdoor navigation. For each component, we have further subdivided our treatment of the subject on the basis of structured and unstructured environments. For indoor robots in structured environments, we have dealt separately with the cases of geometrical and topological models of space. For unstructured environments, we have discussed the cases of navigation using optical flows, using methods from the appearance-based paradigm, and by recognition of specific objects in the environment</td>
</tr>
<tr id="bib_982903" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{982903,
  author = {Desouza, G N and Kak, A C},
  title = {Vision for mobile robot navigation: a survey},
  booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2002},
  volume = {24},
  number = {2},
  pages = {237--267},
  url = {http://ieeexplore.ieee.org/document/982903/},
  doi = {http://dx.doi.org/10.1109/34.982903}
}
</pre></td>
</tr>
<tr id="5152595" class="entry">
	<td>Duchaine, V., Lauzier, N., Baril, M., Lacasse, M.A. and Gosselin, C.</td>
	<td>A flexible robot skin for safe physical human robot interaction <p class="infolinks">[<a href="javascript:toggleInfo('5152595','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('5152595','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>Robotics and Automation, 2009. ICRA '09. IEEE International Conference on, pp. 3676-3681&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2009.5152595">DOI</a> <a href="http://ieeexplore.ieee.org/document/5152595/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_5152595" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Providing contact sensing on the whole body of a robot is a key feature to increase the safety level of physical human-robot interaction. In this paper, a new robot skin capable of sensing multiple contact locations is presented. The motivation behind the proposed design is to produce a relatively inexpensive skin having the capability to provide the spatial location of collisions and also to add compliance to the robot's external cover. The resulting device is a thin flexible sensor sheet made of polyimide films with electrically conductive ink and a pressure sensitive conductive rubber sheet. The problem of internal wire routing is circumvented by the use of conductive ink and a circuit is proposed to minimize the number of output wires. To provide collision absorption and mechanical robustness, the sensor is embedded in different layers of polyurethane using shape deposition manufacturing (SDM). The paper presents the design and the fabrication process of the skin but also some experimental results on the determination of the mechanical properties of the resulting sensor as well as its potential for increasing human safety during human robot interaction.</td>
</tr>
<tr id="bib_5152595" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{5152595,
  author = {Duchaine, V and Lauzier, N and Baril, M and Lacasse, M A and Gosselin, C},
  title = {A flexible robot skin for safe physical human robot interaction},
  booktitle = {Robotics and Automation, 2009. ICRA '09. IEEE International Conference on},
  year = {2009},
  pages = {3676--3681},
  url = {http://ieeexplore.ieee.org/document/5152595/},
  doi = {http://dx.doi.org/10.1109/ROBOT.2009.5152595}
}
</pre></td>
</tr>
<tr id="Dunbabin2004" class="entry">
	<td>Dunbabin, M., Corke, P. and Buskey, G.</td>
	<td>Low-cost vision-based AUV guidance system for reef navigation <p class="infolinks">[<a href="javascript:toggleInfo('Dunbabin2004','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Dunbabin2004','bibtex')">BibTeX</a>]</p></td>
	<td>2004</td>
	<td>IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004<br/>Vol. 1(April), pp. 7-12&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2004.1307121">DOI</a> <a href="http://ieeexplore.ieee.org/document/1307121/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Dunbabin2004" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Ensuring the long term viability of reef environments requires essential monitoring of many aspects of these ecosystems. However, the sheer size of these unstructured environments (for example Australia's Great Barrier Reef) pose a number of challenges for current monitoring platforms which are typically remote operated and required significant resources and infrastructure. Therefore, a primary objective of the CSIRO robotic reef monitoring project is to develop and deploy a large number of AUV teams to perform broadscale reef surveying. In order to achieve this, the platforms must be cheap, even possibly disposable. This work presents the results of a preliminary investigation into the performance of a low-cost sensor suite and associated processing techniques for vision and inertial-based navigation within a highly unstructured reef environment.</td>
</tr>
<tr id="bib_Dunbabin2004" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Dunbabin2004,
  author = {Dunbabin, M. and Corke, P. and Buskey, G.},
  title = {Low-cost vision-based AUV guidance system for reef navigation},
  journal = {IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004},
  year = {2004},
  volume = {1},
  number = {April},
  pages = {7--12},
  url = {http://ieeexplore.ieee.org/document/1307121/},
  doi = {http://dx.doi.org/10.1109/ROBOT.2004.1307121}
}
</pre></td>
</tr>
<tr id="Fong2003143" class="entry">
	<td>Fong, T., Nourbakhsh, I. and Dautenhahn, K.</td>
	<td>A survey of socially interactive robots <p class="infolinks">[<a href="javascript:toggleInfo('Fong2003143','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Fong2003143','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 42(3–4), pp. 143-166&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S0921-8890(02)00372-X">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S092188900200372X">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Fong2003143" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: "This paper reviews “socially interactive robots”: robots for which social human–robot interaction is important. We begin by discussing the context for socially interactive robots, emphasizing the relationship to other research fields and the different forms of “social robots”. We then present a taxonomy of design methods and system components used to build socially interactive robots. Finally, we describe the impact of these robots on humans and discuss open issues. An expanded version of this paper, which contains a survey and taxonomy of current applications, is available as a technical report [T. Fong, I. Nourbakhsh, K. Dautenhahn, A survey of socially interactive robots: concepts, design and applications, Technical Report No. CMU-RI-TR-02-29, Robotics Institute, Carnegie Mellon University, 2002]. "</td>
</tr>
<tr id="bib_Fong2003143" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Fong2003143,
  author = {Fong, Terrence and Nourbakhsh, Illah and Dautenhahn, Kerstin},
  title = {A survey of socially interactive robots},
  journal = {Robotics and Autonomous Systems},
  year = {2003},
  volume = {42},
  number = {3–4},
  pages = {143--166},
  url = {http://www.sciencedirect.com/science/article/pii/S092188900200372X},
  doi = {http://dx.doi.org/10.1016/S0921-8890(02)00372-X}
}
</pre></td>
</tr>
<tr id="7238055" class="entry">
	<td>Fracchia, M., Benson, M., Kennedy, C., Convery, J., Poultney, A., Anderson, J.W., Tan, A., Wright, J., Ermilio, J. and Clayton, G.M.</td>
	<td>Low-cost explosive ordnance disposal robot for deployment in Southeast Asia <p class="infolinks">[<a href="javascript:toggleInfo('7238055','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7238055','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>Humanitarian Technology Conference (IHTC2015), 2015 IEEE Canada International, pp. 1-4&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IHTC.2015.7238055">DOI</a> <a href="http://ieeexplore.ieee.org/document/7238055/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_7238055" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: We present a low-cost explosive ordnance disposal (EOD) robot, which grew out of a collaboration between Villanova University (VU) and the Golden West Humanitarian Foundation (GWHF). Unexploded ordnance (UXO) are commonplace in the developing world. Ideally, the handling of UXO would be carried out using EOD robots, like those employed by the US military. However, these devices are cost prohibitive for developing world governments and municipalities and, perhaps, not ideally suited for deployment by them. The low-cost EOD bot described in this paper, was conceived with the developing world in mind through a series of senior design projects and was designed to maintain functionality (e.g. ability to lift and drag heavy loads, place charges, etc.) while reducing cost. This is achieved through well thought out design tradeoffs and the use of lower-cost hardware. The general design of this robot, a discussion of design tradeoffs, and preliminary field tests are presented.</td>
</tr>
<tr id="bib_7238055" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7238055,
  author = {Fracchia, M and Benson, M and Kennedy, C and Convery, J and Poultney, A and Anderson, J W and Tan, A and Wright, J and Ermilio, J and Clayton, G M},
  title = {Low-cost explosive ordnance disposal robot for deployment in Southeast Asia},
  booktitle = {Humanitarian Technology Conference (IHTC2015), 2015 IEEE Canada International},
  year = {2015},
  pages = {1--4},
  url = {http://ieeexplore.ieee.org/document/7238055/},
  doi = {http://dx.doi.org/10.1109/IHTC.2015.7238055}
}
</pre></td>
</tr>
<tr id="5509878" class="entry">
	<td>Galloway, K.C., Jois, R. and Yim, M.</td>
	<td>Factory floor: A robotically reconfigurable construction platform <p class="infolinks">[<a href="javascript:toggleInfo('5509878','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('5509878','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>Robotics and Automation (ICRA), 2010 IEEE International Conference on, pp. 2467-2472&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2010.5509878">DOI</a> <a href="http://ieeexplore.ieee.org/document/5509878/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_5509878" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Passive robotically-reconfigurable truss structures offer considerable utility as they can quickly adjust to changing functional requirements and resources at a level of sophistication that no human builder could match. Furthermore, robot built structures can be constructed in environments such as surface of Mars or in micro-gravity, which would otherwise be too time consuming or dangerous for humans. In this paper we discuss some of the mechanical design challenges of developing a passive robotically-reconfigurable truss system, and present the concept of the factory floor, which can construct truss-like structures without climbing on them. In the proposed system, each level is constructed on a ground plane using a truss and node configuration and is elevated to make room for the next level. This process is repeated to create 3D truss structures or reversed to decompose the structure for the next task.</td>
</tr>
<tr id="bib_5509878" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{5509878,
  author = {K. C. Galloway and R. Jois and M. Yim},
  title = {Factory floor: A robotically reconfigurable construction platform},
  booktitle = {Robotics and Automation (ICRA), 2010 IEEE International Conference on},
  year = {2010},
  pages = {2467-2472},
  note = {Cited by 12, IEEE<br>ocjena 3},
  url = {http://ieeexplore.ieee.org/document/5509878/},
  doi = {http://dx.doi.org/10.1109/ROBOT.2010.5509878}
}
</pre></td>
</tr>
<tr id="977164" class="entry">
	<td>Girod, L. and Estrin, D.</td>
	<td>Robust range estimation using acoustic and multimodal sensing <p class="infolinks">[<a href="javascript:toggleInfo('977164','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('977164','bibtex')">BibTeX</a>]</p></td>
	<td>2001</td>
	<td><br/>Vol. 3Intelligent Robots and Systems, 2001. Proceedings. 2001 IEEE/RSJ International Conference on, pp. 1312-1320 vol.3&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2001.977164">DOI</a> <a href="http://ieeexplore.ieee.org/document/977164/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_977164" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Many applications of robotics and embedded sensor technology can benefit from fine-grained localization. Fine-grained localization can simplify multi-robot collaboration, enable energy efficient multi-hop routing for low-power radio networks, and enable automatic calibration of distributed sensing systems. We focus on range estimation, a critical prerequisite for fine-grained localization. While many mechanisms for range estimation exist, any individual mode of sensing can be blocked or confused by the environment. We present and analyze an acoustic ranging system that performs well in the presence of many types of interference, but can return incorrect measurements in non-line-of-sight conditions. We then suggest how evidence from an orthogonal sensory channel might be used to detect and eliminate these measurements. The work illustrates the more general research theme of combining multiple modalities to obtain robust results</td>
</tr>
<tr id="bib_977164" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{977164,
  author = {Girod, L and Estrin, D},
  title = {Robust range estimation using acoustic and multimodal sensing},
  booktitle = {Intelligent Robots and Systems, 2001. Proceedings. 2001 IEEE/RSJ International Conference on},
  year = {2001},
  volume = {3},
  pages = {1312--1320 vol.3},
  url = {http://ieeexplore.ieee.org/document/977164/},
  doi = {http://dx.doi.org/10.1109/IROS.2001.977164}
}
</pre></td>
</tr>
<tr id="812832" class="entry">
	<td>Goel, P., Roumeliotis, S.I. and Sukhatme, G.S.</td>
	<td>Robust localization using relative and absolute position estimates <p class="infolinks">[<a href="javascript:toggleInfo('812832','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('812832','bibtex')">BibTeX</a>]</p></td>
	<td>1999</td>
	<td><br/>Vol. 2Intelligent Robots and Systems, 1999. IROS '99. Proceedings. 1999 IEEE/RSJ International Conference on, pp. 1134-1140 vol.2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.1999.812832">DOI</a> <a href="http://ieeexplore.ieee.org/document/812832/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_812832" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A low cost strategy based on well calibrated odometry is presented for localizing mobile robots. The paper describes a two-step process for correction of `systematic errors' in encoder measurements followed by fusion of the calibrated odometry with a gyroscope and GPS resulting in a robust localization scheme. A Kalman filter operating on data from the sensors is used for estimating position and orientation of the robot. Experimental results are presented that show an improvement of at least one order of magnitude in accuracy compared to the un-calibrated, un-filtered case. Our method is systematic, simple and yields very good results. We show that this strategy proves useful when the robot is using GPS to localize itself as well as when GPS becomes unavailable for some time. As a result robot can move in and out of enclosed spaces, such as buildings, while keeping track of its position on the fly</td>
</tr>
<tr id="bib_812832" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{812832,
  author = {Goel, P and Roumeliotis, S I and Sukhatme, G S},
  title = {Robust localization using relative and absolute position estimates},
  booktitle = {Intelligent Robots and Systems, 1999. IROS '99. Proceedings. 1999 IEEE/RSJ International Conference on},
  year = {1999},
  volume = {2},
  pages = {1134--1140 vol.2},
  url = {http://ieeexplore.ieee.org/document/812832/},
  doi = {http://dx.doi.org/10.1109/IROS.1999.812832}
}
</pre></td>
</tr>
<tr id="Golnabi2007630" class="entry">
	<td>Golnabi, H. and Asadpour, A.</td>
	<td>Design and application of industrial machine vision systems  <p class="infolinks">[<a href="javascript:toggleInfo('Golnabi2007630','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Golnabi2007630','bibtex')">BibTeX</a>]</p></td>
	<td>2007</td>
	<td>Robotics and Computer-Integrated Manufacturing 16th International Conference on Flexible Automation and Intelligent Manufacturing<br/>Vol. 23(6), pp. 630 - 637&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.rcim.2007.02.005">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0736584507000233">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Golnabi2007630" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this paper, the role and importance of the machine vision systems in the industrial applications are described. First understanding of the vision in terms of a universal concept is explained. System design methodology is discussed and a generic machine vision model is reported. Such a machine includes systems and sub-systems, which of course depend on the type of applications and required tasks. In general, expected functions from a vision machine are the exploitation and imposition of the environmental constraint of a scene, the capturing of the images, analysis of those captured images, recognition of certain objects and features within each image, and the initiation of subsequent actions in order to accept or reject the corresponding objects. After a vision system performs all these stages, the task in hand is almost completed. Here, the sequence and proper functioning of each system and sub-systems in terms of high-quality images is explained. In operation, there is a scene with some constraint, first step for the machine is the image acquisition, pre-processing of image, segmentation, feature extraction, classification, inspection, and finally actuation, which is an interaction with the scene under study. At the end of this report, industrial image vision applications are explained in detail. Such applications include the area of automated visual inspection (AVI), process control, parts identification, and important role in the robotic guidance and control. Vision developments in manufacturing that can result in improvements in the reliability, in the product quality, and enabling technology for a new production process are presented. The key points in design and applications of a machine vision system are also presented. Such considerations can be generally classified into the six different categories such as the scene constraints, image acquisition, image pre-processing, image processing, machine vision justification, and finally the systematic considerations. Each aspect of such processes is described here and the proper condition for an optimal design is reported.</td>
</tr>
<tr id="bib_Golnabi2007630" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Golnabi2007630,
  author = {H. Golnabi and A. Asadpour},
  title = {Design and application of industrial machine vision systems },
  journal = {Robotics and Computer-Integrated Manufacturing 16th International Conference on Flexible Automation and Intelligent Manufacturing},
  year = {2007},
  volume = {23},
  number = {6},
  pages = {630 - 637},
  note = {Cited by 85, Science Direct},
  url = {http://www.sciencedirect.com/science/article/pii/S0736584507000233},
  doi = {http://dx.doi.org/10.1016/j.rcim.2007.02.005}
}
</pre></td>
</tr>
<tr id="Han2005" class="entry">
	<td>Han, J.Y.</td>
	<td>Low-cost multi-touch sensing through frustrated total internal reflection <p class="infolinks">[<a href="javascript:toggleInfo('Han2005','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Han2005','bibtex')">BibTeX</a>]</p></td>
	<td>2005</td>
	<td>Proceedings of the 18th annual ACM symposium on User interface software and technology - UIST '05, pp. 115-118&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1145/1095034.1095054">DOI</a> <a href="http://portal.acm.org/citation.cfm?doid=1095034.1095054">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Han2005" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper describes a simple, inexpensive, and scalable technique for enabling high-resolution multi-touch sensing on rear-projected interactive surfaces based on frustrated total internal refl ection. We review previous applications of this phenomenon to sensing, provide implementation details, discuss results from our initial prototype, and outline future directions.</td>
</tr>
<tr id="bib_Han2005" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Han2005,
  author = {Han, Jefferson Y.},
  title = {Low-cost multi-touch sensing through frustrated total internal reflection},
  journal = {Proceedings of the 18th annual ACM symposium on User interface software and technology - UIST '05},
  year = {2005},
  pages = {115--118},
  url = {http://portal.acm.org/citation.cfm?doid=1095034.1095054},
  doi = {http://dx.doi.org/10.1145/1095034.1095054}
}
</pre></td>
</tr>
<tr id="hinton2013integration" class="entry">
	<td>Hinton, M.A., Burck, J.M., Collins, K.R., Johannes, M.S., Tunstel Jr, E.W. and Zeher, M.J.</td>
	<td>Integration of Advanced Explosive Ordnance Disposal Robotic Systems Within a Modular Open Systems Architecture <p class="infolinks">[<a href="javascript:toggleInfo('hinton2013integration','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Johns Hopkins APL technical digest<br/>Vol. 32(3), pp. 595&nbsp;</td>
	<td>article</td>
	<td><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.687.5803{\&}rep=rep1{\&}type=pdf{\#}page=43">URL</a>&nbsp;</td>
</tr>
<tr id="bib_hinton2013integration" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{hinton2013integration,
  author = {Hinton, Mark A and Burck, James M and Collins, Kristine R and Johannes, Matthew S and Tunstel Jr, Edward W and Zeher, Michael J},
  title = {Integration of Advanced Explosive Ordnance Disposal Robotic Systems Within a Modular Open Systems Architecture},
  journal = {Johns Hopkins APL technical digest},
  publisher = {Citeseer},
  year = {2013},
  volume = {32},
  number = {3},
  pages = {595},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.687.5803&amp;rep=rep1&amp;type=pdfpage=43}
}
</pre></td>
</tr>
<tr id="HORN199599" class="entry">
	<td>Horn, J. and Schmidt, G&uuml;.</td>
	<td>Continuous localization of a mobile robot based on 3D-laser-range-data, predicted sensor images, and dead-reckoning <p class="infolinks">[<a href="javascript:toggleInfo('HORN199599','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('HORN199599','bibtex')">BibTeX</a>]</p></td>
	<td>1995</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 14(2), pp. 99-118&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/0921-8890(94)00023-U">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/092188909400023U">URL</a>&nbsp;</td>
</tr>
<tr id="abs_HORN199599" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This article describes the localization system of a free-navigating mobile robot. Absolute position and orientation of the vehicle are determined by matching vertical planar surfaces extracted from a 3D-laser-range-image with corresponding surfaces predicted from a 3D-environmental model. Continuous localization is achieved by fusing single-image localization and dead-reckoning data by means of a statistical uncertainty evolution technique. Extensive closed-loop experiments with the full-scale mobile robot MACROBE proved robustness, accuracy and real-time capability of this localization scheme.</td>
</tr>
<tr id="bib_HORN199599" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{HORN199599,
  author = {Horn, Joachim and Schmidt, G&uuml;nther},
  title = {Continuous localization of a mobile robot based on 3D-laser-range-data, predicted sensor images, and dead-reckoning},
  journal = {Robotics and Autonomous Systems},
  year = {1995},
  volume = {14},
  number = {2},
  pages = {99--118},
  url = {http://www.sciencedirect.com/science/article/pii/092188909400023U},
  doi = {http://dx.doi.org/10.1016/0921-8890(94)00023-U}
}
</pre></td>
</tr>
<tr id="1249230" class="entry">
	<td>Hsiu, T., Richards, S., Bhave, A., Perez-Bergquist, A. and Nourbakhsh, I.</td>
	<td>Designing a low-cost, expressive educational robot <p class="infolinks">[<a href="javascript:toggleInfo('1249230','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1249230','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td><br/>Vol. 3Intelligent Robots and Systems, 2003. (IROS 2003). Proceedings. 2003 IEEE/RSJ International Conference on, pp. 2404-2409 vol.3&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2003.1249230">DOI</a> <a href="http://ieeexplore.ieee.org/document/1249230/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_1249230" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The Trikebot is the result of a ground-up design effort chartered to develop an effective and low-cost educational robot for secondary level education and home use. This paper describes all aspects of the Trikebot, including chassis and mechanism; control electronics; communication architecture; robot control server and student programming environment. Notable innovations include a fast-build construction kit, indoor/outdoor terrainability, CMOS vision-centered sensing, back-EMF motor speed control and a Java programming interface.</td>
</tr>
<tr id="bib_1249230" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1249230,
  author = {T. Hsiu and S. Richards and A. Bhave and A. Perez-Bergquist and I. Nourbakhsh},
  title = {Designing a low-cost, expressive educational robot},
  booktitle = {Intelligent Robots and Systems, 2003. (IROS 2003). Proceedings. 2003 IEEE/RSJ International Conference on},
  year = {2003},
  volume = {3},
  pages = {2404-2409 vol.3},
  note = {Cited by 10, IEEE},
  url = {http://ieeexplore.ieee.org/document/1249230/},
  doi = {http://dx.doi.org/10.1109/IROS.2003.1249230}
}
</pre></td>
</tr>
<tr id="7070742" class="entry">
	<td>Jamone, L., Natale, L., Metta, G. and Sandini, G.</td>
	<td>Highly Sensitive Soft Tactile Sensors for an Anthropomorphic Robotic Hand <p class="infolinks">[<a href="javascript:toggleInfo('7070742','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7070742','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>IEEE Sensors Journal<br/>Vol. 15(8), pp. 4226-4233&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/JSEN.2015.2417759">DOI</a> <a href="http://ieeexplore.ieee.org/document/7070742/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_7070742" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper describes the design and realization of novel tactile sensors based on soft materials and magnetic sensing. In particular, the goal was to realize: 1) soft; 2) robust; 3) small; and 4) low-cost sensors that can be easily fabricated and integrated on robotic devices that interact with the environment. We targeted a number of desired features, the most important being: 1) high sensitivity; 2) low hysteresis; and 3) repeatability. The sensor consists of a silicone body in which a small magnet is immersed; an Hall-effect sensor placed below the silicone body measures the magnetic field generated by the magnet, which changes when the magnet is displaced due to an applied external pressure. Two different versions of the sensor have been manufactured, characterized, and mounted on an anthropomorphic robotic hand. Experiments, in which the hand interacts with real-world objects, are reported.</td>
</tr>
<tr id="bib_7070742" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{7070742,
  author = {Jamone, L and Natale, L and Metta, G and Sandini, G},
  title = {Highly Sensitive Soft Tactile Sensors for an Anthropomorphic Robotic Hand},
  journal = {IEEE Sensors Journal},
  year = {2015},
  volume = {15},
  number = {8},
  pages = {4226--4233},
  url = {http://ieeexplore.ieee.org/document/7070742/},
  doi = {http://dx.doi.org/10.1109/JSEN.2015.2417759}
}
</pre></td>
</tr>
<tr id="902882" class="entry">
	<td>Jogan, M. and Leonardis, A.</td>
	<td>Robust localization using panoramic view-based recognition <p class="infolinks">[<a href="javascript:toggleInfo('902882','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('902882','bibtex')">BibTeX</a>]</p></td>
	<td>2000</td>
	<td><br/>Vol. 4Pattern Recognition, 2000. Proceedings. 15th International Conference on, pp. 136-139 vol.4&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICPR.2000.902882">DOI</a> <a href="http://ieeexplore.ieee.org/document/902882/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_902882" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The results of earlier studies on the possibility of spatial localization from panoramic images have shown good prospects for view-based methods. The major advantages of these methods are a wide field-of-view, capability of modeling cluttered environments, and flexibility in the learning phase. The redundant information captured in similar views is efficiently handled by the eigenspace approach. However, the standard approaches are sensitive to noise and occlusion. We present a method of view-based localization in a robust framework that solves these problems to a large degree. Experimental results on a large set of real panoramic images demonstrate the effectiveness of the approach and the level of achieved robustness</td>
</tr>
<tr id="bib_902882" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{902882,
  author = {Jogan, M and Leonardis, A},
  title = {Robust localization using panoramic view-based recognition},
  booktitle = {Pattern Recognition, 2000. Proceedings. 15th International Conference on},
  year = {2000},
  volume = {4},
  pages = {136--139 vol.4},
  url = {http://ieeexplore.ieee.org/document/902882/},
  doi = {http://dx.doi.org/10.1109/ICPR.2000.902882}
}
</pre></td>
</tr>
<tr id="Kasyanik2014" class="entry">
	<td>Kasyanik, V. and Potapchuk, S.</td>
	<td>CCIS 440 - A Low-Cost Mobile Robot for Education <p class="infolinks">[<a href="javascript:toggleInfo('Kasyanik2014','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kasyanik2014','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>Neural Networks and Artificial Intelligence, pp. 182-190&nbsp;</td>
	<td>incollection</td>
	<td><a href="http://link.springer.com/chapter/10.1007{\%}2F978-3-319-08201-1{\_}17{\#}page-1">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Kasyanik2014" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: We present, in this paper, a mobile robot and a program to control it that can be used in robotics education, expecting that the idea evolves, in a visible future, into a more general research tool in the field of robotics. The information necessary for robotic students to design their own mobile robot is, availability of each component of the robot, how each module of the robot is constructed, how these modules are combined, how a sensor system is given, how a simulator for the robot is programmed, what environment is appropriate to test the simulators, and so on. Also, it might be better if a possibility is given for developing it in student's home.</td>
</tr>
<tr id="bib_Kasyanik2014" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Kasyanik2014,
  author = {Kasyanik, Valery and Potapchuk, Sergey},
  title = {CCIS 440 - A Low-Cost Mobile Robot for Education},
  booktitle = {Neural Networks and Artificial Intelligence},
  year = {2014},
  pages = {182--190},
  url = {http://link.springer.com/chapter/10.1007%2F978-3-319-08201-117page-1}
}
</pre></td>
</tr>
<tr id="Khatib1986" class="entry">
	<td>Khatib, O.</td>
	<td>Real-Time Obstacle Avoidance for Manipulators and Mobile Robots <p class="infolinks">[<a href="javascript:toggleInfo('Khatib1986','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Khatib1986','bibtex')">BibTeX</a>]</p></td>
	<td>1986</td>
	<td>The International Journal of Robotics Research, pp. 3024-3031&nbsp;</td>
	<td>article</td>
	<td><a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.910.1287">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Khatib1986" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper presents a unique real-time obstacle avoidance approach for manipulators and mobile robots based on the artificial potential field concept. Collision avoidance, tradi-tionally considered a high level planning problem, can be effectively distributed between different levels of control, al-lowing real-time robot operations in a complex environment. This method has been extended to moving obstacles by using a time-varying artificial patential field. We have applied this obstacle avoidance scheme to robot arm mechanisms and have used a new approach to the general problem of real-time manipulator control. We reformulated the manipulator con-trol problem as direct control of manipulator motion in oper-ational space&amp;mdash;the space in which the task is originally described&amp;mdash;rather than as control of the task's corresponding joint space motion obtained only after geometric and kine-matic transformation. Outside the obstacles ' regions of influ-ence, we caused the end effector to move in a straight line with an upper speed limit. The artificial potential field ap-proach has been extended to collision avoidance for all ma-nipulator links. In addition, a joint space artificial potential field is used to satisfy the manipulator internal joint con-straints. This method has been implemented in the COSMOS system for a PUMA 560 robot. Real-time collision avoidance demonstrations on moving obstacles have been performed by using visual sensing.</td>
</tr>
<tr id="bib_Khatib1986" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Khatib1986,
  author = {Khatib, Oussama},
  title = {Real-Time Obstacle Avoidance for Manipulators and Mobile Robots},
  journal = {The International Journal of Robotics Research},
  year = {1986},
  pages = {3024--3031},
  url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.910.1287}
}
</pre></td>
</tr>
<tr id="Lin2013" class="entry">
	<td>Lin, L.-H., Lawrence, P.D. and Hall, R.</td>
	<td>Robust outdoor stereo vision SLAM for heavy machine rotation sensing <p class="infolinks">[<a href="javascript:toggleInfo('Lin2013','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Lin2013','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Machine Vision and Applications<br/>Vol. 24(1), pp. 205-226&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/s00138-011-0380-6">DOI</a> <a href="http://dx.doi.org/10.1007/s00138-011-0380-6">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Lin2013" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The paper presents a robust outdoor stereo vision simultaneous localization and mapping (SLAM) algorithm. It estimates camera pose reliably in outdoor environments with directional sunlight illumination causing shadows and non-uniform scene lighting. The algorithm has been developed to measure a mining rope shovel's rotation angle about its vertical axis (``swing'' axis). A stereo camera is mounted externally to the shovel house (upper revolvable portion of the shovel), with a clear view of the shovel's lower carbody. As the shovel house swings, the camera revolves with the shovel house in a planar circular orbit, seeing differing views of the carbody top. During the swing, the SLAM algorithm builds a map of observed 3D features on the carbody and simultaneously using these landmarks to estimate the camera position. This estimated camera position is then used to compute the shovel swing angle. Two novel techniques are employed to improve the SLAM algorithm's robustness in outdoor environments. First, a ``Locally Maximal'' feature selection technique for Harris corners is used to select features more consistently in non-uniformly illuminated scenes. Another novel technique is the use of 3D ``Feature Clusters'' as SLAM landmarks rather than individual single features. The Feature Cluster landmarks improve the robustness of the landmark matching and allow significant reduction of the SLAM filter computational cost. This approach of estimating the shovel swing angle has a maximum error of textpm1textdegree upon SLAM map convergence. Results demonstrate the improvements of using the novel techniques compared to previous methods.</td>
</tr>
<tr id="bib_Lin2013" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Lin2013,
  author = {Lin, Li-Heng and Lawrence, Peter D. and Hall, Robert},
  title = {Robust outdoor stereo vision SLAM for heavy machine rotation sensing},
  journal = {Machine Vision and Applications},
  year = {2013},
  volume = {24},
  number = {1},
  pages = {205--226},
  note = {Cited by 2, Springer},
  url = {http://dx.doi.org/10.1007/s00138-011-0380-6},
  doi = {http://dx.doi.org/10.1007/s00138-011-0380-6}
}
</pre></td>
</tr>
<tr id="Liu:2006:RDN:1132905.1132933" class="entry">
	<td>Liu, J., Zhang, Y. and Zhao, F.</td>
	<td>Robust Distributed Node Localization with Error Management <p class="infolinks">[<a href="javascript:toggleInfo('Liu:2006:RDN:1132905.1132933','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Liu:2006:RDN:1132905.1132933','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>Proceedings of the 7th ACM International Symposium on Mobile Ad Hoc Networking and Computing, pp. 250-261&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1145/1132905.1132933">DOI</a> <a href="http://doi.acm.org/10.1145/1132905.1132933">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Liu:2006:RDN:1132905.1132933" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Location knowledge of nodes in a network is essential for many tasks such as routing, cooperative sensing, or service delivery in ad hoc, mobile, or sensor networks. This paper introduces a novel iterative method ILS for node localization starting with a relatively small number of anchor nodes in a large network. At each iteration, nodes are localized using a least-squares based algorithm. The computation is lightweight, fast, and any-time. To prevent error from propagating and accumulating during the iteration, the error control mechanism of the algorithm uses an error registry to select nodes that participate in the localization, based on their relative contribution to the localization accuracy. Simulation results have shown that the active selection strategy significantly mitigates the effect of error propagation. The algorithm has been tested on a network of Berkeley Mica2 motes with ultrasound TOA ranging devices. We have compared the algorithm with more global methods such as MDS-MAP and SDP-based algorithm both in simulation and on real hardware. The iterative localization achieves comparable location accuracy in both cases, compared to the more global methods, and has the advantage of being fully decentralized.</td>
</tr>
<tr id="bib_Liu:2006:RDN:1132905.1132933" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Liu:2006:RDN:1132905.1132933,
  author = {Liu, Juan and Zhang, Ying and Zhao, Feng},
  title = {Robust Distributed Node Localization with Error Management},
  booktitle = {Proceedings of the 7th ACM International Symposium on Mobile Ad Hoc Networking and Computing},
  publisher = {ACM},
  year = {2006},
  pages = {250--261},
  note = {Cited by 45, ACM},
  url = {http://doi.acm.org/10.1145/1132905.1132933},
  doi = {http://dx.doi.org/10.1145/1132905.1132933}
}
</pre></td>
</tr>
<tr id="Malamas2003171" class="entry">
	<td>Malamas, E.N., Petrakis, E.G., Zervakis, M., Petit, L. and Legat, J.-D.</td>
	<td>A survey on industrial vision systems, applications and tools  <p class="infolinks">[<a href="javascript:toggleInfo('Malamas2003171','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Malamas2003171','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td>Image and Vision Computing <br/>Vol. 21(2), pp. 171 - 188&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S0262-8856(02)00152-X">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S026288560200152X">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Malamas2003171" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The state of the art in machine vision inspection and a critical overview of real-world applications are presented in this paper. Two independent ways to classify applications are proposed, one according to the inspected features of the industrial product or process and the other according to the inspection independent characteristics of the inspected product or process. The most contemporary software and hardware tools for developing industrial vision systems are reviewed. Finally, under the light of recent advances in image sensors, software and hardware technology, important issues and directions for designing and developing industrial vision systems are identified and discussed.</td>
</tr>
<tr id="bib_Malamas2003171" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Malamas2003171,
  author = {Elias N Malamas and Euripides G.M Petrakis and Michalis Zervakis and Laurent Petit and Jean-Didier Legat},
  title = {A survey on industrial vision systems, applications and tools },
  journal = {Image and Vision Computing },
  year = {2003},
  volume = {21},
  number = {2},
  pages = {171 - 188},
  note = {Cited by 354, Science Direct},
  url = {http://www.sciencedirect.com/science/article/pii/S026288560200152X},
  doi = {http://dx.doi.org/10.1016/S0262-8856(02)00152-X}
}
</pre></td>
</tr>
<tr id="956029" class="entry">
	<td>Martinez, A.M. and Vitria, J.</td>
	<td>Clustering in image space for place recognition and visual annotations for human-robot interaction <p class="infolinks">[<a href="javascript:toggleInfo('956029','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('956029','bibtex')">BibTeX</a>]</p></td>
	<td>2001</td>
	<td>IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)<br/>Vol. 31(5), pp. 669-682&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/3477.956029">DOI</a> <a href="http://ieeexplore.ieee.org/document/956029/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_956029" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The most classical way of attempting to solve the vision-guided navigation problem for autonomous robots corresponds to the use of three-dimensional (3-D) geometrical descriptions of the scene; what is known as model-based approaches. However, these approaches do not facilitate the user's task because they require that geometrically precise models of the 3-D environment be given by the user. In this paper, we propose the use of “annotations” posted on some type of blackboard or “descriptive” map to facilitate this user-robot interaction. We show that, by using this technique, user commands can be as simple as “go to label 5.” To build such a mechanism, new approaches for vision-guided mobile robot navigation have to be found. We show that this can be achieved by using mixture models within an appearance-based paradigm. Mixture models are more useful in practice than other pattern recognition methods such as principal component analysis (PCA) or Fisher discriminant analysis (FDA)-also known as linear discriminant analysis (LDA), because they can represent nonlinear subspaces. However, given the fact that mixture models are usually learned using the expectation-maximization (EM) algorithm which is a gradient ascent technique, the system cannot always converge to a desired final solution, due to the local maxima problem. To resolve this, a genetic version of the EM algorithm is used. We then show the capabilities of this latest approach on a navigation task that uses the above described “annotations.”</td>
</tr>
<tr id="bib_956029" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{956029,
  author = {A. M. Martinez and J. Vitria},
  title = {Clustering in image space for place recognition and visual annotations for human-robot interaction},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  year = {2001},
  volume = {31},
  number = {5},
  pages = {669-682},
  note = {Cited by 22, IEEE},
  url = {http://ieeexplore.ieee.org/document/956029/},
  doi = {http://dx.doi.org/10.1109/3477.956029}
}
</pre></td>
</tr>
<tr id="6086814" class="entry">
	<td>Melo, K., Paez, L., Hernandez, M., Velasco, A., Calderon, F. and Parra, C.</td>
	<td>Preliminary studies on modular snake robots applied on de-mining tasks <p class="infolinks">[<a href="javascript:toggleInfo('6086814','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6086814','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>Robotics Symposium, 2011 IEEE IX Latin American and IEEE Colombian Conference on Automatic Control and Industry Applications (LARC), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/LARC.2011.6086814">DOI</a> <a href="http://ieeexplore.ieee.org/document/6086814/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_6086814" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper addresses recent developments on Modular Snake Robots suited for applications on de-mining tasks. Inclusion of robotic platforms on the de-mining process will help tasks like the recognizance and perception of dangerous areas, minimizing human risk. As a mobile robot, the modular snake robot can move in a uneven terrain similar to a mined scenario. That is why, the main research efforts have been done on locomotion. Several contributions on this area are reported including gaits like: closed chain rolling, lateral rolling and a gait that use a helix shape both on the outside of cylinders. Another gait studied regards the swing movement of a modular robot chain hanging from one of its end modules. Contributions on robot architecture are reported here, including a distributed model predictive control and a multi-camera and sensor fusion. The perception problem of these robots also are researched by our lab and a pair of developments are shown here.</td>
</tr>
<tr id="bib_6086814" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6086814,
  author = {Melo, K and Paez, L and Hernandez, M and Velasco, A and Calderon, F and Parra, C},
  title = {Preliminary studies on modular snake robots applied on de-mining tasks},
  booktitle = {Robotics Symposium, 2011 IEEE IX Latin American and IEEE Colombian Conference on Automatic Control and Industry Applications (LARC)},
  year = {2011},
  pages = {1--6},
  url = {http://ieeexplore.ieee.org/document/6086814/},
  doi = {http://dx.doi.org/10.1109/LARC.2011.6086814}
}
</pre></td>
</tr>
<tr id="migliore2007novel" class="entry">
	<td>Migliore, S.A., Brown, E.A. and DeWeerth, S.P.</td>
	<td>Novel nonlinear elastic actuators for passively controlling robotic joint compliance <p class="infolinks">[<a href="javascript:toggleInfo('migliore2007novel','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('migliore2007novel','bibtex')">BibTeX</a>]</p></td>
	<td>2007</td>
	<td>Journal of Mechanical Design<br/>Vol. 129(4), pp. 406-412&nbsp;</td>
	<td>article</td>
	<td><a href="http://mechanicaldesign.asmedigitalcollection.asme.org/article.aspx?articleid=1449330">URL</a>&nbsp;</td>
</tr>
<tr id="abs_migliore2007novel" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The ability to control compliance of robotic joints is desirable because the resulting robotic mechanisms can adapt to varying task requirements and can take advantage of natural limb and joint dynamics. The implementation of controllable compliance in ro- bots, however, is often constrained by the inherent instability of active compliance meth- ods and by the limited availability of the custom, nonlinear springs needed by passive compliance methods. This work overcomes a major limitation of passive compliance by producing designs for two novel mechanisms capable of generating a wide variety of specifiable, nonlinear elastic relationships. One of these designs is physically imple- mented as a quadratic “spring” and is used to create a passively compliant robot joint with series-elastic actuation. A simple feed-forward algorithm is then experimentally shown to be sufficient to control independently and simultaneously both joint angle and joint compliance, regardless of the presence of external forces on the joint. We believe that this is the first physically constructed system to use antagonistic quadratic springs to successfully demonstrate open-loop, independent, and simultaneous control of both joint angle and joint stiffness. Because this approach better emulates the underlying joint mechanics used by animals, it may improve both the quality and variety of robotic movements.</td>
</tr>
<tr id="bib_migliore2007novel" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{migliore2007novel,
  author = {Migliore, Shane A and Brown, Edgar A and DeWeerth, Stephen P},
  title = {Novel nonlinear elastic actuators for passively controlling robotic joint compliance},
  journal = {Journal of Mechanical Design},
  publisher = {American Society of Mechanical Engineers},
  year = {2007},
  volume = {129},
  number = {4},
  pages = {406--412},
  note = {Cited by 59, IEEE},
  url = {http://mechanicaldesign.asmedigitalcollection.asme.org/article.aspx?articleid=1449330}
}
</pre></td>
</tr>
<tr id="4681485" class="entry">
	<td>Mohamed, N., Al-Jaroodi, J. and Jawhar, I.</td>
	<td>Middleware for Robotics: A Survey <p class="infolinks">[<a href="javascript:toggleInfo('4681485','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('4681485','bibtex')">BibTeX</a>]</p></td>
	<td>2008</td>
	<td>2008 IEEE Conference on Robotics, Automation and Mechatronics, pp. 736-742&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/RAMECH.2008.4681485">DOI</a> <a href="http://ieeexplore.ieee.org/document/4681485/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_4681485" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The field of robotics relies heavily on various technologies such as mechatronics, computing systems, and wireless communication. Given the fast growing technological progress in these fields, robots can offer a wide range of applications. However real world integration and application development for such a distributed system composed of many robotic modules and networked robotic devices is very difficult. Therefore, middleware services provide a novel approach offering many possibilities and drastically enhancing the application development for robots. This paper surveys the current state of middleware approaches in this domain. It discusses middleware challenges in these systems and presents some representative middleware solutions specifically designed for robots. The selection of the studied methods tries to cover most of the middleware platforms, objectives and approaches that have been proposed by researchers in this field.</td>
</tr>
<tr id="bib_4681485" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{4681485,
  author = {N. Mohamed and J. Al-Jaroodi and I. Jawhar},
  title = {Middleware for Robotics: A Survey},
  booktitle = {2008 IEEE Conference on Robotics, Automation and Mechatronics},
  year = {2008},
  pages = {736-742},
  note = {Cited by 39 ,IEEE},
  url = {http://ieeexplore.ieee.org/document/4681485/},
  doi = {http://dx.doi.org/10.1109/RAMECH.2008.4681485}
}
</pre></td>
</tr>
<tr id="N.BulusuJ.Heidemann2000" class="entry">
	<td>N. Bulusu, J. Heidemann and Estrin, D.</td>
	<td>GPS-less low cost outdoor localization for very small devices. IEEE Personal Communications, 7(5) <p class="infolinks">[<a href="javascript:toggleInfo('N.BulusuJ.Heidemann2000','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('N.BulusuJ.Heidemann2000','bibtex')">BibTeX</a>]</p></td>
	<td>2000</td>
	<td>IEEE Personal Communications Magazine<br/>Vol. 7(5), pp. 28-34&nbsp;</td>
	<td>article</td>
	<td><a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.3261{\&}rank=3">URL</a>&nbsp;</td>
</tr>
<tr id="abs_N.BulusuJ.Heidemann2000" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Instrumenting the physical world through large networks of wireless sensor nodes, particularly for applications like environmen- tal monitoring of water and soil, requires that these nodes be very small, light, untethered and unobtrusive. The problem of localization, i.e., de- termining where a given node is physically located in a network is a challenging one, and yet extremely crucial for many of these applica- tions. Practical considerations such as the small size, form factor, cost and power constraints of nodes preclude the reliance on GPS (Global Positioning System) on all nodes in these networks. In this paper, we review localization techniques and evaluate the effectiveness of a very simple connectivity-metric method for localization in outdoor environ- ments that makes use of the inherent radio-frequency (RF) communi- cations capabilities of these devices. A fixed number of reference points in the network with overlapping regions of coverage transmit periodic beacon signals. Nodes use a simple connectivity metric, that is more ro- bust to environmental vagaries, to infer proximity to a given subset of these reference points. Nodes localize themselves to the centroid of their proximate reference points. The accuracy of localization is then depen- dent on the separation distance between two adjacent reference points and the transmission range of these reference points. Initial experimen- tal results show that the accuracy for 90% of our data points is within one-third of the separation distance. However future work is needed to extend the technique to more cluttered environments.</td>
</tr>
<tr id="bib_N.BulusuJ.Heidemann2000" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{N.BulusuJ.Heidemann2000,
  author = {N. Bulusu, J. Heidemann, and D. Estrin},
  title = {GPS-less low cost outdoor localization for very small devices. IEEE Personal Communications, 7(5)},
  journal = {IEEE Personal Communications Magazine},
  year = {2000},
  volume = {7},
  number = {5},
  pages = {28--34},
  note = {Cited by 4042, GS},
  url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.3261&amp;rank=3}
}
</pre></td>
</tr>
<tr id="1641896" class="entry">
	<td>Ohmura, Y., Kuniyoshi, Y. and Nagakubo, A.</td>
	<td>Conformable and scalable tactile sensor skin for curved surfaces <p class="infolinks">[<a href="javascript:toggleInfo('1641896','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1641896','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006., pp. 1348-1353&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2006.1641896">DOI</a> <a href="http://ieeexplore.ieee.org/document/1641896/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_1641896" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: We present the design and realization of a conformable tactile sensor skin (patent pending). The skin is organized as a network of self-contained modules consisting of tiny pressure-sensitive elements which communicate through a serial bus. By adding or removing modules it is possible to adjust the area covered by the skin as well as the number (and density) of tactile elements. The skin is therefore highly modular and thus intrinsically scalable. Moreover, because the substrate on which the modules are mounted is sufficiently pliable to be folded and stiff enough to be cut, it is possible to freely distribute the individual tactile elements. A tactile skin composed of multiple modules can also be installed on curved surfaces. Due to their easy configurability we call our sensors "cut-and-paste tactile sensors." We describe a prototype implementation of the skin on a humanoid robot</td>
</tr>
<tr id="bib_1641896" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1641896,
  author = {Y. Ohmura and Y. Kuniyoshi and A. Nagakubo},
  title = {Conformable and scalable tactile sensor skin for curved surfaces},
  booktitle = {Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.},
  year = {2006},
  pages = {1348-1353},
  note = {Cited by 107, IEEE},
  url = {http://ieeexplore.ieee.org/document/1641896/},
  doi = {http://dx.doi.org/10.1109/ROBOT.2006.1641896}
}
</pre></td>
</tr>
<tr id="4337971" class="entry">
	<td>Papadimitriou, V. and Papadopoulos, E.</td>
	<td>Putting low-cost commercial robotics components to the test - Development of an educational mechatronics/robotics platform using LEGO components <p class="infolinks">[<a href="javascript:toggleInfo('4337971','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('4337971','bibtex')">BibTeX</a>]</p></td>
	<td>2007</td>
	<td>IEEE Robotics Automation Magazine<br/>Vol. 14(3), pp. 99-110&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/MRA.2007.901322">DOI</a> <a href="http://ieeexplore.ieee.org/document/4337971/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_4337971" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this article, we investigate the possibility of using low-cost commercial material as a means of learning, research, and experimentation in fields such as mechatronics, robotics, and automatic control. The capabilities and limitations of the selected platform, i.e., of the LEGO elements, are studied via two projects that were designed and carried out, including a number of enhancements that address hardware and software limitations. The first project involves a robotic vehicle that can follow predefined paths, while the second concerns two robotic vehicles cooperating in a specific task. Algorithms and additional hardware were developed and the overall results are presented. It was found that the platform is suitable for teaching many diverse issues of central importance in the areas of interest.</td>
</tr>
<tr id="bib_4337971" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{4337971,
  author = {Papadimitriou, V and Papadopoulos, E},
  title = {Putting low-cost commercial robotics components to the test - Development of an educational mechatronics/robotics platform using LEGO components},
  journal = {IEEE Robotics Automation Magazine},
  year = {2007},
  volume = {14},
  number = {3},
  pages = {99--110},
  url = {http://ieeexplore.ieee.org/document/4337971/},
  doi = {http://dx.doi.org/10.1109/MRA.2007.901322}
}
</pre></td>
</tr>
<tr id="Pedre2014" class="entry">
	<td>Pedre Sol Nitsche, M.P.F.C.J.D.C.P.</td>
	<td>Design of a multi-purpose low-cost mobile robot for research and education <p class="infolinks">[<a href="javascript:toggleInfo('Pedre2014','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pedre2014','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td><br/>Vol. 8717 LNAIAdvances in Autonomous Robotics Systems, pp. 185-196&nbsp;</td>
	<td>incollection</td>
	<td><a href="http://dx.doi.org/10.1007/978-3-319-10401-0_17">DOI</a> <a href="http://link.springer.com/chapter/10.1007{\%}2F978-3-319-10401-0{\_}17{\#}page-1">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Pedre2014" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Mobile robots are commonly used for research and education. Although there are several commercial mobile robots available for these tasks, they are often costly, do not always meet the characteristics needed for certain applications and are very difficult to adapt because they have proprietary software and hardware. In this paper, we present the design principles, and describe the development and applications of a mobile robot called ExaBot. Our main goal was to obtain a single multi-purpose low-cost robot -more than ten times cheaper than commercially available platforms- that can be used not only for research, but also for education and public outreach activities. The body of the ExaBot, its sensors, actuators, processing units and control board are described in detail. The software and printed circuit board developed for this project are open source to allow the robotics community to use and upgrade the current version. Finally, different configurations of the ExaBot are presented, showing several applications that fulfill the requirements this robotic platform was designed for. ? 2014 Springer International Publishing.</td>
</tr>
<tr id="bib_Pedre2014" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Pedre2014,
  author = {Pedre, Sol Nitsche, Matías Pessacg, Facundo Caccavelli, Javier De Cristóforis, Pablo},
  title = {Design of a multi-purpose low-cost mobile robot for research and education},
  booktitle = {Advances in Autonomous Robotics Systems},
  year = {2014},
  volume = {8717 LNAI},
  pages = {185--196},
  note = {Cited by 3, GS},
  url = {http://link.springer.com/chapter/10.1007%2F978-3-319-10401-017page-1},
  doi = {http://dx.doi.org/10.1007/978-3-319-10401-0_17}
}
</pre></td>
</tr>
<tr id="1703498" class="entry">
	<td>Petrellis, N., Konofaos, N. and Alexiou, G.P.</td>
	<td>Target Localization Utilizing the Success Rate in Infrared Pattern Recognition <p class="infolinks">[<a href="javascript:toggleInfo('1703498','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1703498','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>IEEE Sensors Journal<br/>Vol. 6(5), pp. 1355-1364&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/JSEN.2006.881342">DOI</a> <a href="http://ieeexplore.ieee.org/document/1703498/?arnumber=1703498">URL</a>&nbsp;</td>
</tr>
<tr id="abs_1703498" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The architecture of an indoor target localization system employing a small number of infrared-emitting diodes and sensors is presented in this paper. The properties of infrared light and magnetic fields have already been exploited for position localization in distances of several centimeters. Ultrasonic waves and laser light can be used for longer distance estimation if the system is capable of accurately measuring the time of flight of the reflected signals. The proposed approach intends to cover a distance of several meters without requiring high accuracy measurements and sensors of increased precision. The digital infrared patterns that are transmitted from a constant position are recognized by a pair of sensors mounted on the moving target, with varying success rate depending on the distance and the angular displacement from the transmitter. Processing the success rate instead of the analogue signal intensity requires low-cost digital microcontroller systems of moderate precision and computational power. Moreover, longer distances can be covered since attenuated, noisy, or scrambled patterns are also important for the position estimation in the proposed approach. A proper modeling of the pattern recognition success rate is presented in order to estimate distances of several meters with an adjustable estimation error. The use of multiple infrared pattern transmitting devices results in extension of the area covered and a reduction of the estimation error due to additional crosschecks that may be accomplished. The area covered can be increased by a factor between 20% and 100% depending on the allowed range overlapping of the transmitting devices. The potential topology of these devices is also discussed and analyzed. The presented system can be used in several virtual reality and robotics applications</td>
</tr>
<tr id="bib_1703498" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{1703498,
  author = {N. Petrellis and N. Konofaos and G. P. Alexiou},
  title = {Target Localization Utilizing the Success Rate in Infrared Pattern Recognition},
  journal = {IEEE Sensors Journal},
  year = {2006},
  volume = {6},
  number = {5},
  pages = {1355-1364},
  note = {Cited by 10, IEEE},
  url = {http://ieeexplore.ieee.org/document/1703498/?arnumber=1703498},
  doi = {http://dx.doi.org/10.1109/JSEN.2006.881342}
}
</pre></td>
</tr>
<tr id="LopezdeMantaras:1997:GUE:267658.267691" class="entry">
	<td>R López de Màntaras J Amat, F.E.M.L. and Sierra, C.</td>
	<td>Generation of Unknown Environment Maps by Cooperative Low-cost Robots <p class="infolinks">[<a href="javascript:toggleInfo('LopezdeMantaras:1997:GUE:267658.267691','bibtex')">BibTeX</a>]</p></td>
	<td>1997</td>
	<td>Proceedings of the First International Conference on Autonomous Agents, pp. 164-169&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1145/267658.267691">DOI</a> <a href="http://doi.acm.org/10.1145/267658.267691">URL</a>&nbsp;</td>
</tr>
<tr id="bib_LopezdeMantaras:1997:GUE:267658.267691" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{LopezdeMantaras:1997:GUE:267658.267691,
  author = {R López de Màntaras, J Amat, F Esteva, M López, and Sierra, C.},
  title = {Generation of Unknown Environment Maps by Cooperative Low-cost Robots},
  booktitle = {Proceedings of the First International Conference on Autonomous Agents},
  publisher = {ACM},
  year = {1997},
  pages = {164--169},
  note = {Cited by 18, Google Scholar},
  url = {http://doi.acm.org/10.1145/267658.267691},
  doi = {http://dx.doi.org/10.1145/267658.267691}
}
</pre></td>
</tr>
<tr id="1565451" class="entry">
	<td>Rowe, A., Rosenberg, C. and Nourbakhsh, I.</td>
	<td>A Second Generation Low Cost Embedded Color Vision System <p class="infolinks">[<a href="javascript:toggleInfo('1565451','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1565451','bibtex')">BibTeX</a>]</p></td>
	<td>2005</td>
	<td>2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops, pp. 136-136&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/CVPR.2005.396">DOI</a> <a href="http://ieeexplore.ieee.org/document/1565451/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_1565451" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this paper we describe a low cost embedded vision system, the CMUcam2. The CMUcam2 is the second generation of the CMUcam system and attempts to overcome the shortcomings of the original system as well as improve upon and add to its functionality. The goal of the system is to provide simple vision capabilities to small embedded systems in the form of an intelligent sensor. The system utilizes a low cost CMOS color camera module, a frame buffer chip and all image data is processed by a low cost microcontroller. The system includes the original functionality of color blob tracking, but improves upon it with tracking speeds of up to 50 frames per second. New functionality includes frame differencing, edge detection, and color histogramming. Other improvements were also made to facilitate communication with slower speed processors, as is often the case in a variety of robotics applications, including miniature robotics, hobby robotics and aerial robots.</td>
</tr>
<tr id="bib_1565451" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1565451,
  author = {A. Rowe and C. Rosenberg and I. Nourbakhsh},
  title = {A Second Generation Low Cost Embedded Color Vision System},
  booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},
  year = {2005},
  pages = {136-136},
  note = {Cited by 15, IEEE},
  url = {http://ieeexplore.ieee.org/document/1565451/},
  doi = {http://dx.doi.org/10.1109/CVPR.2005.396}
}
</pre></td>
</tr>
<tr id="1041390" class="entry">
	<td>Rowe, A., Rosenberg, C. and Nourbakhsh, I.</td>
	<td>A low cost embedded color vision system <p class="infolinks">[<a href="javascript:toggleInfo('1041390','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1041390','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td><br/>Vol. 1Intelligent Robots and Systems, 2002. IEEE/RSJ International Conference on, pp. 208-213 vol.1&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IRDS.2002.1041390">DOI</a> <a href="http://ieeexplore.ieee.org/document/1041390/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_1041390" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this paper we describe a functioning low cost embedded vision system which can perform basic color blob tracking at 16.7 frames per second. This system utilizes a low cost CMOS color camera module and all image data is processed by a high speed, low cost microcontroller. This eliminates the need for a separate frame grabber and high speed host computer typically found in traditional vision systems. The resulting embedded system makes it possible to utilize simple color vision algorithms in applications like small mobile robotics where a traditional vision system would not be practical.</td>
</tr>
<tr id="bib_1041390" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1041390,
  author = {A. Rowe and C. Rosenberg and I. Nourbakhsh},
  title = {A low cost embedded color vision system},
  booktitle = {Intelligent Robots and Systems, 2002. IEEE/RSJ International Conference on},
  year = {2002},
  volume = {1},
  pages = {208-213 vol.1},
  note = {Cited by 34, IEEE},
  url = {http://ieeexplore.ieee.org/document/1041390/},
  doi = {http://dx.doi.org/10.1109/IRDS.2002.1041390}
}
</pre></td>
</tr>
<tr id="6224638" class="entry">
	<td>Rubenstein, M., Ahler, C. and Nagpal, R.</td>
	<td>Kilobot: A low cost scalable robot system for collective behaviors <p class="infolinks">[<a href="javascript:toggleInfo('6224638','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6224638','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 3293-3298&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2012.6224638">DOI</a> <a href="http://ieeexplore.ieee.org/document/6224638/?arnumber=6224638">URL</a>&nbsp;</td>
</tr>
<tr id="abs_6224638" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In current robotics research there is a vast body of work on algorithms and control methods for groups of decentralized cooperating robots, called a swarm or collective. These algorithms are generally meant to control collectives of hundreds or even thousands of robots; however, for reasons of cost, time, or complexity, they are generally validated in simulation only, or on a group of a few tens of robots. To address this issue, this paper presents Kilobot, a low-cost robot designed to make testing collective algorithms on hundreds or thousands of robots accessible to robotics researchers. To enable the possibility of large Kilobot collectives where the number of robots is an order of magnitude larger than the largest that exist today, each robot is made with only $14 worth of parts and takes 5 minutes to assemble. Furthermore, the robot design allows a single user to easily operate a large Kilobot collective, such as programming, powering on, and charging all robots, which would be difficult or impossible to do with many existing robotic systems.</td>
</tr>
<tr id="bib_6224638" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6224638,
  author = {M. Rubenstein and C. Ahler and R. Nagpal},
  title = {Kilobot: A low cost scalable robot system for collective behaviors},
  booktitle = {Robotics and Automation (ICRA), 2012 IEEE International Conference on},
  year = {2012},
  pages = {3293-3298},
  note = {Cited by 51, IEEE},
  url = {http://ieeexplore.ieee.org/document/6224638/?arnumber=6224638},
  doi = {http://dx.doi.org/10.1109/ICRA.2012.6224638}
}
</pre></td>
</tr>
<tr id="6696380" class="entry">
	<td>Saarinen, J., Andreasson, H., Stoyanov, T. and Lilienthal, A.J.</td>
	<td>Normal distributions transform Monte-Carlo localization (NDT-MCL) <p class="infolinks">[<a href="javascript:toggleInfo('6696380','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6696380','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 382-389&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2013.6696380">DOI</a> <a href="http://ieeexplore.ieee.org/document/6696380/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_6696380" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Industrial applications often impose hard requirements on the precision of autonomous vehicle systems. As a consequence industrial Automatically Guided Vehicle (AGV) systems still use high-cost infrastructure based positioning solutions. In this paper we propose a map based localization method that fulfills the requirements on precision and repeatability, typical for industrial application scenarios. The proposed method - Normal Distributions Transform Monte Carlo Localization (NDT-MCL) is based on a well established probabilistic framework. In a novel contribution, we formulate the MCL localization approach using the Normal Distributions Transform (NDT) as an underlying representation for both map and sensor data. By relaxing the hard discretization assumption imposed by grid-map models and utilizing the piece-wise continuous NDT representation the proposed algorithm achieves substantially improved accuracy and repeatability. The proposed NDT-MCL algorithm is evaluated using offline data sets from both a laboratory and a real-world industrial environments. Additionally, we report a comparison of the proposed algorithm to grid-based MCL and to a commercial localization system when used in a closed-loop with the control system of an AGV platform. In all tests the proposed algorithm is demonstrated to provide performance superior to that of standard grid-based MCL and comparable to the performance of the commercial infrastructure based positioning system.</td>
</tr>
<tr id="bib_6696380" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6696380,
  author = {J. Saarinen and H. Andreasson and T. Stoyanov and A. J. Lilienthal},
  title = {Normal distributions transform Monte-Carlo localization (NDT-MCL)},
  booktitle = {2013 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2013},
  pages = {382-389},
  note = {Cited by 10, IEEE},
  url = {http://ieeexplore.ieee.org/document/6696380/},
  doi = {http://dx.doi.org/10.1109/IROS.2013.6696380}
}
</pre></td>
</tr>
<tr id="schilling2002mobile" class="entry">
	<td>Schilling, K., Roth, H., R&ouml;sch, O.J. and others</td>
	<td>Mobile mini-robots for engineering education <p class="infolinks">[<a href="javascript:toggleInfo('schilling2002mobile','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('schilling2002mobile','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td>Global J. of Engng. Educ<br/>Vol. 6(1), pp. 79-84&nbsp;</td>
	<td>article</td>
	<td><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.5970&rep=rep1&type=pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_schilling2002mobile" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Mobile robots provide a motivating and interesting tool to perform laboratory experiments within the context of mechatronics, microelectronics and control. Students study this particular example in system design and integration tasks at different levels of complexity. This paper describes a set of workshops in which mobile robots were constructed in order to introduce students by hands-on experiments to mechatronic systems and control system design. This was tackled in combination with a teleoperations environment for rovers. Such tele-education experiments in the area of telematics are addressed in the paper, as well as describing typical objectives, the mobile robot hardware and the exercises performed within such robotics workshops.</td>
</tr>
<tr id="bib_schilling2002mobile" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{schilling2002mobile,
  author = {Schilling, Klaus and Roth, Hubert and R&ouml;sch, Otto J and others},
  title = {Mobile mini-robots for engineering education},
  journal = {Global J. of Engng. Educ},
  publisher = {Citeseer},
  year = {2002},
  volume = {6},
  number = {1},
  pages = {79--84},
  note = {Cited by 28, Google Scholar},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.5970&amp;rep=rep1&amp;type=pdf}
}
</pre></td>
</tr>
<tr id="4058483" class="entry">
	<td>Schmitz, N., Koch, J., Proetzsch, M. and Berns, K.</td>
	<td>Fault-Tolerant 3D Localization for Outdoor Vehicles <p class="infolinks">[<a href="javascript:toggleInfo('4058483','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('4058483','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>2006 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 941-946&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2006.281771">DOI</a> <a href="http://ieeexplore.ieee.org/document/4058483/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_4058483" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper presents a robust Kalman-based localization for outdoor vehicles. Outdoor vehicles require a fault-tolerant system that can manage temporary unavailable sensor measurements. The sensor system of the vehicle consists of odometry, inertial measurement unit (IMU) and differential global positioning system (DGPS) receiver. The system allows full 3D localization including position, attitude and velocities. Final experiments showed the localization and navigation capabilities of the outdoor robot RAVON</td>
</tr>
<tr id="bib_4058483" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{4058483,
  author = {N. Schmitz and J. Koch and M. Proetzsch and K. Berns},
  title = {Fault-Tolerant 3D Localization for Outdoor Vehicles},
  booktitle = {2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2006},
  pages = {941-946},
  note = {Cited by 5, IEEE},
  url = {http://ieeexplore.ieee.org/document/4058483/},
  doi = {http://dx.doi.org/10.1109/IROS.2006.281771}
}
</pre></td>
</tr>
<tr id="Thrun2001" class="entry">
	<td>Thrun, S., Fox, D., Burgard, W. and Dellaert, F.</td>
	<td>Robust Monte Carlo localization for mobile robots <p class="infolinks">[<a href="javascript:toggleInfo('Thrun2001','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Thrun2001','bibtex')">BibTeX</a>]</p></td>
	<td>2001</td>
	<td>Artificial Intelligence<br/>Vol. 128(1-2), pp. 99-141&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S0004-3702(01)00069-8">DOI</a> <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.8488">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Thrun2001" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Mobile robot localization is the problem of determining a robot's pose from sensor data. This article presents a family of probabilistic localization algorithms known as Monte Carlo Localization (MCL). MCL algorithms represent a robot's belief by a set of weighted hypotheses (samples), which approximate the posterior under a common Bayesian formulation of the localization problem. Building on the basic MCL algorithm, this article develops a more robust algorithm called Mixture-MCL, which integrates two complimentary ways of generating samples in the estimation. To apply this algorithm to mobile robots equipped with range finders, a kernel density tree is learned that permits fast sampling. Systematic empirical results illustrate the robustness and computational efficiency of the approach. textcopyright 2001 Published by Elsevier Science B.V.</td>
</tr>
<tr id="bib_Thrun2001" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Thrun2001,
  author = {Thrun, Sebastian and Fox, Dieter and Burgard, Wolfram and Dellaert, Frank},
  title = {Robust Monte Carlo localization for mobile robots},
  journal = {Artificial Intelligence},
  year = {2001},
  volume = {128},
  number = {1-2},
  pages = {99--141},
  url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.8488},
  doi = {http://dx.doi.org/10.1016/S0004-3702(01)00069-8}
}
</pre></td>
</tr>
<tr id="5509295" class="entry">
	<td>Ulmen, J. and Cutkosky, M.</td>
	<td>A robust, low-cost and low-noise artificial skin for human-friendly robots <p class="infolinks">[<a href="javascript:toggleInfo('5509295','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('5509295','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>Robotics and Automation (ICRA), 2010 IEEE International Conference on, pp. 4836-4841&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2010.5509295">DOI</a> <a href="http://ieeexplore.ieee.org/document/5509295/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_5509295" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: As robots and humans move towards sharing the same environment, the need for safety in robotic systems is of growing importance. Towards this goal of human-friendly robotics, a robust, low-cost, low-noise capacitive force sensing array is presented with application as a whole body artificial skin covering. This highly scalable design provides excellent noise immunity, low-hysteresis, and has the potential to be made flexible and formable. Noise immunity is accomplished through the use of shielding and local sensor processing. A small and low-cost multivibrator circuit is replicated locally at each taxel, minimizing stray capacitance and noise coupling. Each circuit has a digital pulse train output, which allows robust signal transmission in noisy electrical environments. Wire count is minimized through serial or row-column addressing schemes, and the use of an open-drain output on each taxel allows hundreds of sensors to require only a single output wire. With a small set of interface wires, large arrays can be scanned hundreds of times per second and dynamic response remains flat over a broad frequency range. Sensor performance is evaluated on a bench-top version of a 4 × 4 taxel array in quasi-static and dynamic cases.</td>
</tr>
<tr id="bib_5509295" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{5509295,
  author = {Ulmen, J and Cutkosky, M},
  title = {A robust, low-cost and low-noise artificial skin for human-friendly robots},
  booktitle = {Robotics and Automation (ICRA), 2010 IEEE International Conference on},
  year = {2010},
  pages = {4836--4841},
  url = {http://ieeexplore.ieee.org/document/5509295/},
  doi = {http://dx.doi.org/10.1109/ROBOT.2010.5509295}
}
</pre></td>
</tr>
<tr id="ulrich2000appearance" class="entry">
	<td>Ulrich, I. and Nourbakhsh, I.</td>
	<td>Appearance-based obstacle detection with monocular color vision <p class="infolinks">[<a href="javascript:toggleInfo('ulrich2000appearance','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('ulrich2000appearance','bibtex')">BibTeX</a>]</p></td>
	<td>2000</td>
	<td>AAAI/Innovative Applications of Artificial Intelligence Conferences, pp. 866-871&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.aaai.org/Papers/AAAI/2000/AAAI00-133.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_ulrich2000appearance" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper presents a new vision-based obstacle detection method for mobile robots. Each individual image pixel is classified as belonging either to an obstacle or the ground based on its color appearance. The method uses a single passive color camera, performs in real-time, and provides a binary obstacle image at high resolution. The system is easily trained by simply driving the robot through its environment. In the adaptive mode, the system keeps learning the appearance of the ground during operation. The system has been tested successfully in a variety of environments, indoors as well as outdoors.</td>
</tr>
<tr id="bib_ulrich2000appearance" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{ulrich2000appearance,
  author = {Ulrich, Iwan and Nourbakhsh, Illah},
  title = {Appearance-based obstacle detection with monocular color vision},
  booktitle = {AAAI/Innovative Applications of Artificial Intelligence Conferences},
  year = {2000},
  pages = {866--871},
  note = {Cited by 311, Google Scholar},
  url = {http://www.aaai.org/Papers/AAAI/2000/AAAI00-133.pdf}
}
</pre></td>
</tr>
<tr id="Wachs:2011:VHA:1897816.1897838" class="entry">
	<td>Wachs, J.P., Kolsch, M., Stern, H. and Edan, Y.</td>
	<td>Vision-based Hand-gesture Applications <p class="infolinks">[<a href="javascript:toggleInfo('Wachs:2011:VHA:1897816.1897838','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Wachs:2011:VHA:1897816.1897838','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>Commun. ACM<br/>Vol. 54(2), pp. 60-71&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1145/1897816.1897838">DOI</a> <a href="http://doi.acm.org/10.1145/1897816.1897838">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Wachs:2011:VHA:1897816.1897838" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Here, we describe the requirements of hand-gesture interfaces and the challenges in meeting the needs of var- ious application types. System require- ments vary depending on the scope of the application; for example, an en- tertainment system does not need the gesture-recognition accuracy required of a surgical system. We divide these applications into four main classes—medical systems and assistive technologies; crisis man- agement and disaster relief; enter- tainment; and human-robot interac- tion—illustrating them through a set of examples. For each, we present the human factors and usability consider- ations needed to motivate use. Some techniques are simple, often lacking robustness in cluttered or dynamic scenarios, indicating the potential for further improvement. In each, the raw data is real-time video streams of hand gestures (vision-based), requiring ef- fective methods for capturing and processing images. (Not covered is the literature related to voice recognition and gaze-tracking control.)</td>
</tr>
<tr id="bib_Wachs:2011:VHA:1897816.1897838" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Wachs:2011:VHA:1897816.1897838,
  author = {Wachs, Juan Pablo and Kolsch, Mathias and Stern, Helman and Edan, Yael},
  title = {Vision-based Hand-gesture Applications},
  journal = {Commun. ACM},
  publisher = {ACM},
  year = {2011},
  volume = {54},
  number = {2},
  pages = {60--71},
  note = {Cited by 79, ACM},
  url = {http://doi.acm.org/10.1145/1897816.1897838},
  doi = {http://dx.doi.org/10.1145/1897816.1897838}
}
</pre></td>
</tr>
<tr id="626982" class="entry">
	<td>Ward, A., Jones, A. and Hopper, A.</td>
	<td>A new location technique for the active office <p class="infolinks">[<a href="javascript:toggleInfo('626982','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('626982','bibtex')">BibTeX</a>]</p></td>
	<td>1997</td>
	<td>IEEE Personal Communications<br/>Vol. 4(5), pp. 42-47&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/98.626982">DOI</a> <a href="http://ieeexplore.ieee.org/document/626982/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_626982" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Configuration of the computing and communications systems found at home and in the workplace is a complex task that currently requires the attention of the user. Researchers have begun to examine computers that would autonomously change their functionality based on observations of who or what was around them. By determining their context, using input from sensor systems distributed throughout the environment, computing devices could personalize themselves to their current user, adapt their behaviour according to their location, or react to their surroundings. The authors present a novel sensor system, suitable for large-scale deployment in indoor environments, which allows the locations of people and equipment to be accurately determined. We also describe some of the context-aware applications that might make use of this fine-grained location information</td>
</tr>
<tr id="bib_626982" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{626982,
  author = {A. Ward and A. Jones and A. Hopper},
  title = {A new location technique for the active office},
  journal = {IEEE Personal Communications},
  year = {1997},
  volume = {4},
  number = {5},
  pages = {42-47},
  note = {Cited by 487, IEEE},
  url = {http://ieeexplore.ieee.org/document/626982/},
  doi = {http://dx.doi.org/10.1109/98.626982}
}
</pre></td>
</tr>
<tr id="715187" class="entry">
	<td>Werb, J. and Lanzl, C.</td>
	<td>Designing a positioning system for finding things and people indoors <p class="infolinks">[<a href="javascript:toggleInfo('715187','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('715187','bibtex')">BibTeX</a>]</p></td>
	<td>1998</td>
	<td>IEEE Spectrum<br/>Vol. 35(9), pp. 71-78&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/6.715187">DOI</a> <a href="http://ieeexplore.ieee.org/document/715187/?arnumber=715187">URL</a>&nbsp;</td>
</tr>
<tr id="abs_715187" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Despite extraordinary advances in Global Positioning System (GPS) technology, millions of square meters of indoor space are out of reach of Navstar satellites. Their signals, originating high above the Earth, are not designed to penetrate most construction materials, and no amount of technical wizardry is likely to help. So the greater part of the world's commerce, being conducted indoors, cannot be followed by GPS satellites. Here, the authors describe how tracking people and assets indoors has now moved from the realm of science fiction to reality, thanks to a radiofrequency identification technique now being introduced to the market</td>
</tr>
<tr id="bib_715187" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{715187,
  author = {J. Werb and C. Lanzl},
  title = {Designing a positioning system for finding things and people indoors},
  journal = {IEEE Spectrum},
  year = {1998},
  volume = {35},
  number = {9},
  pages = {71-78},
  note = {Cited by 108 ,IEEE},
  url = {http://ieeexplore.ieee.org/document/715187/?arnumber=715187},
  doi = {http://dx.doi.org/10.1109/6.715187}
}
</pre></td>
</tr>
<tr id="407627" class="entry">
	<td>Wienkop, U., Lawitzky, G. and Feiten, W.</td>
	<td>Intelligent low-cost mobility <p class="infolinks">[<a href="javascript:toggleInfo('407627','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('407627','bibtex')">BibTeX</a>]</p></td>
	<td>1994</td>
	<td><br/>Vol. 3Intelligent Robots and Systems '94. 'Advanced Robotic Systems and the Real World', IROS '94. Proceedings of the IEEE/RSJ/GI International Conference on, pp. 1708-1715 vol.3&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.1994.407627">DOI</a> <a href="http://ieeexplore.ieee.org/abstract/document/407627/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_407627" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Autonomous low-cost mobility of robots has been a challenging problem for quite a long time. In this paper the typical problems of sonar based autonomous navigation and the authors' solutions to overcome them are discussed. The authors have created, robust modules for sonar data fusion and safe steering which significantly improve known methods. There are furthermore robot control behaviors which offer specific competence to solve high-level tasks. These behaviors build a hierarchical architecture but have the ability to assess their respective task and autonomously suggest a different, more competent behavior to continue. Thus, the behaviors work together as distributed competencies. The concept described here is being evaluated in a system on the authors' experimental robot ROAMER. The available modules already operate robustly in cluttered office environments</td>
</tr>
<tr id="bib_407627" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{407627,
  author = {U. Wienkop and G. Lawitzky and W. Feiten},
  title = {Intelligent low-cost mobility},
  booktitle = {Intelligent Robots and Systems '94. 'Advanced Robotic Systems and the Real World', IROS '94. Proceedings of the IEEE/RSJ/GI International Conference on},
  year = {1994},
  volume = {3},
  pages = {1708-1715 vol.3},
  note = {Cited by 1, IEEE},
  url = {http://ieeexplore.ieee.org/abstract/document/407627/},
  doi = {http://dx.doi.org/10.1109/IROS.1994.407627}
}
</pre></td>
</tr>
<tr id="1490685" class="entry">
	<td>Yamada, Y., Morizono, T., Umetani, Y. and Takahashi, H.</td>
	<td>Highly Soft Viscoelastic Robot Skin With a Contact Object-Location-Sensing Capability <p class="infolinks">[<a href="javascript:toggleInfo('1490685','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1490685','bibtex')">BibTeX</a>]</p></td>
	<td>2005</td>
	<td>IEEE Transactions on Industrial Electronics<br/>Vol. 52(4), pp. 960-968&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/TIE.2005.851654">DOI</a> <a href="http://ieeexplore.ieee.org/document/1490685/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_1490685" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper concerns the development of robot skin capable of accurately sensing the location of objects in area contact with the skin surface. There has been no report on tactile sensing which attained not only skin deformation detection but also contact object location sensing with high accuracy. In the category of optomechatronics technology, we apply optical fibers to transmit surface deformation information of soft skin for sensing the location of an object in contact with the soft skin accurately. In the paper, we illustrate the structure of the robot skin, and describe the principle of both detecting the position of the reflector chips and sensing the contact location of an object. The robot skin is characterized by the fact that the surface is low cost and easily replacable, and the sensing performance is robust against any electromagnetic disturbance. We then show experimental results for verifying the principles using a wedge-shaped object. For evaluating the sensing accuracy, comparisons are made: 1) between the location of a real convex of the object and that of the corresponding estimated polygon and 2) for the position of two vertices of the object when independent fitting and Lagrangian fitting methods are applied.</td>
</tr>
<tr id="bib_1490685" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{1490685,
  author = {Y. Yamada and T. Morizono and Y. Umetani and H. Takahashi},
  title = {Highly Soft Viscoelastic Robot Skin With a Contact Object-Location-Sensing Capability},
  journal = {IEEE Transactions on Industrial Electronics},
  year = {2005},
  volume = {52},
  number = {4},
  pages = {960-968},
  note = {Cited by 27, IEEE},
  url = {http://ieeexplore.ieee.org/document/1490685/},
  doi = {http://dx.doi.org/10.1109/TIE.2005.851654}
}
</pre></td>
</tr>
<tr id="6216365" class="entry">
	<td>Zhan, G. and Shi, W.</td>
	<td>LOBOT: Low-Cost, Self-Contained Localization of Small-Sized Ground Robotic Vehicles <p class="infolinks">[<a href="javascript:toggleInfo('6216365','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6216365','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>IEEE Transactions on Parallel and Distributed Systems<br/>Vol. 24(4), pp. 744-753&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/TPDS.2012.176">DOI</a> <a href="http://ieeexplore.ieee.org/document/6216365/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_6216365" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: It is often important to obtain the real-time location of a small-sized ground robotic vehicle when it performs autonomous tasks either indoors or outdoors. We propose and implement LOBOT, a low-cost, self-contained localization system for small-sized ground robotic vehicles. LOBOT provides accurate real-time, 3D positions in both indoor and outdoor environments. Unlike other localization schemes, LOBOT does not require external reference facilities, expensive hardware, careful tuning or strict calibration, and is capable of operating under various indoor and outdoor environments. LOBOT identifies the local relative movement through a set of integrated inexpensive sensors and well corrects the localization drift by infrequent GPS-augmentation. Our empirical experiments in various temporal and spatial scales show that LOBOT keeps the positioning error well under an accepted threshold.</td>
</tr>
<tr id="bib_6216365" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{6216365,
  author = {G. Zhan and W. Shi},
  title = {LOBOT: Low-Cost, Self-Contained Localization of Small-Sized Ground Robotic Vehicles},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  year = {2013},
  volume = {24},
  number = {4},
  pages = {744-753},
  note = {Cited by 4, IEEE},
  url = {http://ieeexplore.ieee.org/document/6216365/},
  doi = {http://dx.doi.org/10.1109/TPDS.2012.176}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 08/11/2016.</small>
</footer>
<!-- file generated by JabRef -->
</body>
</html>