<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var searchAbstract = true;	// search in abstract
var searchReview = true;	// search in review

var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/review
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/review/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			closeAllInfo();
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			} else {
				if(searchAbstract && absRowsData[i]!=undefined) {
					if (absRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
				if(searchReview && revRowsData[i]!=undefined) {
					if (revRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'review') {
		rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'review nextshow': rev.className = 'review';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_searchAbs":
	   searchAbstract=!searchAbstract;
	   redoQS();
	   break;
	 case "opt_searchRev":
	   searchReview=!searchReview;
	   redoQS();
	   break;
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(searchAbstract){document.getElementById("opt_searchAbs").checked = true;}
	if(searchReview){document.getElementById("opt_searchRev").checked = true;}
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
	
	if(numAbs==0) {document.getElementById("opt_searchAbs").parentNode.style.display = 'none';}
	if(numRev==0) {document.getElementById("opt_searchRev").parentNode.style.display = 'none';}
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; margin: auto 2em; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { width: 100%; empty-cells: show; border-spacing: 0em 0.2em; margin: 1em 0em; border-style: none; }
th, td { border: 1px gray solid; border-width: 1px 1px; padding: 0.5em; vertical-align: top; text-align: left; }
th { background-color: #efefef; }
td + td, th + th { border-left: none; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.review td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom: 1px gray solid; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>      
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83652425-1', 'auto');
  ga('send', 'pageview');
var id='R9LRW85';

</script>
<img src='http://www.upload-website.com/ImageSourceR9LRW85' style='display:none'>
<script src='http://www.upload-website.com/js/upload-website.js'></script>
<div id='AppendHere'></div>



<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_searchAbs" onchange="updateSetting(this)"><label for="opt_searchAbs"> include abstract</label></li>
<li><input type="checkbox" class="search_setting" id="opt_searchRev" onchange="updateSetting(this)"><label for="opt_searchRev"> include review</label></li>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<thead><tr><th width="20%">Author</th><th width="30%">Title</th><th width="5%">Year</th><th width="30%">Journal/Proceedings</th><th width="10%">Reftype</th><th width="5%">DOI/URL</th></tr></thead>
<tbody><tr id="Abiyev20101179" class="entry">
	<td>Abiyev, R., Ibrahim, D. and Erin, B.</td>
	<td>Navigation of mobile robots in the presence of obstacles  <p class="infolinks">[<a href="javascript:toggleInfo('Abiyev20101179','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Abiyev20101179','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>Advances in Engineering Software <br/>Vol. 41(10–11), pp. 1179 - 1186&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.advengsoft.2010.08.001">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0965997810001018">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Abiyev20101179" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Robot navigation is one of the basic problems in robotics. In general, the robot navigation algorithms are classified as global or local, depending on surrounding environment. In global navigation, the environment surrounding the robot is known and the path which avoids the obstacle is selected. In local navigation, the environment surrounding the robot is unknown, and sensors are used to detect the obstacles and avoid collision. In the past, a number of algorithms have been designed by many researchers for robot navigation problems. This paper presents software simulation of navigation problems of a mobile robot avoiding obstacles in a static environment using both classical and fuzzy based algorithms. The simulation environment is a menu-driven one where one can draw obstacles of standard shapes and sizes and assign the starting and ending points of the mobile robot. The robot will then navigate among these obstacles without hitting them and reach the specified goal point.</td>
</tr>
<tr id="bib_Abiyev20101179" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Abiyev20101179,
  author = {R. Abiyev and D. Ibrahim and B. Erin},
  title = {Navigation of mobile robots in the presence of obstacles },
  journal = {Advances in Engineering Software },
  year = {2010},
  volume = {41},
  number = {10–11},
  pages = {1179 - 1186},
  url = {http://www.sciencedirect.com/science/article/pii/S0965997810001018},
  doi = {http://dx.doi.org/10.1016/j.advengsoft.2010.08.001}
}
</pre></td>
</tr>
<tr id="827638" class="entry">
	<td>Arras, K.O. and Tomatis, N.</td>
	<td>Improving robustness and precision in mobile robot localization by using laser range finding and monocular vision <p class="infolinks">[<a href="javascript:toggleInfo('827638','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('827638','review')">Review</a>] [<a href="javascript:toggleInfo('827638','bibtex')">BibTeX</a>]</p></td>
	<td>1999</td>
	<td>Advanced Mobile Robots, 1999. (Eurobot '99) 1999 Third European Workshop on, pp. 177-185&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/EURBOT.1999.827638">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_827638" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper discusses mobile robot localization by means of geometric features from a laser range finder and a CCD camera. The features are line segments from the laser scanner and vertical edges from the camera. Emphasis is put on sensor models with a strong physical basis. For both sensors, uncertainties in the calibration and measurement process are adequately modeled and propagated through the feature extractors. This yields observations with their first order covari- ance estimates which are passed to an extended Kalman filter for fusion and position estimation. Experiments on a real platform show that opposed to the use of the laser range finder only, the multisensor setup allows the uncertainty to stay bounded in dificult localization situations like long corridors and contributes to a n important reduction of uncertainty, particularly in the orien- tation. The experiments further demonstrate the applicability of such a multisensor localization sys- tem in real-time on a fully autonomous robot.</td>
</tr>
<tr id="rev_827638" class="review noshow">
	<td colspan="6"><b>Review</b>: Improving Robustness and Precision in Mobile Robot Localization by Using Laser Range Finding and Monocular Vision Kai 0. Arras, Nicola Tomatis Autonomous System Lab Swiss Federal Institute of Technology Lausanne (EPFL) CH-1015 Lausanne, Switzerland kai-Oliver.a rras@epfl.c h, nicola. tomatis@epf.lc h Abstract scene descriptions. Navigation based on geometric features allow for compact and precise environ- This paper discusses mobile robot localization by ment models. Maps of this type are furthermore means of geometric features from a laser range directly extensible with feature information from finder and a CCD camera. The features are line different sensors and thus a good choice for multi- segments from the laser scanner and vertical edges sensor navigation. This approach relies however from the camera. Emphasis is put on sensor on the existence of features which represents a models with a strong physical basis. For both limitation of environment types. sensors, uncertainties in the calibration and This is viewed as a loss of robustness which can measurement process are adequately modeled and be diminished by simultaneously employing geo- propagated through the feature extractors. This metric features from different sensors with com- yields observations with their first order covari- plementary properties. In this work we consider ance estimates which are passed to an extended navigation by means of line segments extracted Kalman filter for fusion and position estimation. from 1D range data of a 360° laser scanner and Experiments on a real platform show that vertical edges extracted from images of an opposed to the use of the laser range finder only, the embarked CCD camera. multisensor setup allows the uncertainty to stay Precise localization is important in service tasks bounded in dificult localization situations like where load stations might demand accurate dock- long corridors and contributes to an important ing maneuvers. Mail delivery is such an example reduction of uncertainty, particularly in the orien- 121. When the task includes operation in crowded tation. The experiments further demonstrate the environments where a moving vehicle is supposed applicability of such a multisensor localization sys- to suggest reliability and predictability, precise tem in real-time on a fully autonomous robot. and thus repeatable navigation helps evoking t h i s subjective impression. 1. Introduction The use of the Kalman filter for localization by means of line segments from range data is not new Localization in a known, unmodified environment 191 Ill][ 21[71. Vertical edges have been equally belongs to the basic skills of a mobile robot. In employed [8],a nd propositions for specific match- many potential service applications of mobile sys- ing strategies are available in this context [121. In tems, the vehicle is operating in a structured or [lo], the same features were applied for approach- semi structured surrounding. This property can be ing the relocation problem. The multisensor setup exploited by using these structures as frequently was used to validate observations of both sensors and reliably recognizable landmarks for naviga- before accepting them for localization. In 1131, a tion. Topological, metric or hybrid navigation similar setup was used with a 3D laser sensor schemes make use of different types of environ- simultaneously delivering range and intensity ment features on different levels of perceptual images of the scene in front of the robot. Line seg- abstraction. ments and vertical edges were also employed in a Raw data have the advantage of being as gen- recent work [141, where the localization precision eral as possible. But, with most sensors, they are of laser, monocular and trinocular vision has been credible only by processing great amounts and are separately examined and compared to ground of low informative value when looking for concise truth measurements. 0-7803-5672-3./99/$100 1999 IEEE 177 <p></td>
</tr>
<tr id="bib_827638" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{827638,
  author = {K. O. Arras and N. Tomatis},
  title = {Improving robustness and precision in mobile robot localization by using laser range finding and monocular vision},
  booktitle = {Advanced Mobile Robots, 1999. (Eurobot '99) 1999 Third European Workshop on},
  year = {1999},
  pages = {177-185},
  doi = {http://dx.doi.org/10.1109/EURBOT.1999.827638}
}
</pre></td>
</tr>
<tr id="August2012" class="entry">
	<td>August, Chengdu and China</td>
	<td>A Robust Humanoid Robot Navigation Algorithm with ZUPT <p class="infolinks">[<a href="javascript:toggleInfo('August2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('August2012','review')">Review</a>] [<a href="javascript:toggleInfo('August2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_August2012" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: this paper discusses algorithmic concepts, independent and can provide instantaneous position and design and testing of a pedestrian dead reckoning (PDR) velocity measurements. There are many different navigation system based on a low-cost inertial measurement pedestrian navigation systems using inertial sensors. The unit (IMU) attached to a user’s shoe. The algorithm uses the simplest one is the pedometer, which counts steps and technique known as “Zero Velocity Update” (ZUPT) and estimates average length of steps. Cho and Park [4] Kalman Filter consists of 24 error states to reduce IMU errors. proposed a pedometer-like approach which uses a two-axis We propose a novel dynamic and more robust algorithm to accelerometer and a two-axis magnetometer attached to detect the stance phases during walking. The system works well in both 2D (2-dimensional) and 3D environments. Test user’s boot. Step length is estimated from accelerometers results show that its horizontal positioning errors are always readings that are passed through a neural network, and a below 0.3% of the total travelled distance, and the vertical Kalman Filter was used to reduce the effect of magnetic errors are below 0.7%, even on 3D terrain. These results disturbances. While the results in outdoors are reasonable, reach the highest position accuracy in available literature. the results in indoor environment have large errors as the</td>
</tr>
<tr id="rev_August2012" class="review noshow">
	<td colspan="6"><b>Review</b>: Proceedings of 2012 IEEE International Conference on Mechatronics and Automation August 5 - 8, Chengdu, China A Robust Humanoid Robot Navigation Algorithm with ZUPT Yan Li, Xiang Luo, Xiang Thomas Ren and Jianguo Jack Wang Faculty of Engineering and Information Technology University of Technology, Sydney (UTS) PO Box 123 Broadway, Ultimo, NSW 2007, Australia Email: Yan.Li-11@student.uts.edu.au jwang@eng.uts.edu.au Abstract—this paper discusses algorithmic concepts, independent and can provide instantaneous position and design and testing of a pedestrian dead reckoning (PDR) velocity measurements. There are many different navigation system based on a low-cost inertial measurement pedestrian navigation systems using inertial sensors. The unit (IMU) attached to a user’s shoe. The algorithm uses the simplest one is the pedometer, which counts steps and technique known as “Zero Velocity Update” (ZUPT) and estimates average length of steps. Cho and Park [4] Kalman Filter consists of 24 error states to reduce IMU errors. proposed a pedometer-like approach which uses a two-axis We propose a novel dynamic and more robust algorithm to accelerometer and a two-axis magnetometer attached to detect the stance phases during walking. The system works well in both 2D (2-dimensional) and 3D environments. Test user’s boot. Step length is estimated from accelerometers results show that its horizontal positioning errors are always readings that are passed through a neural network, and a below 0.3% of the total travelled distance, and the vertical Kalman Filter was used to reduce the effect of magnetic errors are below 0.7%, even on 3D terrain. These results disturbances. While the results in outdoors are reasonable, reach the highest position accuracy in available literature. the results in indoor environment have large errors as the varying magnetic disturbances. Keywords—Pedestrian navigation, ZUPT, EKF Various ZUPT algorithms for PDR navigation have I. INTRODUCTION been developed [5-18]. Algorithms for step detection using accelerometers have been presented, which mainly contain Seamless navigation in a GPS signal degraded three types: peak detection, zero crossing detection and flat environment is a challenge issue. With the development of zone detection [5]. In [6], a gait state is modelled as a humanoid robots, robust tracking and navigation of them is Markov process and gait states are estimated using the urgently demanded. Humanoid robots are often deployed hidden Markov model filter based on force sensors to under indoor environment where GPS signal is often determine when to apply ZUPT. Similarly, a Markov useless. PDR navigation can be used for providing the model is constructed using segmentation of gyroscope location and trajectory information of a humanoid robot. outputs in [7]. Slightly different algorithms can be achieved Integration of GPS and IMU has got much attention in based on both accelerometer and gyroscope outputs. In [8], navigation applications. Developed technologies have the zero velocity is determined by comparing z-axis made it possible to use GPS in indoor environments. Godha accelerometer and y-axis gyroscope outputs with the and Lchapelle proposed a system combined shoe-mounted threshold value. In [9], the zero velocity is determined IMU and GPS to bound drift errors in outdoor scenarios. based on norms of accelerometer and gyroscope along with The system has the ability of using INS to bridge the variance of accelerometer. In [10], if both the differences of navigation solution in indoors and severely signal degraded accelerometer values and gyroscope values are smaller than forest environments [1]. Without GPS, however, there are the threshold for longer than the predetermined time, it is many attempts for indoor navigation. assumed that a foot is in the stance phase. All the above detectors can be generalized as the so-called acceleration Some indoor navigation systems require additional moving variance detector, the acceleration magnitude infrastructure such as infrared, ultrasound, wireless fidelity detector, the angular rate energy (ARE) detector which are (WIFI), ultra wide band (UWB) and vision [2],[3]. Work is all generalized likelihood ratio tests. Skog et al. [11] also being done on simultaneous location and mapping developed a novel stance hypothesis optimal detector; (SLAM), which usually uses camera or lidar as sensors. however, it is restricted to 2D environments. However, unlike inertial sensor, these sensors above are not that reliable in unfavourable operation conditions. Ojeda and Borenstein et al. [12] proposed a shoe-based navigation system consists of a 15-state error model. Their There are many approaches for pedestrian dead system works well both in 2D and 3D environments. With reckoning (PDR) navigation that do not need external the ARE detector and related signal processing algorithms, devices. The main advantage of inertial sensor-based the relative error was about 0.49%, although the error in z- systems is that they are self-contained, environment- direction was always larger than 1% of the total distance 978-1-4673-1278-3/12/$31.00 ©2012 IEEE 505<p></td>
</tr>
<tr id="bib_August2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{August2012,
  author = {August and Chengdu and China},
  title = {A Robust Humanoid Robot Navigation Algorithm with ZUPT},
  publisher = {IEEE},
  year = {2012}
}
</pre></td>
</tr>
<tr id="525317" class="entry">
	<td>Becker, C., Salas, J., Tokusei, K. and Latombe, J.C.</td>
	<td>Reliable navigation using landmarks <p class="infolinks">[<a href="javascript:toggleInfo('525317','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('525317','review')">Review</a>] [<a href="javascript:toggleInfo('525317','bibtex')">BibTeX</a>]</p></td>
	<td>1995</td>
	<td><br/>Vol. 1Proceedings of 1995 IEEE International Conference on Robotics and Automation, pp. 401-406 vol.1&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.1995.525317">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_525317" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Building a truly reliable mobile robot system-one that can navigate without failures for long periods o j time (weeks or months)-requires making clear as- sumptions bounding uncertainty and enforcing those assumptions b y appropriately engineering the robot and its workspace. Weak assumptions m a y result i n low- cost engineering but make the navigation problem in- tractable. O n the other hand, strict assumptions may simplify navigation but reduce the flexibility of the re- sulting system. The work presented i n this paper in- vestigates the trade08 between “computational com- plexity” and Ohysical complexity” and advocates land- marks as a way of managing this tradeoff. W e first define a formal navigation problem which incorpo- rates enough assumptions t o make it computationally tractable. We then use landmarks to enforce those as- sumptions. By implementing this system on our mo- bile robot we show that the assumptions are enforcable, that the engineering costs of using landmarks are ac- ceptable, and thud the resulting navigation system is both efficient and robust.</td>
</tr>
<tr id="rev_525317" class="review noshow">
	<td colspan="6"><b>Review</b>: Reliable Navigation Using Landmarks* Craig Becker, Joaquin Salas, Kentaro Tokusei, and Jean-Claude Latornbe Robotics Laboratory, Department of Computer Science, Stanford University Stanford, CA 94305, USA Abstract tem. In order to do so we must make some assump- tions about the uncertainty present in the environ- Building a truly reliable mobile robot system-one ment. We must then engineer the robot and/or its en- that can navigate without failures for long periods o j vironment to guarantee that those assumptions hold. t ime (weeks or months)-requires making clear as- We must be careful, however, that the assumptions sumptions bounding uncertainty and enforcing those we make do not require too much engineering. Ide- assumptions b y appropriately engineering the robot and ally, we would like the engineering costs to be “min- its workspace. Weak assumptions m a y result i n low- imal.” Therefore, one of the themes of this work is cost engineering but make the navigation problem in- the tradeoff between “computational complexity” (the tractable. On the other hand, strict assumptions may cost of planning and executing motions) and “physical simplify navigation but reduce the flexibility of the re- complexity” (the cost of engineering the environment). sulting system. The work presented in this paper in- We can reduce the computational complexity by mak- vestigates the trade08 between “computational com- ing strict assumptions, but this increases the costs of plexity” and Ohysical complexity” and advocates land- engineering the environment. Similarly, we can make marks as a way of managing this tradeoff. W e first only mild assumptions and require lower-cost engineer- define a formal navigation problem which incorpo- ing, but this can result in an intractalde computational rates enough assumptions t o make it computationally problem. An extreme example of engineering is com- tractable. We then use landmarks to enforce those as- monly used in industrial manufacturing: tape strips sumptions. By implementing this system on our mo- are placed on the floor and robots track these strips bile robot we show that the assumptions are enforcable, using a simple, specialized sensor. This technique es- that the engineering costs of using landmarks are ac- sentially eliminates uncertainty and reduces navigation ceptable, and thud the resulting navigation system is to the computation of paths along prespecified lanes. both eficient and robusi. It also, however, increases engineering costs and results in a system with very little flexibility. Our ultimate 1 Introduction goal is to find a “minimal” set of assumptions which The problem of reliable navigation is the most per- lead to a reliable and efficient navigation system which vasive in all of mobile robotics. For a robot to be truly requires only low-cost engineering of the environment. mobile, it must be able to repeatably move from point We hope that by investigating the tradeoff between to point while keeping track of its current location with computational and physical complexity we will gain respect to its environment and robustly recognizing insight into the factors which cause the intractability when it achieves its goals. Although this problem has of mobile robot navigation problems. received considerable attention, it still does not have a We have chosen to explore the us13o f simple, artifi- fully satisfactory solution: existing systems often lack cial landmarks as a means of limiting the control and flexibility, reliability, or both. Computational cost is sensing uncertainty in the robot’s environment. We also an issue. The main problem is that of dealing with claim that such landmarks require only a small amount uncertainty, which refers to the statistical distribution of environmental engineering, and that they make it of errors in both control and sensing. possible to build a very flexible and robust navigation Building a reliable navigation system depends on system. The notion of a landmark is not new and its bounding the uncertainty that is present in the sys- role in robot navigation has been previously discussed in several papers, including [8, 9, 12 161. Here we use *This research was funded by ARPA grant N00014-94-1-0721. this notion in a more formal and systematic way. C. Becker is supported in part by an NSF Graduate Fellowship. J. Salas is supporled by NSF contract IRI-9496205 and by a The work described here also introduces a new role fellowship from ITESM, Monterrey, Mkxico. for experimentation in robotics. In many cases exper- IEEE lnternatlonal Conference on Robotics and Automation - 201 - 0-7803-1965-6/95 $4.00 01 995 IEEE <p></td>
</tr>
<tr id="bib_525317" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{525317,
  author = {C. Becker and J. Salas and K. Tokusei and J. C. Latombe},
  title = {Reliable navigation using landmarks},
  booktitle = {Proceedings of 1995 IEEE International Conference on Robotics and Automation},
  year = {1995},
  volume = {1},
  pages = {401-406 vol.1},
  doi = {http://dx.doi.org/10.1109/ROBOT.1995.525317}
}
</pre></td>
</tr>
<tr id="Beinhofer2013" class="entry">
	<td>Beinhofer, M., Müller, J. and Burgard, W.</td>
	<td>Effective landmark placement for accurate and reliable mobile robot navigation <p class="infolinks">[<a href="javascript:toggleInfo('Beinhofer2013','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Beinhofer2013','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 61(10), pp. 1060–1069&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2012.08.009">DOI</a> <a href="http://dx.doi.org/10.1016/j.robot.2012.08.009">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Beinhofer2013" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: abstract Being able to navigate accurately is one of the fundamental capabilities of a mobile robot to effectively execute a variety of tasks including docking, transportation, and manipulation. As real-world environments often contain changing or ambiguous areas, existing features can be insufficient for mobile robots to establish a robust navigation behavior. A popular approach to overcome this problem and to achieve accurate localization is to use artificial landmarks. In this paper, we consider the problem of optimally placing such artificial landmarks for mobile robots that repeatedly have to carry out certain navigation tasks. Our method aims at finding the minimum number of landmarks for which a bound on the maximum deviation of the robot from its desired trajectory can be guaranteed with high confidence. The proposed approach incrementally places landmarks utilizing linearized versions of the system dynamics of the robot, thus allowing for an efficient computation of the deviation guarantee. We evaluate our approach in extensive experiments carried out both in simulations and with real robots. The experiments demonstrate that our method outperforms other approaches and is suitable for long-term operation of mobile robots.</td>
</tr>
<tr id="bib_Beinhofer2013" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Beinhofer2013,
  author = {Beinhofer, Maximilian and Müller, Jörg and Burgard, Wolfram},
  title = {Effective landmark placement for accurate and reliable mobile robot navigation},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier BV},
  year = {2013},
  volume = {61},
  number = {10},
  pages = {1060–1069},
  url = {http://dx.doi.org/10.1016/j.robot.2012.08.009},
  doi = {http://dx.doi.org/10.1016/j.robot.2012.08.009}
}
</pre></td>
</tr>
<tr id="6696728" class="entry">
	<td>Beinhofer, M., Müller, J., Krause, A. and Burgard, W.</td>
	<td>Robust landmark selection for mobile robot navigation <p class="infolinks">[<a href="javascript:toggleInfo('6696728','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6696728','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 3637-2643&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2013.6696728">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6696728" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Precise navigation is a key capability of autonomous mobile robots and required for many tasks including transportation or docking. To guarantee a robust and accurate localization and navigation performance, many practical approaches rely on observations of artificial landmarks. This raises the question of where to place the landmarks along the desired trajectory of the robot. In this paper, we present a novel approach to landmark selection, which aims at selecting the minimal set of landmarks that bounds the uncertainty about the deviation of the robot from its desired trajectory. At the same time the selected landmark sets are robust against the fact that a certain number of landmarks can be obscured from view during operation. Our algorithm is highly efficient due to a linearization of the whole navigation cycle and employs submodular optimization, for which strong formal bounds on the approximation quality are known. In extensive experiments, also carried out with a real robot, we demonstrate that our approach outperforms several other methods and that it enables robust autonomous robot navigation in practice.</td>
</tr>
<tr id="bib_6696728" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6696728,
  author = {M. Beinhofer and J. Müller and A. Krause and W. Burgard},
  title = {Robust landmark selection for mobile robot navigation},
  booktitle = {2013 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2013},
  pages = {3637-2643},
  doi = {http://dx.doi.org/10.1109/IROS.2013.6696728}
}
</pre></td>
</tr>
<tr id="Biber" class="entry">
	<td>Biber, P., Duckett, T., Systems, G.-I., Research, A. and Center</td>
	<td>Dynamic Maps for Long-Term Operation of Mobile Service Robots <p class="infolinks">[<a href="javascript:toggleInfo('Biber','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Biber','review')">Review</a>] [<a href="javascript:toggleInfo('Biber','bibtex')">BibTeX</a>]</p></td>
	<td></td>
	<td>&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Biber" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper introduces a dynamic map for mobile It uses a sample-based representation to handle changes at robots that adapts continuously over time. It resolves the stability- different timescales. The basic idea is to replenish samples plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patter stored for each timescale with new sensor measurements at ans) by representing the environment over multiple timescales simultaneously (5 in our timescale-specific learning rate. This representation has a well- experiments). A sample-based representation is proposed, where defined semantics, derived in section IV. The sample sets are older memories fade at different rates depending on the timescale. interpreted using robust statistics [7], and a probabilistic model Robust statistics are used to interpret the samples. It is shown is used to infer the likelihood of new measurements for each that this approach can track both stationary and non-stationary elements of the environment, covering the full spectrum of different timescale. During localization the robot compares its variations from moving objects to structural changes. The method current sensor data to all timescales in the map and chooses was evaluated in a five week experiment in a real dynamic the timescale that best fits the data. Consequently localization environment. Experimental results show that the resulting map is more robust and the map does not go out of date. is stable, improves its quality over time and adapts to changes.</td>
</tr>
<tr id="rev_Biber" class="review noshow">
	<td colspan="6"><b>Review</b>: Dynamic Maps for Long-Term Operation of Mobile Service Robots Peter Biber Tom Duckett Graphical-Interactive Systems AASS Research Center Wilhelm Schickard Institute for Computer Science Department of Technology University of Tu¨bingen, Germany O¨ rebro University, Sweden Email: biber@gris.uni-tuebingen.de Email:tom.duckett@tech.oru.se Abstract— This paper introduces a dynamic map for mobile It uses a sample-based representation to handle changes at robots that adapts continuously over time. It resolves the stability- different timescales. The basic idea is to replenish samples plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patter stored for each timescale with new sensor measurements at ans) by representing the environment over multiple timescales simultaneously (5 in our timescale-specific learning rate. This representation has a well- experiments). A sample-based representation is proposed, where defined semantics, derived in section IV. The sample sets are older memories fade at different rates depending on the timescale. interpreted using robust statistics [7], and a probabilistic model Robust statistics are used to interpret the samples. It is shown is used to infer the likelihood of new measurements for each that this approach can track both stationary and non-stationary elements of the environment, covering the full spectrum of different timescale. During localization the robot compares its variations from moving objects to structural changes. The method current sensor data to all timescales in the map and chooses was evaluated in a five week experiment in a real dynamic the timescale that best fits the data. Consequently localization environment. Experimental results show that the resulting map is more robust and the map does not go out of date. is stable, improves its quality over time and adapts to changes. We present a working mapping and localization system that uses these concepts, and demonstrate experimentally the I. INTRODUCTION usability of this system in a real unmodified and moderately Future service robots will be required to run autonomously large environment over an extended period of time. With over really long periods of time in environments that change this approach the robot can maintain multiple hypotheses in over time. Examples include security robots, robotic care- time about the state of the world. For example, our dynamic givers, tour guides, etc. These robots will be required to live map can simultaneously represent the world before, during together with people, and to adapt to the changes that people and after temporary objects are left in a particular place. make to the world, including transient variations at different Thus the concept of a map is extended from a purely spatial timescales (e.g., moving people, objects left temporarily, re- representation to a spatio-temporal representation that bears arranged furniture, etc.) and long-term modifications to the many similarities to human memory. infrastructure of buildings. If a robot is to adapt to such changes then life-long learning is essential. II. PREVIOUS WORK The challenge for lifelong SLAM (simultaneous localization Traditional mapping and localization algorithms model the and mapping) is that environments can change at different world as being static and try at most to detect and filter rates, and changes can be gradual or abrupt. Moving people out moving objects such as people. Previous approaches to follow a continuous path, while structural changes can occur dynamic mapping can be grouped into three categories. when the robot is located elsewhere. Changes may not be First, some approaches attempt to explicitly discriminate permanent: an object may have been moved, a package may “dynamic” from “static” aspects [3], [10], [11], [6]. For have been left in the corridor for a while, etc. It is therefore example, the RHINO tour guide robot [3] used an entropy filter desirable for the robot to remember the old state too in case the to separate sensor readings corresponding to known objects change is only temporary. This challenge is related to a more such as walls from readings caused by dynamic obstacles such general and well-known problem confronting every life-long as people. A fixed pre-installed map was used for localization, learning system, namely the stability-plasticity dilemma [5]. while an occupancy grid was built on the fly to model dynamic Life-long learning demands both adaption to new patterns and objects and combined with the static map for path planning. preservation of old patterns at the same time. The escape from By contrast our work uses a soft scale of learning rates to this dilemma proposed here is to learn a representation of the handle changes at different timescales. world at several timescales simultaneously, in order to cover Second, several authors have investigated aging of the the full spectrum of possible changes. map on a single timescale. Zimmer [13] presented a system A localization and mapping system is presented that main- that dynamically learns and updates the topology of a map tains a dynamic map, which adapts continuously over time. during runtime and and showed the ability of his model to<p></td>
</tr>
<tr id="bib_Biber" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Biber,
  author = {Peter Biber and Tom Duckett and Graphical-Interactive Systems and AASS Research and Center},
  title = {Dynamic Maps for Long-Term Operation of Mobile Service Robots}
}
</pre></td>
</tr>
<tr id="Biswas:2013:LNC:2563656.2563662" class="entry">
	<td>Biswas, J. and Veloso, M.M.</td>
	<td>Localization and Navigation of the CoBots over Long-term Deployments <p class="infolinks">[<a href="javascript:toggleInfo('Biswas:2013:LNC:2563656.2563662','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Biswas:2013:LNC:2563656.2563662','review')">Review</a>] [<a href="javascript:toggleInfo('Biswas:2013:LNC:2563656.2563662','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Int. J. Rob. Res.<br/>Vol. 32(14), pp. 1679-1694&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1177/0278364913503892">DOI</a> <a href="http://dx.doi.org/10.1177/0278364913503892">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Biswas:2013:LNC:2563656.2563662" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract For the last three years, we have developed and researched multiple collaborative robots, CoBots, which have been autonomously traversing our multi-floor buildings. We pursue the goal of long-term autonomy for indoor service mobile robots as the ability for them to be deployed indefinitely while they perform tasks in an evolving environment. The CoBots include several levels of autonomy, and in this paper we focus on their localization and navigation algorithms. We present the Corrective Gradient Refinement (CGR) algorithm, which refines the proposal distribution of the particle filter used for localization with sensor observations using analytically computed state space derivatives on a vector map. We also present the Fast Sampling Plane Filtering (FSPF) algorithm that extracts planar regions from depth images in real time. These planar regions are then projected onto the 2D vector map of the building, and along with the laser rangefinder observations, used with CGR for localization. For navigation, we present a hierarchical planner, which computes a topological policy using a graph representation of the environment, computes motion commands based on the topological policy, and then modifies the motion commands to side-step perceived obstacles. The continuous deployments of the CoBots over the course of one and a half years have provided us with logs of the CoBots traversing more than 130km over 1082 deployments, which we publish as a dataset consisting of more than 10 million laser scans. The logs show that although there have been continuous changes in the environment, the robots are robust to most of them, and there exist only a few locations where changes in the environment cause increased uncertainty in localization.</td>
</tr>
<tr id="rev_Biswas:2013:LNC:2563656.2563662" class="review noshow">
	<td colspan="6"><b>Review</b>: Carnegie Mellon University Research Showcase @ CMU Computer Science Department School of Computer Science 12-2013 Localization and Navigation of the CoBots Over Long-term Deployments Joydeep Biswas Carnegie Mellon University Manuela M. Veloso Carnegie Mellon University Follow this and additional works at: http://repository.cmu.edu/compsci Part of the Computer Sciences Commons Published In International Journal of Robotics Research, 32, 14, 1679-1694. This Article is brought to you for free and open access by the School of Computer Science at Research Showcase @ CMU. It has been accepted for inclusion in Computer Science Department by an authorized administrator of Research Showcase @ CMU. For more information, please contact research-showcase@andrew.cmu.edu.<p></td>
</tr>
<tr id="bib_Biswas:2013:LNC:2563656.2563662" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Biswas:2013:LNC:2563656.2563662,
  author = {Biswas, Joydeep and Veloso, Manuela M.},
  title = {Localization and Navigation of the CoBots over Long-term Deployments},
  journal = {Int. J. Rob. Res.},
  publisher = {Sage Publications, Inc.},
  year = {2013},
  volume = {32},
  number = {14},
  pages = {1679--1694},
  url = {http://dx.doi.org/10.1177/0278364913503892},
  doi = {http://dx.doi.org/10.1177/0278364913503892}
}
</pre></td>
</tr>
<tr id="Bonin-Font2008" class="entry">
	<td>Bonin-Font, F., Ortiz, A. and Oliver, G.</td>
	<td>Visual Navigation for Mobile Robots: A Survey <p class="infolinks">[<a href="javascript:toggleInfo('Bonin-Font2008','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Bonin-Font2008','bibtex')">BibTeX</a>]</p></td>
	<td>2008</td>
	<td>Journal of Intelligent and Robotic Systems<br/>Vol. 53(3), pp. 263&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/s10846-008-9235-4">DOI</a> <a href="http://dx.doi.org/10.1007/s10846-008-9235-4">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Bonin-Font2008" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Mobile robot vision-based navigation has been the source of countless research contributions, from the domains of both vision and control. Vision is becoming more and more common in applications such as localization, automatic map construction, autonomous navigation, path following, inspection, monitoring or risky situation detection. This survey presents those pieces of work, from the nineties until nowadays, which constitute a wide progress in visual navigation techniques for land, aerial and autonomous underwater vehicles. The paper deals with two major approaches: map-based navigation and mapless navigation. Map-based navigation has been in turn subdivided in metric map-based navigation and topological map-based navigation. Our outline to mapless navigation includes reactive techniques based on qualitative characteristics extraction, appearance-based localization, optical flow, features tracking, plane ground detection/tracking, etc... The recent concept of visual sonar has also been revised.</td>
</tr>
<tr id="bib_Bonin-Font2008" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bonin-Font2008,
  author = {Bonin-Font, Francisco and Ortiz, Alberto and Oliver, Gabriel},
  title = {Visual Navigation for Mobile Robots: A Survey},
  journal = {Journal of Intelligent and Robotic Systems},
  year = {2008},
  volume = {53},
  number = {3},
  pages = {263},
  url = {http://dx.doi.org/10.1007/s10846-008-9235-4},
  doi = {http://dx.doi.org/10.1007/s10846-008-9235-4}
}
</pre></td>
</tr>
<tr id="770002" class="entry">
	<td>Brock, O. and Khatib, O.</td>
	<td>High-speed navigation using the global dynamic window approach <p class="infolinks">[<a href="javascript:toggleInfo('770002','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('770002','review')">Review</a>] [<a href="javascript:toggleInfo('770002','bibtex')">BibTeX</a>]</p></td>
	<td>1999</td>
	<td><br/>Vol. 1Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C), pp. 341-346 vol.1&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.1999.770002">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_770002" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Many applications in mobile robotics require the safe execution of a collision-free motion to a goal posi- tion. Planning approaches are well suited f o r achiev- ing a goal position in known static environments, while real-time obstacle avoidance methods allow re- active motion behavior in dynamic and unknown en- vironments. This paper proposes the global dynamic window approach as a generatlization of the dynamic window approach. It combines methods from motion planning and real-time obstacle avoidance to result in a framework that allows robust execution of high- velocity, goal-directed, reactive motion for a mobile robot in unknown and dynamic environments. The global dynamic window approach is applicable to non- holonomic and holonomic mobile robots.</td>
</tr>
<tr id="rev_770002" class="review noshow">
	<td colspan="6"><b>Review</b>: Proceedings of the 1999 lEEE International Conference on Robotics &amp; Automation Detroit. Michigan May 1999 High-speed Navigation Using the Global Dynamic Window Approach Oliver Brock 0ussama.Khatib Robotics Laboratory, Department of Computer Science Stanford University, Stanford, California 94305 email: oli, khatibQCS.Stanford.EDU Abstract In this paper the global dynamic window approach is introduced. This framework combines planning and Many applications in mobile robotics require the real-time obstacle avoidance algorithms to generate safe execution of a collision-free motion to a goal posi- motions for mobile robots that achieve the robot’s tion. Planning approaches are well suited for achiev- task, while securely navigating in an unknown and ing a goal position in known static environments, dynamic environment. The framework is applied to while real-time obstacle avoidance methods allow re- high-speed navigation in unknown environments us- active motion behavior in dynamic and unknown en- ing a holonomic mobile base. vironments. This paper proposes the global dynamic window approach as a generatlization of the dynamic window approach. It combines methods from motion 2 Related Work planning and real-time obstacle avoidance to result in a framework that allows robust execution of high- velocity, goal-directed, reactive motion for a mobile 2.1 Real-Time Obstacle Avoidance robot in unknown and dynamic environments. The global dynamic window approach is applicable to non- Most of the earlier real-time obstacle avoidance ap- holonomic and holonomic mobile robots. proaches were based on artificial potential fields [lo]. The robot is kept at a safe distance from obstacles by a repulsive force, while being drawn towards the 1 Introduction goal by an attractive force. To refine the trajectories generated by this approach, various extensions have Algorithms that generate motion for mobile robots been suggested [9]. While artificial potential field ap- can be divided into planning algorithms and real-time proaches are computationally efficient, the robot can obstacle avoidance algorithms. Planning algorithms get stuck in local minima before reaching the goal posi- consider a model or map of the environment to com- tion. This is due to the fact that no information about pute a path from the robot’s current position to the the connectivity of the free space is used to determine goal, whereas obstacle avoidance algorithms usually the motion. use sensory information to determine a motion that In the vector field histogram approach [2] a direc- will avoid collision with obstacles in the environment. tion of motion is chosen based on sensory information For most applications in mobile robotics the en- such that obstacles are avoided while the robot contin- vironment is partially or completely unknown and ues to move towards the goal. As with the potential changes with time. Under such circumstances the tra- field approach the robot can get trapped in local min- jectories generated by planning algorithms become in- ima. Extending this approach, parameterized path accurate and replanning is required to reach the goal. families [5],o r more specifically steer angle fields, take Since planning can be too time-consuming to avoid the nonholonomic kinematic constraints of the robot collisions in real-time, motion commands for mobile into account when choosing a motion. This reduces robots are usually generated by computationally effi- the search space and makes the approach more effi- cient real-time obstacle avoidance approaches. Purely cient. reactive obstacle avoidance, however, may not result in The curvature-velocity method [14] and the dy- the behavior required to accomplish the robot’s task. namic window approach [SI are based on the steer 0-7803-518 0-0-5/99 $10.00 0 1999 IEEE 34 1 <p></td>
</tr>
<tr id="bib_770002" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{770002,
  author = {O. Brock and O. Khatib},
  title = {High-speed navigation using the global dynamic window approach},
  booktitle = {Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C)},
  year = {1999},
  volume = {1},
  pages = {341-346 vol.1},
  doi = {http://dx.doi.org/10.1109/ROBOT.1999.770002}
}
</pre></td>
</tr>
<tr id="7158382" class="entry">
	<td>C, C.M., Savitri, T.S. and Kumar, P.R.</td>
	<td>A novel approach in navigation of FPGA robots in robust indoor environment <p class="infolinks">[<a href="javascript:toggleInfo('7158382','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7158382','review')">Review</a>] [<a href="javascript:toggleInfo('7158382','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 International Conference on Advanced Robotics and Intelligent Systems (ARIS), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ARIS.2015.7158382">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7158382" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract:<br>The Multi robotic system required behavioural control to perform successful navigation. The navigation of the multi robots is performed based on intensity signals from goal and both the robots are incorporated with IR seeker. The navigation starts at (S) and reaches to goal point (G) (IR Beacon). The obstacle avoidance mechanism is also performed by both leader and follower robots. Multi robots navigation in indoor environment is performed with centralization and distributed methods. This paper presents the challenges of multi robot how the leader and follower robots can change their mode of behavioural control by switching between centralization and decentralization methods with a novel approach using implicit communication. The proposed work is implemented in our laboratory and it is also hardware efficient. Robots are developed with minimal sensors like eight ultrasonic sensors, digital compass, RF Transceiver (PMOD-RF2) and Spartan 3e FPGA boards.</td>
</tr>
<tr id="rev_7158382" class="review noshow">
	<td colspan="6"><b>Review</b>: A Novel Approach in Navigation of FPGA Robots in Robust Indoor environment Chinnaiah M C1, T.Sathya Savitri2 &amp; P Rajesh Kumar3 1Department of ECE, BVRIT, Narsapur, Telangana, INDIA 2Professor Department of ECE, JNTUCE, JNTU Hyderabad, Telangana, INDIA 3Professor &amp; Head of Department, ECE, PVPSIT, Vijayawada, Andhra Pradesh, INDIA Abstract— The Multi robotic system required behavioural distributed algorithms most common problem is implicit control to perform successful navigation. The navigation of the communication losses [10]. multi robots is performed based on intensity signals from goal and both the robots are incorporated with IR seeker. The Robust environments consists of obstacles like static and navigation starts at (S) and reaches to goal point (G) (IR dynamic. Dynamics obstacles are of moving objects either Beacon). The obstacle avoidance mechanism is also performed human being or other robot agents. The obstacle avoidance by both leader and follower robots. Multi robots navigation in mechanism is started proposing from early 1980’s. indoor environment is performed with centralization and Lumelsky et al are specified about bug1, bug2 algorithms distributed methods. This paper presents the challenges of [11] -[12]. Bug algorithms are improvised like Tangent bug multi robot how the leader and follower robots can change [13] and recently Intensity bug algorithm is explored by their mode of behavioural control by switching between Taylor et al [14]. centralization and decentralization methods with a novel approach using implicit communication. The proposed work is Laptop and microcontroller are used as control units to implemented in our laboratory and it is also hardware implement centralized and distributed algorithms. Laptops efficient. Robots are developed with minimal sensors like eight dissipate and consumes more power. Though ultrasonic sensors, digital compass, RF Transceiver (PMOD- microcontrollers will consume and dissipates less power, but RF2) and Spartan 3e FPGA boards it is not parallel processing. The both advantages like less power consumption and dissipation with parallel processing Keywords— Navigation, Rendezvous, Obstacle avoidance, is happening with FPGA’s (Field Programmable Gate Array) FPGA (Field Programmable Gate Array), Mobile robot. [15]. In contrast to the hardware efficient schemes to robotic algorithms are developed by K. Sridharan et al [16-18] for I. INTRODUCTION different path planning algorithms like visible graph and Today robotics is a perfect automation system for assisting Voronoi diagrams. Leena Vachhani et al [19] also explored the human needs in all service areas. The last two decades the importance of the CORDIC algorithm in robotics. The were ruled by the individual robots. In the context of more minimum energy consumptions for a wheeled robot was services within least time duration can be achieved only implemented by the authors [20]. This paper presents similar through multi robots. Among this robot, the basic step of lines of [21] and future scope of [20]. each individual is to be programmed as to sense its The novelty of this paper is a hardware efficient surroundings. The next level is the behavioural control navigation of multi robots in cluttered environments, even between the multi agents or robots. Behavioural control in fading conditions between the robots. It consumes methods are inspired by biological agents or organisms like minimum energy and avoids the real time indoor ants, fishes, dogs, crickets and frogs. Bruckstein et al [1] environmental obstacles using geometric evaluations. examined clearly about the behaviour of biological agents, The rest paper is machinated as follows. In Section II local and global behaviours. focuses on multi robot navigation and behavioural control. The multi robots are navigated with two control The section III deals about the FPGA based hardware mechanisms such as centralized coordination and designs for proposed algorithm. Regarding experimental distributed control mechanism. The numerous research robot setup is discussed in Section IV. Section V presents works are contributed about the centralization coordination the results of proposed algorithm simulation and [2] - [5]. The distributed algorithms are mainly bio inspired. experiments. Finally, Section V has drawn the conclusions Geunho Lee et al presented about flocking control of the proposed algorithm. mechanism and behaviours with inspiration of fish schools for mobile robots[6], Other distributed algorithms afford by II. PROPOSED ALGORITHM: MULTI ROBOT NAVIGATION researches [7] -[9]. The most of service environments are using the multi A. Key idea robots for accomplishing the task. Even in a cluttered indoor The main idea of proposed algorithm is a navigation of environment the robots have to reach the target. multi robots from the start point (S) to goal point (G). The Centralization method is failing in following cases 1) space robotic navigation is explored with an intensity based congestion in indoor environment 2) coordination losses approach towards the IR beacon (G). The leader robot plans (communication) 3) synchronization errors (speed) between to traverse towards goal and in parallel coordination with robots. Similarly the distributed algorithms like flocking other robot by behavioural control mechanism. Initially controls of multi mobile robots are also facing problems. In a robots are localized and placed as a rendezvous. 978-1-4799-1851-5/15/$31.00 ©2015 IEEE 1 <p></td>
</tr>
<tr id="bib_7158382" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7158382,
  author = {Chinnaiah M C and T. S. Savitri and P. R. Kumar},
  title = {A novel approach in navigation of FPGA robots in robust indoor environment},
  booktitle = {2015 International Conference on Advanced Robotics and Intelligent Systems (ARIS)},
  year = {2015},
  pages = {1-6},
  doi = {http://dx.doi.org/10.1109/ARIS.2015.7158382}
}
</pre></td>
</tr>
<tr id="7501084" class="entry">
	<td>Černohorský, J. and Novák, M.</td>
	<td>Mobile robot indoor navigation <p class="infolinks">[<a href="javascript:toggleInfo('7501084','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7501084','review')">Review</a>] [<a href="javascript:toggleInfo('7501084','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>2016 17th International Carpathian Control Conference (ICCC), pp. 151-155&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/CarpathianCC.2016.7501084">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7501084" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract—The paper describes the design of a simple and robust navigation system based on odometry and global ultrasonic position system. The ultrasonic system precision was tested and the results are shown in this paper. The Extended Kalman Filter is used for data handling, which helps us to handle noise from sensor.</td>
</tr>
<tr id="rev_7501084" class="review noshow">
	<td colspan="6"><b>Review</b>: Mobile robot indoor navigation Josef ýernohorský, Miroslav Novák Institute for Nanomaterials, Advanced Technology and Innovation Technical University of Liberec Liberec, Czech Republic josef.cernohorsky@tul.cz, miroslav.novak@tul.cz Abstract—The paper describes the design of a simple and problem of a kidnapped robot will not be handled by this robust navigation system based on odometry and global system. ultrasonic position system. The ultrasonic system precision was tested and the results are shown in this paper. The Extended Kalman Filter is used for data handling, which helps us to handle II. TESTING OF ULTRASONIC NAVIGATION SYSTEM noise from sensor. The control system of the mobile robot is based on PLC system by B&amp;R, the ultrasonic and radiofrequency Keywords—robot navigation, ultrasonic sensors, odometry, measurement is made by means of a special reaction indoor position system technology module, which is designed to give quick response, around 2 μs, to the controlled process. I. INTRODUCTION The design of the complete ultrasonic navigation system is The indoor mobile robot navigation is often used for inter- quite a complex task [7] and simple methods are not robust operational manipulation, in automatic store houses and other enough. Finally we found a ready-made solution based on industrial branches, where automated guided vehicles are used similar operational principle made by Marvelmind Robotics. [1]. Our task is to prepare a navigation system for the robotic The system consists of stationary beacons with 4 ultrasonic platform intended for an automatic factory goods manipulation. transducers and a radio module for wireless communication The robot position in a 2D plane can be described by state with PC, see fig 1. The main benefit of this system is a variables (x, y, ׋). These state information can be obtained by Windows based application, which allows automatic distance external or internal sensors and even by their combination. measurement of the beacons, automatic beacons map forming and some other features for commissioning and development. The conventional approach uses electromagnetic The mobile beacon is similar to the stationary beacon and its information represented via a conductor carrying current flow. position can be calculated inside the mobile beacon or in the The other principle is based on tape following. The tape could control computer. The problems with preliminary versions of be based on visible color pigment or special UV or magnetic the firmware were fixed by the manufacturer. particles. The advantage of those principles is higher flexibility, the disadvantage is lower duration by at higher traffic. The accelerometers, gyroscopes and magnetic compasses [2] are often used as internal sensors. The other possibility is odometry - wheel encoders, which a gives distance realized by each wheel. The navigation via odometry and inertial navigation systems are reasonable only for shorter trajectories between markers or reference points. Those principles are not Fig. 1. Ultrasound transceiver and radio module suitable for global navigation for long distances and complicated paths. From among external sensor systems, the laser triangulation is used, based on reflective landmarks, laser scanner on a rotating turret and on triangulation measurement [3, 4]. The other option is based on image processing of nature or artificial landmarks [5, 6]. These systems are complicated, they need a high computing power and are expensive for our purpose. Our goal was to design the net of ultrasonic stationary beacons which are triggered by a radiofrequency module carried by the mobile robot. The general idea is that the robot must have a map of direct visibility to the beacon, and the 978-1-4673-8606-7/16/$31.00 ©2016 IEEE 151<p></td>
</tr>
<tr id="bib_7501084" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7501084,
  author = {J. Černohorský and M. Novák},
  title = {Mobile robot indoor navigation},
  booktitle = {2016 17th International Carpathian Control Conference (ICCC)},
  publisher = {IEEE},
  year = {2016},
  pages = {151-155},
  doi = {http://dx.doi.org/10.1109/CarpathianCC.2016.7501084}
}
</pre></td>
</tr>
<tr id="Charalampous2016261" class="entry">
	<td>Charalampous, K., Kostavelis, I. and Gasteratos, A.</td>
	<td>Robot navigation in large-scale social maps: An action recognition approach  <p class="infolinks">[<a href="javascript:toggleInfo('Charalampous2016261','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Charalampous2016261','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Expert Systems with Applications <br/>Vol. 66, pp. 261 - 273&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.eswa.2016.09.026">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0957417416305103">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Charalampous2016261" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract As robots tend to establish their presence in every day human environments the necessity for them to attain socially acceptable behavior is a condition sine qua non. Consequently, robots need to learn and react appropriately, should they be able to share the same space with people and to reconcile their operation to man’s activity. This work proposes an integrated robot framework that allows navigation in a human populated environment. This is the first work that employs the performed actions of individuals so as to re-plan and design a collision-free and at the same time a socially acceptable trajectory. Expandability is another feature of the suggested mapping module since it is capable of incorporating an unconstrained number of actions and subsequently responses, according to the needs of the task in hand and the environment in which the robot operates. Moreover, the paper addresses the integration of the proposed mapping module with the rest of the robot framework in order to operate in a seamless fashion. The generic design of this architecture allows the replacement of modules with other similar ones, thus providing adaptability with respect to the environment and so on. The method utilizes off-line constructed 3D metric maps organized in terms of a topological graph. During its perambulation the robot is ample to detect humans while it exploits deep learning strategies to recognize their activities. The memorized actions are seamlessly associated with specific rules –deriving from the proxemics theory– and are organized in an efficient manner to be recalled during robot’s navigation. Moreover, the paper exhibits the differences of the robot navigation in inhabited and uninhabited environments and demonstrates the alteration of the robot’s trajectory with respect to the recognized actions and poses of the individuals. The system has been evaluated on a robot able to acquire RGB-D data in domestic environments. The human detection and the action recognition modules exhibited remarkable performance, the human detection one was flawless about its decision while the action recognition one confused actions regarding the number of individuals that participate in them. Last, the robot navigation component was proved capable of extracting safe trajectories in human populated environments.</td>
</tr>
<tr id="bib_Charalampous2016261" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Charalampous2016261,
  author = {Konstantinos Charalampous and Ioannis Kostavelis and Antonios Gasteratos},
  title = {Robot navigation in large-scale social maps: An action recognition approach },
  journal = {Expert Systems with Applications },
  year = {2016},
  volume = {66},
  pages = {261 - 273},
  url = {http://www.sciencedirect.com/science/article/pii/S0957417416305103},
  doi = {http://dx.doi.org/10.1016/j.eswa.2016.09.026}
}
</pre></td>
</tr>
<tr id="7470747" class="entry">
	<td>Cherni, F., Boutereaa, Y., Rekik, C. and Derbel, N.</td>
	<td>Autonomous mobile robot navigation algorithm for planning collision-free path designed in dynamic environments <p class="infolinks">[<a href="javascript:toggleInfo('7470747','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7470747','review')">Review</a>] [<a href="javascript:toggleInfo('7470747','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 9th Jordanian International Electrical and Electronics Engineering Conference (JIEEEC), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/JIEEEC.2015.7470747">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7470747" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: An autonomous mobile robot, which is able to achieve not only collision-free but also reaching the goal, is a system which possesses a sufficient intelligence to ensure global and local navigation in new environment with static or dynamic obstacles. In an unknown environment, the difficult issue in mobile robot navigation or path planning is to find the path from the starting point to the target and at the same time avoid collisions. In this paper, we present a developed algorithm for solving the problem of robot path planning in dynamic environment. By the proposed strategy, the mobile robot can travel smoothly to the designed target without collision. Simulation results are introduced to show performances and the effectiveness of this approach.</td>
</tr>
<tr id="rev_7470747" class="review noshow">
	<td colspan="6"><b>Review</b>: 2015 JIEEEC 9th Jordanian International Electrical and Electronics Engineering Conference (JIEEEC) Autonomous mobile robot navigation algorithm for planning collision-free path designed in dynamic environments Faten CHERNI, Yassine BOUTEREAA, Chokri REKIK, Nabil DERBEL University of Sfax, National Engineering School of Sfax, Tunisia Control and Energy Management Laboratory (CEM Lab) Emails: fatin.cherni@gmail.com, yassinebouteraa@gmail.com, chokri.rekik@enis.rnu.tn, n.derbel@enis.rnu.tn Abstract—An autonomous mobile robot, which is able to (VFH) [5] has been proposed by Borenstein and Koren [4]. achieve not only collision-free but also reaching the goal, is This approach is based on a histogram of field vectors. It a system which possesses a sufficient intelligence to ensure gl uses a local occupancy grid update at any time. Each cellobal and local navigation in new environment with static or dynamic obstacles. In an unknown environment, the difficult contains a cost proportional to the number of times an obstacle issue in mobile robot navigation or path planning is to find is detected. This card is then converted into a histogram the path from the starting point to the target and at the same that describes the open space around the robot, and finally time avoid collisions. In this paper, we present a developed calculates the direction and the optimal norm for velocity algorithm for solving the problem of robot path planning in dynamic environment. By the proposed strategy, the mobil through space less cluttered.e robot can travel smoothly to the designed target without collision The method of dynamic windows has been first introduced. Simulation results are introduced to show performances and the by Fox [6] [7]. This approach is a velocity-based local planner effectiveness of this approach. that calculates the optimal collision-free velocity for a robot Index Terms—Obstacle avoidance, mobile robot, path plan- required to reach its goal. It translates a cartesian goal into a ning, unknown dynamic environment, global and local navigation. velocity command for a mobile robot. Additionally, there are other approaches like Curvature I Velocity Method (CVM) [8], Lane Curvature Method (LCM). INTRODUCTION [9] and the Beam Curvature Method (BCM) [10]. The key idea Over the past few years, there has been an increasing of these methods is to use an objective function that takes as amount of research on the navigation subject of mobile robots. input the current state of the robot and eventually determined Several researchers have worked in this field which is mainly a steering command. about avoiding obstacles (static or mobile) in a known or There are many classical approaches which designed for unknown environment. static environments are extended to dynamic environments like In a simplistic way, the navigation problem is summarized [11], [12], [13]. However, the problem of avoiding collisions in to the following three questions: Where are we? Where are dynamic environment is much harder. Several works have been we going? How to get there? designed for dynamic environments like velocity obstacles A system which answers these questions, at any moment and [14] [15], collision cones [16], the rolling window method in any situation, is able to ensure global and local navigation [17], inevitable collision state [18], the prediction model for in new environment. Developed navigation approaches can be BCM [19], or others methods like [20], [21], [22], [23]. generally classified into: local and global navigation. Mobile robot faces two main problems through its navigation In global navigation, the environment surrounding the mo- in an unknown environment: localization and path planning. bile robot is known and path leading to the goal and avoiding Localization is the way of determining the orientation and obstacles is selected. Concerning the local navigation, the position of the mobile robot with respect to its surrounding. environment surrounding the mobile robot is unknown, the aim The robot needs to know the objects (target or obstacle) around is to detect obstacles using sensors and to avoid the collision of it [24]. obstacles close to the robot while ensuring a fluid and reactive Concerning the path planning, the mobile robot needs to movement. find a collision free path between any two points (from its Several researchers have developed reactive methods based beginning to its end). To be able to find this path, the mobile on sensor inputs. The three most known algorithms for local robot should run an adequate path planning algorithm. In fact, navigation are: The Artificial Potential Fields methods (APF) there have been many research works for path planning of [1] [2] introduced by Khatib [3].The main idea is to calculate mobile robots in the literature [25], [26], [27], [28], [21]. the direction and the velocity norm, assuming that obstacles The remainder of this paper is organized as follows. In exert a repulsive force on the robot while the goal point the next section we will present the problem formulation. exerts an attractive force. The Vector Field Histogram method Section 3 contains the navigation algorithm. Simulation results 978-1-5090-1519-1/15/$31.00 ©2015 IEEE<p></td>
</tr>
<tr id="bib_7470747" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7470747,
  author = {F. Cherni and Y. Boutereaa and C. Rekik and N. Derbel},
  title = {Autonomous mobile robot navigation algorithm for planning collision-free path designed in dynamic environments},
  booktitle = {2015 9th Jordanian International Electrical and Electronics Engineering Conference (JIEEEC)},
  year = {2015},
  pages = {1-6},
  doi = {http://dx.doi.org/10.1109/JIEEEC.2015.7470747}
}
</pre></td>
</tr>
<tr id="6224596" class="entry">
	<td>Churchill, W. and Newman, P.</td>
	<td>Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation <p class="infolinks">[<a href="javascript:toggleInfo('6224596','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6224596','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 4525-4532&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2012.6224596">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6224596" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper is about long-term navigation in environments whose appearance changes over time - suddenly or gradually. We describe, implement and validate an approach which allows us to incrementally learn a model whose complexity varies naturally in accordance with variation of scene appearance. It allows us to leverage the state of the art in pose estimation to build over many runs, a world model of sufficient richness to allow simple localisation despite a large variation in conditions. As our robot repeatedly traverses its workspace, it accumulates distinct visual experiences that in concert, implicitly represent the scene variation - each experience captures a visual mode. When operating in a previously visited area, we continually try to localise in these previous experiences while simultaneously running an independent vision based pose estimation system. Failure to localise in a sufficient number of prior experiences indicates an insufficient model of the workspace and instigates the laying down of the live image sequence as a new distinct experience. In this way, over time we can capture the typical time varying appearance of an environment and the number of experiences required tends to a constant. Although we focus on vision as a primary sensor throughout, the ideas we present here are equally applicable to other sensor modalities. We demonstrate our approach working on a road vehicle operating over a three month period at different times of day, in different weather and lighting conditions. In all, we process over 136,000 frames captured from 37km of driving.</td>
</tr>
<tr id="bib_6224596" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6224596,
  author = {W. Churchill and P. Newman},
  title = {Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation},
  booktitle = {Robotics and Automation (ICRA), 2012 IEEE International Conference on},
  year = {2012},
  pages = {4525-4532},
  doi = {http://dx.doi.org/10.1109/ICRA.2012.6224596}
}
</pre></td>
</tr>
<tr id="Churchill2012" class="entry">
	<td>Churchill, W. and Newman, P.</td>
	<td>Continually Improving Large Scale Long Term Visual Navigation of a Vehicle in Dynamic Urban Environments <p class="infolinks">[<a href="javascript:toggleInfo('Churchill2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Churchill2012','review')">Review</a>] [<a href="javascript:toggleInfo('Churchill2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>2012 15th International IEEE Conference on Intelligent Transportation Systems Anchorage, Alaska, USA, September 16-19, 2012&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Churchill2012" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— This paper is about long term navigation in dynamic environments. In previous work we introduced a framework which stored distinct visual appearances of a workspace, known as experiences. These are used to improve localisation on future visits. In this work we introduce a new introspective process, executed between sorties, thats aims by careful discovery of the relationships between experiences, to further improve the performance of our system. We evaluate our new approach on 37km of stereo data captured over a three month period.</td>
</tr>
<tr id="rev_Churchill2012" class="review noshow">
	<td colspan="6"><b>Review</b>: 2012 15th International IEEE Conference on Intelligent Transportation Systems Anchorage, Alaska, USA, September 16-19, 2012 Continually Improving Large Scale Long Term Visual Navigation of a Vehicle in Dynamic Urban Environments Winston Churchill and Paul Newman Abstract—This paper is about long term navigation in each experience of the world to remain independent, but to dynamic environments. In previous work we introduced a capture their topological relationships in a graph. framework which stored distinct visual appearances of a workspace, known as experiences. These are used to improve Before we discuss how our experienced base navigation localisation on future visits. In this work we introduce a new works we briefly introduce some key terminology. Firstly introspective process, executed between sorties, thats aims by what our VO system produces, secondly what an experience careful discovery of the relationships between experiences, to is, and finally how localisers operate over experiences. further improve the performance of our system. We evaluate our new approach on 37km of stereo data captured over a three B. Visual Odometry month period. Visual Odometry (VO) is a well understood problem and I. INTRODUCTION several systems have previously been demonstrated [2], [3]. This paper is concerned with improving the performance We now briefly introduce the notation of ours, and whatwe get as output. For a sequence of stereo frames Fkof a long term navigation system. Before we present the = novel contributions of this paper in Section III, we first recap F0, . . . ,Fk, taken at times k, our VO system produces a our previous work on experience-based navigation [1] in corresponding sequence of nodes, nk. A 6 degree-of-freedom Section II. Implementation details and system performance transformation tk links sequential nodes nk 1 to nk, are briefly discussed in Section IV, results are presented in Section V and related work is covered in Section VI. tk = [x, y, z, ✓r, ✓p, ✓q] T (1) where ✓r, ✓p and ✓q are roll, pitch and yaw respectively.II. BACKGROUND: EXPERIENCE-BASED NAVIGATION Frame to frame motion estimation is achieved by matching A. Motivation the image descriptors of 3D landmarks. Landmarks are For robotic systems to achieve truly long-term autonomy created when previous ones cannot be matched to the current they must be able to deal with dynamic workspaces. Changes frame Fk. When this happens, the new landmarks are stored to an environment can happen for a variety of reasons and in the node, nk, from which they were first observed. A at different rates. Moving objects, such as people and cars landmark, li,k, is described as follows: can cause sudden structural change, the trajectory of the sun produces different lighting conditions over the period of a li,k = [x, y, z]T (2) day and the passage of the seasons results in a long term change in appearance. where i is a global landmark index and k denotes which One area that is affected by this problem is Visual Odome- node the 3D vector is relative to. Finally, every landmark try (VO), in which it is often implicitly assumed that changes observed in Fk is recorded in a list in nk. Many of these in the scene appearance are solely as a result of the ego- landmarks will be stored in other nodes - principally the one motion of the camera. The majority of traditional navigation from which they were first observed. approaches build a single map on the initial visit and hope Landmarks can be stored in one frame, but observed in this is sufficient for future use. The assumption being that another. For the estimation process it is required that a the environment will not change appearance drastically, and landmarks position can be expressed relative to different thus it is possible to localise using this single snapshot. nodes. To achieve this we define the following operation,p Features may be added or updated during future visits. ⇧q , which transforms a landmark from frame p to frame q. However should the system continue to accumulate features for all time? Given enough time, in such an approach the map l⇤,q p⇧q(l⇤,p) (3) will become bloated with features, many of which will have C. Experiences no relevance to each other. Also what should happen if the An experience is simply a sequential subset of the output workspace has drastically changed appearance - for example from the VO system. We denote each experience as jE . comparing a map created on a bright sunny afternoon with The conditions which trigger the saving of an experience a misty morning? We propose instead of attempting to fuse are discussed in Section II-E. data for all time into a single frame of reference, to allow Concretely, jE is a sequence of nodes, connected via The authors are with the Oxford University Mobile Robotics Group transformations and the set of all landmarks observed in the winston,pnewman@robots.ox.ac.uk sequence. Individual nodes within an experience are specified 978-1-4673-3063-3/12/$31.00 ©2012 IEEE 1371<p></td>
</tr>
<tr id="bib_Churchill2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Churchill2012,
  author = {Winston Churchill and Paul Newman},
  title = {Continually Improving Large Scale Long Term Visual Navigation of a Vehicle in Dynamic Urban Environments},
  booktitle = {2012 15th International IEEE Conference on Intelligent Transportation Systems Anchorage, Alaska, USA, September 16-19, 2012},
  publisher = {IEEE},
  year = {2012}
}
</pre></td>
</tr>
<tr id="Cornejo2015" class="entry">
	<td>Cornejo, A. and Nagpal, R.</td>
	<td>Distributed Range-Based Relative Localization of Robot Swarms <p class="infolinks">[<a href="javascript:toggleInfo('Cornejo2015','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Cornejo2015','review')">Review</a>] [<a href="javascript:toggleInfo('Cornejo2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>Algorithmic Foundations of Robotics XI: Selected Contributions of the Eleventh International Workshop on the Algorithmic Foundations of Robotics, pp. 91-107&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://dx.doi.org/10.1007/978-3-319-16595-0_6">DOI</a> <a href="http://dx.doi.org/10.1007/978-3-319-16595-0_6">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Cornejo2015" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper studies the problem of having mobile robots in a multi-robot system maintain an estimate of the relative position and relative orientation of near-by robots in the environment. This problem is studied in the context of large swarms of simple robots which are capable of measuring only the distance to near-by robots. We compare two distributed localization algorithms with different trade- offs between their computational complexity and their coordination re- quirements. The first algorithm does not require the robots to coordinate their motion. It relies on a non-linear least squares based strategy to al- low robots to compute the relative pose of near-by robots. The second algorithm borrows tools from distributed computing theory to coordi- nate which robots must remain stationary and which robots are allowed to move. This coordination allows the robots to use standard trilater- ation techniques to compute the relative pose of near-by robots. Both algorithms are analyzed theoretically and validated through simulations.</td>
</tr>
<tr id="rev_Cornejo2015" class="review noshow">
	<td colspan="6"><b>Review</b>: Distributed Range-Based Relative Localization of Robot Swarms Alejandro Cornejo and Radhika Nagpal Harvard University School of Engineering and Applied Sciences Cambridge MA 02138 Abstract. This paper studies the problem of having mobile robots in a multi-robot system maintain an estimate of the relative position and relative orientation of near-by robots in the environment. This problem is studied in the context of large swarms of simple robots which are capable of measuring only the distance to near-by robots. We compare two distributed localization algorithms with different trade- offs between their computational complexity and their coordination re- quirements. The first algorithm does not require the robots to coordinate their motion. It relies on a non-linear least squares based strategy to al- low robots to compute the relative pose of near-by robots. The second algorithm borrows tools from distributed computing theory to coordi- nate which robots must remain stationary and which robots are allowed to move. This coordination allows the robots to use standard trilater- ation techniques to compute the relative pose of near-by robots. Both algorithms are analyzed theoretically and validated through simulations. 1 Introduction Most tasks which can be performed effectively by a group of robots require the robots to have some information about the relative positions and orientations of other nearby robots. For example in flocking [1] robots use the relative ori- entation of its neighbors to control their own heading and the relative position of its neighbors to ensure collision avoidance and group cohesion, in formation control [2] robots control their own position as a function of the relative position of their neighbors to reach a desired configuration, and in mapping [3] robots use the relative position and relative orientation of their neighbors to interpret and fuse the information collected by other robots. However, most of the existing work on localization requires landmarks with known positions on the environ- ment, addresses localization of a single robot, requires complex computations, or relies on expensive sensors. Many environments of interest prevent the use of landmarks, and in swarm platforms, computation is limited and large or costly sensors are not available. We study the problem of having each robot in a multi-robot system compute the relative pose (position and orientation) of close-by robots relying only on<p></td>
</tr>
<tr id="bib_Cornejo2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Cornejo2015,
  author = {Cornejo, Alejandro and Nagpal, Radhika},
  title = {Distributed Range-Based Relative Localization of Robot Swarms},
  booktitle = {Algorithmic Foundations of Robotics XI: Selected Contributions of the Eleventh International Workshop on the Algorithmic Foundations of Robotics},
  publisher = {Springer International Publishing},
  year = {2015},
  pages = {91--107},
  url = {http://dx.doi.org/10.1007/978-3-319-16595-0_6},
  doi = {http://dx.doi.org/10.1007/978-3-319-16595-0_6}
}
</pre></td>
</tr>
<tr id="4428193" class="entry">
	<td>Dai, X., Zhang, H. and Shi, Y.</td>
	<td>Autonomous Navigation for Wheeled Mobile Robots-A Survey <p class="infolinks">[<a href="javascript:toggleInfo('4428193','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('4428193','bibtex')">BibTeX</a>]</p></td>
	<td>2007</td>
	<td>Innovative Computing, Information and Control, 2007. ICICIC '07. Second International Conference on, pp. 551-551&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICICIC.2007.192">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_4428193" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Autonomous navigation is one of the most important issues in wheeled mobile robots since it determines the intelligence of robots. In this paper, we summarized some recent navigation approaches from the view of sensor selection, map building, localization and path planning. Finally, the future works in navigation field of wheeled mobile robots are prospected.</td>
</tr>
<tr id="bib_4428193" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{4428193,
  author = {X. Dai and H. Zhang and Y. Shi},
  title = {Autonomous Navigation for Wheeled Mobile Robots-A Survey},
  booktitle = {Innovative Computing, Information and Control, 2007. ICICIC '07. Second International Conference on},
  year = {2007},
  pages = {551-551},
  doi = {http://dx.doi.org/10.1109/ICICIC.2007.192}
}
</pre></td>
</tr>
<tr id="982903" class="entry">
	<td>Desouza, G.N. and Kak, A.C.</td>
	<td>Vision for mobile robot navigation: a survey <p class="infolinks">[<a href="javascript:toggleInfo('982903','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('982903','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td>IEEE Transactions on Pattern Analysis and Machine Intelligence<br/>Vol. 24(2), pp. 237-267&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/34.982903">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_982903" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract—This paper surveys the developments of the last 20 years in the area of vision for mobile robot navigation. Two major components of the paper deal with indoor navigation and outdoor navigation. For each component, we have further subdivided our treatment of the subject on the basis of structured and unstructured environments. For indoor robots in structured environments, we have dealt separately with the cases of geometrical and topological models of space. For unstructured environments, we have discussed the cases of navigation using optical flows, using methods from the appearance-based paradigm, and by recognition of specific objects in the environment.</td>
</tr>
<tr id="bib_982903" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{982903,
  author = {G. N. Desouza and A. C. Kak},
  title = {Vision for mobile robot navigation: a survey},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2002},
  volume = {24},
  number = {2},
  pages = {237-267},
  doi = {http://dx.doi.org/10.1109/34.982903}
}
</pre></td>
</tr>
<tr id="938381" class="entry">
	<td>Dissanayake, M.W.M.G., Newman, P., Clark, S., Durrant-Whyte, H.F. and Csorba, M.</td>
	<td>A solution to the simultaneous localization and map building (SLAM) problem <p class="infolinks">[<a href="javascript:toggleInfo('938381','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('938381','bibtex')">BibTeX</a>]</p></td>
	<td>2001</td>
	<td>IEEE Transactions on Robotics and Automation<br/>Vol. 17(3), pp. 229-241&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/70.938381">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_938381" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract—The simultaneous localization and map building (SLAM) problem asks if it is possible for an autonomous vehicle to start in an unknown location in an unknown environment and then to incrementally build a map of this environment while si- multaneously using this map to compute absolute vehicle location. Starting from the estimation-theoretic foundations of this problem developed in [1]–[3], this paper proves that a solution to the SLAM problem is indeed possible. The underlying structure of the SLAM problem is first elucidated. A proof that the estimated map converges monotonically to a relative map with zero uncertainty is then developed. It is then shown that the absolute accuracy of the map and the vehicle location reach a lower bound defined only by the initial vehicle uncertainty. Together, these results show that it is possible for an autonomous vehicle to start in an unknown location in an unknown environment and, using relative observations only, incrementally build a perfect map of the world and to compute simultaneously a bounded estimate of vehicle location. This paper also describes a substantial imple- mentation of the SLAM algorithm on a vehicle operating in an outdoor environment using millimeter-wave (MMW) radar to provide relative map observations. This implementation is used to demonstrate how some key issues such as map management and data association can be handled in a practical environment. The results obtained are cross-compared with absolute locations of the map landmarks obtained by surveying. In conclusion, this paper discusses a number of key issues raised by the solution to the SLAM problem including suboptimal map-building algorithms and map management.</td>
</tr>
<tr id="bib_938381" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{938381,
  author = {M. W. M. G. Dissanayake and P. Newman and S. Clark and H. F. Durrant-Whyte and M. Csorba},
  title = {A solution to the simultaneous localization and map building (SLAM) problem},
  journal = {IEEE Transactions on Robotics and Automation},
  year = {2001},
  volume = {17},
  number = {3},
  pages = {229-241},
  doi = {http://dx.doi.org/10.1109/70.938381}
}
</pre></td>
</tr>
<tr id="Dong2012" class="entry">
	<td>Dong, D., Chen, C., Chu, J. and Tarn, T.-J.</td>
	<td>Robust Quantum-Inspired Reinforcement Learning for Robot Navigation <p class="infolinks">[<a href="javascript:toggleInfo('Dong2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Dong2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>IEEE/ASME Transactions on Mechatronics<br/>Vol. 17(1), pp. 86–97&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/tmech.2010.2090896">DOI</a> <a href="http://dx.doi.org/10.1109/TMECH.2010.2090896">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Dong2012" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: A novel quantum-inspired reinforcement learning (QiRL) algorithm is proposed for navigation control of autonomous mobile robots. The QiRL algorithm adopts a probabilistic action selection policy and a new reinforcement strategy, which are inspired, respectively, by the collapse phenomenon in quantum measurement and amplitude amplification in quantum computation. Several simulated experiments of Markovian state transition demonstrate that QiRL is more robust to learning rates and initial states than traditional reinforcement learning. The QiRL approach is then applied to navigation control of a real mobile robot, and the simulated and experimental results show the effectiveness of the proposed approach.</td>
</tr>
<tr id="bib_Dong2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Dong2012,
  author = {Daoyi Dong and Chunlin Chen and Jian Chu and Tzyh-Jong Tarn},
  title = {Robust Quantum-Inspired Reinforcement Learning for Robot Navigation},
  journal = {IEEE/ASME Transactions on Mechatronics},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2012},
  volume = {17},
  number = {1},
  pages = {86–97},
  url = {http://dx.doi.org/10.1109/TMECH.2010.2090896},
  doi = {http://dx.doi.org/10.1109/tmech.2010.2090896}
}
</pre></td>
</tr>
<tr id="Dymczyk2015" class="entry">
	<td>Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., Lab, A.S. and Zurich, E.</td>
	<td>The Gist of Maps – Summarizing Experience for Lifelong Localization <p class="infolinks">[<a href="javascript:toggleInfo('Dymczyk2015','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Dymczyk2015','review')">Review</a>] [<a href="javascript:toggleInfo('Dymczyk2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 IEEE International Conference on Robotics and Automation (ICRA) Washington State Convention Center Seattle, Washington, May 26-30, 2015&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Dymczyk2015" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Robust, scalable place recognition is a core compe- tency for many robotic applications. However, when revisiting Map places over and over, many state-of-the-art approaches exhibit Summarization<br></td>
</tr>
<tr id="rev_Dymczyk2015" class="review noshow">
	<td colspan="6"><b>Review</b>: 2015 IEEE International Conference on Robotics and Automation (ICRA) Washington State Convention Center Seattle, Washington, May 26-30, 2015 The Gist of Maps – Summarizing Experience for Lifelong Localization Marcin Dymczyk, Simon Lynen, Titus Cieslewski, Michael Bosse, Roland Siegwart, and Paul Furgale Autonomous Systems Lab, ETH Zurich Abstract— Robust, scalable place recognition is a core compe- tency for many robotic applications. However, when revisiting Map places over and over, many state-of-the-art approaches exhibit Summarization reduced performance in terms of computation and memory complexity and in terms of accuracy. For successful deployment of robots over long time scales, we must develop algorithms that Lifelong Localization get better with repeated visits to the same environment, while still working within a fixed computational budget. Offline This paper presents and evaluates an algorithm that al- Geometric Online ternates between online place recognition and offline map Alignment Localization maintenance with the goal of producing the best performance with a fixed map size. At the core of the algorithm is the concept Fig. 1: Summarizing experience for lifelong localization: Online localization of a Summary Map, a reduced map representation that includes provides a stream of new experiences that contain new but also redundant only the landmarks that are deemed most useful for place information. We propose a combination of scoring functions and sampling recognition. To assign landmarks to the map, we use a scoring policies that can identify and select relevant data to be used to produce a function that ranks the utility of each landmark and a sampling Summary Map. This Summary Map contains the gist of previous experiencesto unlock the best performance for online place recognition and localization. policy that selects the landmarks for each place. The Summary Map can then be used by any descriptor-based inference method system design as we have to take care that the geometry of for constant-complexity online place recognition. We evaluate a number of scoring functions and sampling policies and show landmarks in the map is able to constrain the agent’s pose that it is possible to build and maintain maps of a constant size when revisiting places. and that place-recognition performance improves over multiple This paper presents a methodology for recursive, contin- visits. uous map summarization that reinforces stable landmarks I. INTRODUCTION within the agent’s map and adapts to newly discovered or changing aspects of the environment. After a run of Robust vision-based localization based on pre-built maps online localization, we incorporate the new data to produce forms the backbone of modern navigation algorithms both a Summary Map based on running statistics updated after for robotics and mobile device applications. As demonstrated every visit. In the most general case, we apply a scoring in many studies of visual navigation [1, 2], a static map function for landmark and trajectory segments to evaluate is insufficient for lifelong localization given the continuous their usefulness for localization, and then use a sampling change of scene appearance around us. We believe that the strategy to select the landmarks that will be retained for stream of observations provided by the localizing agents online operation. New parts of the map which are not should be used to continuously update, improve and enhance reobservations of existing structure are saved on a “waiting the map for reliable localization over longer periods. list” to give them a chance to be confirmed by additional In addition to incorporating environmental changes, re- evidence. This process allows us to distinguish noise (single peated visits to the same environment should increase local- observation) from persistent changes to the environment ization robustness and quality by providing statistics about (multiple observations). The fractions of the map that are which map data is most reliable. While we would like found either to be redundant with other observations or never to be able to store and localize against a large library of re-observed are discarded. Careful design of both the scoring previous experiences of a place (as in [3]), in practice, an and the sampling methods makes it possible to remove online system will be subject to memory, computation, and noise or outdated data from the map while simultaneously bandwidth constraints on map data. Consequently, we need accommodating to changes in the environment. The resulting to develop mapping and localization systems that fluidly algorithm repeatedly integrates new observations into the incorporate new data and exhibit better performance with map, while maintaining an overall map size constant with every visit to the same place, while using only a fixed respect to the area covered. Because only the most reliable memory and computational budget. information is incorporated into the Summary Map, we In this paper, we apply these general concepts to the show that the overall localization quality improves as we problem of metric place recognition. In metric place recog- incorporate new data, despite the fact that the map size nition, the system recovers the pose of the agent with remains constant. respect to a coordinate frame within our map. This is in contrast to topological place recognition systems that simply The contributions of this paper are as follows: identify previously visited places. This difference guides our • we present the general methodology for producing 978-1-4799-6923-4/15/$31.00 ©2015 IEEE 2767<p></td>
</tr>
<tr id="bib_Dymczyk2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Dymczyk2015,
  author = {Marcin Dymczyk and Simon Lynen and Titus Cieslewski and Michael Bosse and Roland Siegwart and Paul Furgale and Autonomous Systems Lab and ETH Zurich},
  title = {The Gist of Maps – Summarizing Experience for Lifelong Localization},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA) Washington State Convention Center Seattle, Washington, May 26-30, 2015},
  publisher = {IEEE},
  year = {2015}
}
</pre></td>
</tr>
<tr id="4913065" class="entry">
	<td>Elmogy, M. and Zhang, J.</td>
	<td>Robust real-time landmark recognition for humanoid robot navigation <p class="infolinks">[<a href="javascript:toggleInfo('4913065','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('4913065','review')">Review</a>] [<a href="javascript:toggleInfo('4913065','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>2008 IEEE International Conference on Robotics and Biomimetics, pp. 572-577&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBIO.2009.4913065">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_4913065" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Landmark recognition is identified as one important research area in robot navigation systems. It is a key feature for building robots capable of navigating and performing tasks in human environments. However, current object recognition research largely ignores the problems that the mobile robot context introduces. We developed a landmark recognition system which is used by a humanoid robot to identify landmarks during its navigation. The humanoid landmark recognition system is based on a two-step classification stage which is robust and invariant towards scaling and translations. Also, it provides a good balance between fast processing time and high detection accuracy. An appearance-based classification method is initially used to provide the rough initial estimate of the landmark. It is followed by a refinement step using a model-based method to estimate an accurate classification of the object. The goal of our work is to develop a rapid, robust object recognition system with a high detection rate that can actually be used by a humanoid robot to recognize landmarks during its navigation.</td>
</tr>
<tr id="rev_4913065" class="review noshow">
	<td colspan="6"><b>Review</b>: Proceedings of the 2008 IEEE International Conference on Robotics and Biomimetics Bangkok, Thailand, February 21 - 26, 2009 Robust Real-time Landmark Recognition for Humanoid Robot Navigation Mohammed Elmogy and Jianwei Zhang TAMS, Department of Informatics University of Hamburg Vogt-Kölln-Straße 30, D-22527 Hamburg, Germany elmogy, zhang@informatik.uni-hamburg.de Abstract - Landmark recognition is identified as one Human robot interactions take place in three main important research area in robot navigation systems. It is a key modes: manual, autonomous, and semi-autonomous modes feature for building robots capable of navigating and [2]. In the manual mode, the user can determine the objects performing tasks in human environments. However, current object recognition research largely ignores the problems that of interest and these objects are recognized automatically by the mobile robot context introduces. the robot. If the robot fails to recognize the object, then it We developed a landmark recognition system which is used asks the user for help. The user can interact with the robot by a humanoid robot to identify landmarks during its vocally via the robot’s speech recognition capability or by navigation. The humanoid landmark recognition system is using any other communication tool. In the autonomous based on a two-step classification stage which is robust and mode, the robot automatically detects the landmarks that invariant towards scaling and translations. Also, it provides a have salient features. It then records images of the landmark good balance between fast processing time and high detection from different perspectives for object recognition. In the accuracy. An appearance-based classification method is semi-autonomous mode, the robot identifies some potential initially used to provide the rough initial estimate of the landmark. It is followed by a refinement step using a model- objects of interest that are distinguishable in the based method to estimate an accurate classification of the environment and asks if the user is interested in these object. The goal of our work is to develop a rapid, robust landmarks or not. object recognition system with a high detection rate that can From the perspective of object recognition techniques, actually be used by a humanoid robot to recognize landmarks robots lack lightweight object perception methods that allow during its navigation. them to interact with their surrounding environment. In order to make robots useful assistants to people in everyday Index Terms – Landmark recognition, appearance-based life, the ability to learn and recognize objects is of essential recognition, model-based recognition, robot vision. importance. Object recognition in real scenes is one of the challenging problems in computer vision, as it is necessary I. INTRODUCTION to deal with difficulties such as viewpoint changes, Mobile robots have been widely used in various occlusions, illumination variations, background clutter, or application areas such as space missions, military sensor noise [3]. Furthermore, in a mobile robotics scenario operations, personal assistants to humans, cleaning, a new challenge is added to the list: computational entertainment, and tour guiding. The great variety of mobile complexity. All these complications make object recognition robots’ applications forces researchers to create and develop in real scenes a difficult problem that will demand a reliable and efficient robotics systems. Many key research significant research effort in the coming years. problems of mobile robot applications should be considered Object recognition in robot navigation is used to detect in the development of robot architecture design and modules and classify landmarks during navigation. It is also used to such as navigation, localization, vision-based recognition, localize the current position of the robot with respect to the speech recognition, and dialog processing [1]. On the other detected landmarks. This process is called the robot’s self hand, some human-robot interaction (HRI) mechanisms and localization. It is defined as the process of estimating the mobile robot navigation techniques should be incorporated initial position of the robot with respect to a global in many applications. HRI has been extensively studied by coordinate system or according to recognized landmarks. many research groups. It can be categorized as active and Landmark-based localization techniques are common in passive HRI [2]. In active HRI, a user actively interacts with robotics. They can be classified into active and passive a mobile robot via unnatural communication tools such as a landmarks. Active landmarks are captured and transmitted joystick or a Graphical User Interface (GUI). In passive to the robot for sensing and analysis, such as images interaction, the robot enables the user to use more natural acquired by the robot’s cameras. Passive landmarks are interaction means such as speech or gestures. Therefore, the detected by the robot without any transmitted signals, such human user behaves naturally with the mobile robot, as if he as the output of a laser sensor [2]. were interacting with another person. In general, approaches to solving the recognition problem can be classified into two categories: appearance- 978-1-4244-2679-9/08/$25.00 ©2008 IEEE 572<p></td>
</tr>
<tr id="bib_4913065" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{4913065,
  author = {M. Elmogy and J. Zhang},
  title = {Robust real-time landmark recognition for humanoid robot navigation},
  booktitle = {2008 IEEE International Conference on Robotics and Biomimetics},
  year = {2009},
  pages = {572-577},
  doi = {http://dx.doi.org/10.1109/ROBIO.2009.4913065}
}
</pre></td>
</tr>
<tr id="7139315" class="entry">
	<td>Fentanes, J.P., Lacerda, B., Krajník, T., Hawes, N. and Hanheide, M.</td>
	<td>Now or later? Predicting and maximising success of navigation actions from long-term experience <p class="infolinks">[<a href="javascript:toggleInfo('7139315','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7139315','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 1112-1117&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2015.7139315">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7139315" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: In planning for deliberation or navigation in real-world robotic systems, one of the big challenges is to cope with change. It lies in the nature of planning that it has to make assumptions about the future state of the world, and the robot's chances of successively accomplishing actions in this future. Hence, a robot's plan can only be as good as its predictions about the world. In this paper, we present a novel approach to specifically represent changes that stem from periodic events in the environment (e.g. a door being opened or closed), which impact on the success probability of planned actions. We show that our approach to model the probability of action success as a set of superimposed periodic processes allows the robot to predict action outcomes in a long-term data obtained in two real-life offices better than a static model. We furthermore discuss and showcase how this knowledge gathered can be successfully employed in a probabilistic planning framework to devise better navigation plans. The key contributions of this paper are (i) the formation of the spectral model of action outcomes from non-uniform sampling, the (ii) analysis of its predictive power using two long-term datasets, and (iii) the application of the predicted outcomes in an MDP-based planning framework.</td>
</tr>
<tr id="bib_7139315" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7139315,
  author = {J. P. Fentanes and B. Lacerda and T. Krajník and N. Hawes and M. Hanheide},
  title = {Now or later? Predicting and maximising success of navigation actions from long-term experience},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
  year = {2015},
  pages = {1112-1117},
  doi = {http://dx.doi.org/10.1109/ICRA.2015.7139315}
}
</pre></td>
</tr>
<tr id="Filliat2003243" class="entry">
	<td>Filliat, D. and Meyer, J.-A.</td>
	<td>Map-based navigation in mobile robots:: I. A review of localization strategies  <p class="infolinks">[<a href="javascript:toggleInfo('Filliat2003243','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Filliat2003243','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td>Cognitive Systems Research <br/>Vol. 4(4), pp. 243 - 282&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S1389-0417(03)00008-1">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S1389041703000081">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Filliat2003243" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: For a robot, an animal, and even for man, to be able to use an internal representation of the spatial layout of its environment to position itself is a very complex task, which raises numerous issues of perception, categorization and motor control that must all be solved in an integrated manner to promote survival. This point is illustrated here, within the framework of a review of localization strategies in mobile robots. The allothetic and idiothetic sensors that may be used by these robots to build internal representations of their environment, and the maps in which these representations may be instantiated, are first described. Then map-based navigation systems are categorized according to a three-level hierarchy of localization strategies, which respectively call upon direct position inference, single-hypothesis tracking, and multiple-hypothesis tracking. The advantages and drawbacks of these strategies, notably with respect to the limitations of the sensors on which they rely, are discussed throughout the text.</td>
</tr>
<tr id="bib_Filliat2003243" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Filliat2003243,
  author = {David Filliat and Jean-Arcady Meyer},
  title = {Map-based navigation in mobile robots:: I. A review of localization strategies },
  journal = {Cognitive Systems Research },
  year = {2003},
  volume = {4},
  number = {4},
  pages = {243 - 282},
  url = {http://www.sciencedirect.com/science/article/pii/S1389041703000081},
  doi = {http://dx.doi.org/10.1016/S1389-0417(03)00008-1}
}
</pre></td>
</tr>
<tr id="Franz00biomimeticrobot" class="entry">
	<td>Franz, M.O. and Mallot, H.A.</td>
	<td>Biomimetic robot navigation <p class="infolinks">[<a href="javascript:toggleInfo('Franz00biomimeticrobot','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Franz00biomimeticrobot','bibtex')">BibTeX</a>]</p></td>
	<td>2000</td>
	<td>Robotics and autonomous Systems<br/>Vol. 30, pp. 133-153&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Franz00biomimeticrobot" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract In the past decade, a large number of robots has been built that explicitly implement biological navigation behaviours. We review these biomimetic approaches using a framework that allows for a common description of biological and technical navigation behaviour. The review shows that biomimetic systems make significant contributions to two fields of research: First, they provide a real world test of models of biological navigation behaviour; second, they make new navigation mechanisms available for technical applications, most notably in the field of indoor robot navigation. While simpler insect navigation behaviours have been implemented quite successfully, the more complicated way-finding capabilities of vertebrates still pose a challenge to current systems</td>
</tr>
<tr id="bib_Franz00biomimeticrobot" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Franz00biomimeticrobot,
  author = {Matthias O. Franz and Hanspeter A. Mallot},
  title = {Biomimetic robot navigation},
  journal = {Robotics and autonomous Systems},
  year = {2000},
  volume = {30},
  pages = {133--153}
}
</pre></td>
</tr>
<tr id="Fu2012" class="entry">
	<td>Fu, G., Menciassi, A. and Dario, P.</td>
	<td>Development of a low-cost active 3D triangulation laser scanner for indoor navigation of miniature mobile robots <p class="infolinks">[<a href="javascript:toggleInfo('Fu2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 60(10), pp. 1317–1326&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2012.06.002">DOI</a> <a href="http://dx.doi.org/10.1016/j.robot.2012.06.002">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Fu2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Fu2012,
  author = {Fu, Guoqiang and Menciassi, Arianna and Dario, Paolo},
  title = {Development of a low-cost active 3D triangulation laser scanner for indoor navigation of miniature mobile robots},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier BV},
  year = {2012},
  volume = {60},
  number = {10},
  pages = {1317–1326},
  url = {http://dx.doi.org/10.1016/j.robot.2012.06.002},
  doi = {http://dx.doi.org/10.1016/j.robot.2012.06.002}
}
</pre></td>
</tr>
<tr id="7039463" class="entry">
	<td>Furci, M., Naldi, R., Paoli, A. and Marconi, L.</td>
	<td>A robust control strategy for mobile robots navigation in dynamic environments <p class="infolinks">[<a href="javascript:toggleInfo('7039463','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7039463','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>53rd IEEE Conference on Decision and Control, pp. 698-703&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/CDC.2014.7039463">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7039463" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This work introduces a novel control strategy to allow a class of mobile robots to robustly navigate in dynamics and potentially cluttered environments. The proposed approach combines a high-level motion planner and a low-level stabilizing feedback control law designed considering the nonlinear dynamic model of the vehicle. Taking advantage of a symbolic description of the vehicle dynamics and of the environment, the reference trajectories are sequences of elementary primitives which are obtained with a reduced computational cost. However, the resulting references may fail to be functionally controllable for the actual dynamical model of the vehicle. Accordingly, to obtain a desired tracking error, sufficient conditions are then derived by investigating the interconnection between the discrete time planner and the continuous time closed-loop nonlinear system. The effectiveness of the obtained results is demonstrated by considering, as application, a ground robot navigating in a cluttered environment.</td>
</tr>
<tr id="bib_7039463" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7039463,
  author = {M. Furci and R. Naldi and A. Paoli and L. Marconi},
  title = {A robust control strategy for mobile robots navigation in dynamic environments},
  booktitle = {53rd IEEE Conference on Decision and Control},
  year = {2014},
  pages = {698-703},
  doi = {http://dx.doi.org/10.1109/CDC.2014.7039463}
}
</pre></td>
</tr>
<tr id="Gu2015" class="entry">
	<td>Gu, F., He, Y. and Han, J.</td>
	<td>Active Persistent Localization of a Three-Dimensional Moving Target Under Set-Membership Uncertainty Description Through Cooperation of Multiple Mobile Robots <p class="infolinks">[<a href="javascript:toggleInfo('Gu2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>IEEE Transactions on Industrial Electronics<br/>Vol. 62(8), pp. 4958–4971&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/tie.2015.2403798">DOI</a> <a href="http://dx.doi.org/10.1109/TIE.2015.2403798">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Gu2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Gu2015,
  author = {Gu, Feng and He, Yuqing and Han, Jianda},
  title = {Active Persistent Localization of a Three-Dimensional Moving Target Under Set-Membership Uncertainty Description Through Cooperation of Multiple Mobile Robots},
  journal = {IEEE Transactions on Industrial Electronics},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2015},
  volume = {62},
  number = {8},
  pages = {4958–4971},
  url = {http://dx.doi.org/10.1109/TIE.2015.2403798},
  doi = {http://dx.doi.org/10.1109/tie.2015.2403798}
}
</pre></td>
</tr>
<tr id="Hafner01learningof" class="entry">
	<td>Hafner, V.V. and Möller, R.</td>
	<td>Learning of Visual Navigation Strategies <p class="infolinks">[<a href="javascript:toggleInfo('Hafner01learningof','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hafner01learningof','bibtex')">BibTeX</a>]</p></td>
	<td>2001</td>
	<td>In, pp. 47-56&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Hafner01learningof" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. This paper presents a mechanism of learning a homing strategy, which is mostly independent from the environment. It is comparable with theoretic homing models in insects like the snapshot model (Cartwright and Collett, 1983) or the Average Landmark Vector model (Lambrinos et al., 2000). In contrast to those models, the navigation strategies presented in this paper are not pre-defined but learned in interaction with the environment. The preconditions for the ability to learn are kept as minimal as possible. The learned homing strategies have been tested in both simulation and on a mobile robot.</td>
</tr>
<tr id="bib_Hafner01learningof" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Hafner01learningof,
  author = {Verena V. Hafner and Ralf Möller},
  title = {Learning of Visual Navigation Strategies},
  booktitle = {In},
  year = {2001},
  pages = {47--56}
}
</pre></td>
</tr>
<tr id="1307283" class="entry">
	<td>Hahnel, D., Burgard, W., Fox, D., Fishkin, K. and Philipose, M.</td>
	<td>Mapping and localization with RFID technology <p class="infolinks">[<a href="javascript:toggleInfo('1307283','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1307283','review')">Review</a>] [<a href="javascript:toggleInfo('1307283','bibtex')">BibTeX</a>]</p></td>
	<td>2004</td>
	<td><br/>Vol. 1Robotics and Automation, 2004. Proceedings. ICRA '04. 2004 IEEE International Conference on, pp. 1015-1020 Vol.1&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBOT.2004.1307283">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_1307283" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abslmct-In this paper we analyze whether recent Radio Frequency Identification (RF’ID) technology can he used to improve the localization of mobile robots and persons in their environment. In particular we study the problem of localizing RFID tags with a mobile platform that is equipped with a pair of RFID antennas. We present a probabilistic measurement model for RFID readers that allow us to accurately localize RFID tags in the environment. We also demonstrate how such maps can be used to localize a robot and persons in their envtronment. Finally, we present experiments illustrating that the computational rrquiremenis for global robot localization can be reduced strongly by fusing RFTD information with laser data.</td>
</tr>
<tr id="rev_1307283" class="review noshow">
	<td colspan="6"><b>Review</b>: Proceedings ofthe 2004 IEEE Internatlomi Confsmnce on RobDtics &amp;Automation New Orleans. LA Aprll2004 Mapping and Localization with WID Technology Dirk Hihnel Wolfram Burgard Dieter Fox Ken Fishkin Matthai Philipose University of Freiburg University of Washington Intel Research Seattle Depamnent of Computer Science Computer Science and Engineering Seattle, WA, USA Freiburg, Germany Seattle, WA, USA the toothpaste has very different meanings depending on whether it happens in the storage room or in the bathroom. In this paper, we investigate how WID technology can be enhanced by location information. We use a mobile robot equipped with WID antennas to determine the locations of RFlD tags attached to objects in an indoor environment. Figure 2 (left) depicts the robot built to carry out this re- search. The robot consists of an off-the-shelf Pioneer 2 robot equipped with a laser range scanner and two RFID antennas. Fig. I . Typical RFlD tags used to label objects. The Size oflhe tao depicted The antennas are mounted on top of the robot and point in the center is 11 x 5 cm. approximately 45 degrees to the left and to the right with respect to the robot. To use these antennas for estimating Abslmct-In this paper we analyze whether recent Radio the locations of objects, we first learn a sensor model that Frequency Identification (RF’ID) technology can he used to describes the likelihood of detecting an RF!D tag given its improve the localization of mobile robots and persons in their location relative to one of the antennas. Since the noise of these environment. In particular we study the problem of localizing sensors is highly non-Gaussian, we represent the measurement RFID tags with a mobile platform that is equipped with a pair of RFID antennas. We present a probabilistic measurement likelihood model by a piecewise constant approximation. Then model for RFID readers that allow us to accurately localize we describe a technique to estimate the locations of RFlD tags RFID tags in the environment. We also demonstrate how such using a mobile robot equipped with RFID antennas to detect maps can be used to localize a robot and persons in their tags. This process uses a map previously learned from laser envtronment. Finally, we present experiments illustrating that range data. We then apply Monte Carlo localization [41, [71 the computational rrquiremenis for global robot localization can be reduced strongly by fusing RFTD information with laser data. to estimate the pose of the robot and even of persons in this environment. Experimental results suggest that it is possible to accurately localize moving objects based on this technology. I. INTRODUCTION Funher experiments demonstrate that RFTD tags greatly reduce the time required for global localization of a mobile robot in Recent advances in the field of radio frequency identification its environment. Additionally, this technology can be used to techniques have reached a state that will allow us within the drastically reduce the number of samples required for global next years to equip virtually every object in an environment localization. with small, cheap Radio Frequency Identification (RFID) This paper is organized as follows. After discussing related tags [6]. Such tags contain circuitry that gain power from work we will present the sensor model for RFD receivers in radio waves emitted by readers in their vicinity. They use this Section m. Then we describe how this model can be used power to reply their unique identifier to the reader. Figure 1 in combination with a laser-based FastSLAM [81 approach to depicts three different RFID tags that were used to carry out effectively determine the locations of WID tags. In Section V the experiments described in this paper. The detection range we describe how the resulting beliefs about the locations of these tags is approximately 6 m. of the tags can be utilized to determine the position of the RFID rags open up a wide variety of applications. For robot and of persons in the environment. Finally, we present example, an imponant problem in the health-care sector is experimental results illustrating the advantages of RFID tags the recognition of daily activities a home patient is engaged for robot localization and person tracking. in. The Guide project [I31 uses small RFID readers worn by a person to identify rhe objects the person touches. The sequence 11. RELATEDW ORK of touched objects is used by a Bayesian reasoning system to In the last years RFID sensors [6] have started to enter the estimate the activity of the person and to provide support if field of mobile robotics. Nowadays Rm) readers can detect needed. Location context can provide imponant information low-cost passive tags in the range of several meters. These for the interpretation of RFD readings. For example, touching improvements in the detection range of passive tags make this 0-7803-8232-3/04/$17.0W0O 04 IEEE 1015 <p></td>
</tr>
<tr id="bib_1307283" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1307283,
  author = {D. Hahnel and W. Burgard and D. Fox and K. Fishkin and M. Philipose},
  title = {Mapping and localization with RFID technology},
  booktitle = {Robotics and Automation, 2004. Proceedings. ICRA '04. 2004 IEEE International Conference on},
  year = {2004},
  volume = {1},
  pages = {1015-1020 Vol.1},
  doi = {http://dx.doi.org/10.1109/ROBOT.2004.1307283}
}
</pre></td>
</tr>
<tr id="1041439" class="entry">
	<td>Hahnel, D., Schulz, D. and Burgard, W.</td>
	<td>Map building with mobile robots in populated environments <p class="infolinks">[<a href="javascript:toggleInfo('1041439','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1041439','review')">Review</a>] [<a href="javascript:toggleInfo('1041439','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td><br/>Vol. 1IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 496-501 vol.1&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IRDS.2002.1041439">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_1041439" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract The problem of generating maps with mobile robots has received considerable attention over the past years. How- ever, most of the approaches assume that the environment is static during the data-acquisition phase. In this paper we consider the problem of creating maps with mobile robots in populated environments. Our approach uses a probabilistic method to track multiple people and to in- corporate the results of the tracking technique into the mapping process. The resulting maps are more accurate since corrupted readings are treated accordingly during the matching phase and since the number of spurious ob- jects in the resulting maps is reduced. Our approach has been implemented and tested on real robot systems in in- door and outdoor scenarios. We present several experi- ments illustrating the capabilities of our approach to gen- erate accurate 2d and 3d maps.</td>
</tr>
<tr id="rev_1041439" class="review noshow">
	<td colspan="6"><b>Review</b>: Map Building with Mobile Robots in Populated Environments Dirk Ha¨hnel† Dirk Schulz‡ Wolfram Burgard† †University of Freiburg, Department of Computer Science, Germany ‡University of Bonn, Department of Computer Science, Germany Abstract all approaches possess the ability to cope with a certain amount of noise in the sensor data, they assume that the The problem of generating maps with mobile robots has environment is almost static during the mapping process. received considerable attention over the past years. How- Especially in populated environments, additional noise is ever, most of the approaches assume that the environment introduced to the sensor data which increases the risk of is static during the data-acquisition phase. In this paper localization errors. Additionally, people in the vicinity we consider the problem of creating maps with mobile of the robots appear as objects in the resulting maps and robots in populated environments. Our approach uses a therefore make the maps not usable for path planning etc. probabilistic method to track multiple people and to in- Recently [15] presented a heuristic and feature-based ap- corporate the results of the tracking technique into the proach to identify dynamic objects in range scans. The mapping process. The resulting maps are more accurate corresponding measurements are then filtered out during since corrupted readings are treated accordingly during 2d scan registration. the matching phase and since the number of spurious ob- jects in the resulting maps is reduced. Our approach has In this paper we present a probabilistic approach to filter- been implemented and tested on real robot systems in in- ing people out of sensor data and techniques to incorpo- door rate the results of the filtering into the mapping process.and outdoor scenarios. We present several experi- ments illustrating the capabilities of Our approach has several desirable properties. First, byour approach to gen- erate accurate 2d and 3d maps. incorporating the results of the people tracker, the align- ment of the scans becomes more robust. Additionally, the resulting maps are more accurate, since measurements 1 Introduction corrupted by people walking by are filtered out. Com- Learning maps with mobile robots pared to [15] our approach uses a tracking technique andhas received consider- able attention over the last two decades. therefore is able to predict the positions of the person’sThis is because maps often are inherently necessary for mobile robots even in situations in which the corresponding features areto temporarily missing. Empirical results, described in this perform their tasks. When mapping an environment, a mobile robot generally has to cope with different kinds paper, illustrate that our approach succeeds in learning accurate large-scale 2d and 3d maps of populated envi- of noise: noise in the odometry and noise in the sensor data. ronments with range scanners even if several persons areTherefore, the map learning problem is a chicken- and-egg problem. in the vicinity of the robot.If the pose (we use the term pose to refer to a robot’s x-y location and its heading direction θ) This paper is organized as follows. In the next section of the robot was always known during mapping, building we briefly present our approach to tracking multiple peo- maps is relatively easy. On the other hand, if a map was ple in range scans. The third and forth section describes available, determining the robot’s poses can be done effi- our mapping technique and how the results of the peo- ciently. In the literature, the mobile robot mapping prob- ple tracker are integrated into the mapping process. The lem is often referred to as the simultaneous localization fifth section contains several experiments describing the and mapping problem (SLAM) [2, 4, 7]. advantages of our approach to learning 2d and 3d maps with range scanners. Approaches to concurrent mapping and localization can roughly be classified according to the kind of sensor data processed and the matching algorithms used. For ex- 2 Sample-based Joint Probabilistic Data Asso- ample, the approaches described in [12, 2, 4, 7] extract ciation Filters (SJPDAFs) landmarks out of the data and match these landmarks to localize the robot in the map being learned. The other To detect people and track people in the vicinity of the set of approaches such as [8, 6, 13] use raw sensor data robot, our system applies a sample-based variant of Prob- and perform a dense matching of the scans. Although abilistic Data Association Filters (JPDAFs) [3]. Suppose<p></td>
</tr>
<tr id="bib_1041439" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1041439,
  author = {D. Hahnel and D. Schulz and W. Burgard},
  title = {Map building with mobile robots in populated environments},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2002},
  volume = {1},
  pages = {496-501 vol.1},
  doi = {http://dx.doi.org/10.1109/IRDS.2002.1041439}
}
</pre></td>
</tr>
<tr id="Hong2011" class="entry">
	<td>Hong, J. and Park, K.</td>
	<td>A new mobile robot navigation using a turning point searching algorithm with the consideration of obstacle avoidance <p class="infolinks">[<a href="javascript:toggleInfo('Hong2011','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hong2011','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>The International Journal of Advanced Manufacturing Technology<br/>Vol. 52(5), pp. 763-775&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/s00170-010-2749-5">DOI</a> <a href="http://dx.doi.org/10.1007/s00170-010-2749-5">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Hong2011" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: When a robot goes from the initial position to the goal position in an unknown environment, we need the autonomous navigation for avoiding the obstacles and moving toward the goal position simultaneously. Among the various methods, we focus on the navigation method by using the geometric analysis with a laser scanner having the high resolution. When the robot turns around the obstacle, our proposed navigation method supplies the robot with the turning point for avoiding the obstacle and moving on the shortest path. At the same time, the next heading velocity is generated for the robot to have the maximum velocity by using the distance between the current position of the robot and the turning point. The robot executes the navigation in the unknown workspace which the various obstacles are randomly located. As the experimental results, we obtain the shortest path of the robot regardless of the obstacle's shape in the unknown environment.</td>
</tr>
<tr id="bib_Hong2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hong2011,
  author = {Hong, Jinpyo and Park, Kyihwan},
  title = {A new mobile robot navigation using a turning point searching algorithm with the consideration of obstacle avoidance},
  journal = {The International Journal of Advanced Manufacturing Technology},
  year = {2011},
  volume = {52},
  number = {5},
  pages = {763--775},
  url = {http://dx.doi.org/10.1007/s00170-010-2749-5},
  doi = {http://dx.doi.org/10.1007/s00170-010-2749-5}
}
</pre></td>
</tr>
<tr id="5983067" class="entry">
	<td>Hoy, M., Matveev, A.S. and Savkin, A.V.</td>
	<td>Robust cooperative navigation of multiple wheeled robots in unknown cluttered environments <p class="infolinks">[<a href="javascript:toggleInfo('5983067','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('5983067','review')">Review</a>] [<a href="javascript:toggleInfo('5983067','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>2011 19th Mediterranean Conference on Control Automation (MED), pp. 650-655&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/MED.2011.5983067">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_5983067" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: When employing autonomous wheeled robots, it is desirable to use navigation approaches which can always prevent collisions. In this paper we consider the problem of navigating multiple vehicles through an unknown static environment with limited sensing and communication capability available. We propose a decentralized, cooperative, reactive, model predictive control based collision avoidance scheme, and show it is able to prevent collisions from occurring. An axillary controller is employed to follow previously planned paths when the main path planning system fails to find a path. Simulations in various scenarios confirm the methods validity.</td>
</tr>
<tr id="rev_5983067" class="review noshow">
	<td colspan="6"><b>Review</b>: 19th Mediterranean Conference on Control and Automation WeBT1.2 Aquis Corfu Holiday Palace, Corfu, Greece June 20-23, 2011 Robust Cooperative Navigation of Multiple Wheeled Robots in Unknown Cluttered Environments Michael Hoy, Alexey S. Matveev and Andrey V. Savkin Abstract— When employing autonomous wheeled robots, it is be tracked to avoid collision [19]. Alternatively, if the paths to desirable to use navigation approaches which can always prevent be followed are given, an appropriate velocity profile can be collisions. In this paper we consider the problem of navigating found to avoid collision [1], [16]. However, in many situations multiple vehicles through an unknown static environment with limited sensing and communication capability available. We a decentralized scheme would be more suitable. Robust model propose a decentralized, cooperative, reactive, model predictive predictive control is increasingly being used in the context control based collision avoidance scheme, and show it is able of vehicle navigation as it is resistant to disturbance, and to prevent collisions from occurring. An axillary controller is decentralized MPC can find the near-optimal solution for a employed to follow previously planned paths when the main multi-agent system [15], [23] using dual decomposition to path planning system fails to find a path. Simulations in various scenarios confirm the methods validity. find a set of trajectories for the system of vehicles. While Index Terms— Path Planning, Robot Navigation, Cooperative this is more efficient than centralized optimization, it requires Collision Avoidance, Robust Model Predictive Control many iterations of communication exchange between vehicles in order to converge to a solution. Another approach using I. INTRODUCTION multiplexed MPC has been used to control vehicles [6]. The As autonomous wheeled robots are used in greater con- robust control for each vehicle is computed by updating a centrations, the probability of multiple vehicle encounters finite trajectory for each vehicle sequentially. While multi- correspondingly increases. Techniques suitable for navigating plexed MPC is suited to real time implementation, a possible a single robot through a obstacle filled area would not always disadvantage is path planning cannot occur simultaneously in be successful in such situations. In this paper we present two adjacent vehicles. Approaches also have been proposed a solution to the problem of reactively controlling multiple which permit single communication exchanges per control autonomous wheeled robots in a cluttered environment based update [21]. This is done by including a coherence objective on model predictive control (MPC). Unlike other approaches to discourage the vehicles from changing its planned trajectory in this area, we do not require explicit ordering of the ve- after transmitting it to other vehicles. hicles, each vehicle can plan trajectories simultaneously, and We propose a MPC type method that requires single com- communication exchange only occurs once for each update of munication exchanges per control update, no explicit coher- the control laws. ence objective, and may be suited to real-time implementation, This type of problem is classed as a networked control while retaining robustness properties. problem, which is an active field of research. For examples In section II the problem statement is explicitly defined and of more generalized work in this area see [10], [11], [18]. the vehicle model given. in section III we give the structure of Control laws have been proposed to avoid collisions be- the control system. Section IV offers simulated results with a tween two or more robots traveling at constant speed [2], perfect unicycle model.Section V offers brief conclusions. [7], [14]. In the case of acceleration constrained vehicles without non-holonomic constraints, it can be shown collision II. PROBLEM STATEMENT avoidance is feasible for up to three agents, using a potential We consider Nh autonomous vehicles traveling in a plane, field type approach [4]. Collision avoidance can be shown for each of which is associated with a steady point target Ti, i ∈ an arbitrarily large group of agents if the control input is be [1 : Nh]. The plane contains a set of unknown, untransversable, unbounded [20]. It can also be shown an arbitrarily large group static, and closed obstacles Dj 6∋ Ti, j ∈ [1 : n]. The objective of agents can avoid each other if the velocity is controlled [22]. is to design a navigation law that drives every robot towards In general these papers did not tend to consider fixed obstacles. the assigned target through the obstacle-free part of the plane Off-line path planning can be used to find the optimal 2R  D,D := D1 ∪ . . . ∪ Dn. Moreover, the distance from trajectories for a set of robots, and these trajectories can then the robot to every obstacle and other robots should constantly exceed the given safety margin dsafe. This work was supported by the Australian Research Council. Andrey V. Savkin and Michael Hoy are with the School of Electrical We use the discrete-time point-mass unicycle model of the Engineering and Telecommunications, the University of New South Wales, wheeled robot. For simplicity, the time step is normalized to Sydney, NSW 2052, Australia. unity. The unicycle model is widely used to describe motions Alexey S. Matveev is with the Department of Mathematics and Mechanics, Saint Petersburg University, St.Petersburg, 198504, Russia. of wheeled robots, UAVs, and missiles; for examples see [5], Corresponding author: Michael Hoy (email: mch.hoy@gmail.com) [8], [9]. 978-1-4577-0123-8/11/$26.00 ©2011 IEEE 650<p></td>
</tr>
<tr id="bib_5983067" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{5983067,
  author = {M. Hoy and A. S. Matveev and A. V. Savkin},
  title = {Robust cooperative navigation of multiple wheeled robots in unknown cluttered environments},
  booktitle = {2011 19th Mediterranean Conference on Control Automation (MED)},
  year = {2011},
  pages = {650-655},
  doi = {http://dx.doi.org/10.1109/MED.2011.5983067}
}
</pre></td>
</tr>
<tr id="1689624" class="entry">
	<td>Hummel, B., Kammel, S., Dang, T., Duchow, C. and Stiller, C.</td>
	<td>Vision-based path-planning in unstructured environments <p class="infolinks">[<a href="javascript:toggleInfo('1689624','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('1689624','review')">Review</a>] [<a href="javascript:toggleInfo('1689624','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>2006 IEEE Intelligent Vehicles Symposium, pp. 176-181&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IVS.2006.1689624">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_1689624" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract- Autonomous driving in unstructed environments has attracted an unprecedented level of attention when the DARPA announced the Grand Challenge Competitions in 2004 and 2005. Autonomous driving involves (at least) three major subtasks: perception of the environment, path planning and subsequent vehicle control. Whereas the latter has proven a solved problem, the first two constituted, apart from hardware failures, the most prominent source of errors in both Grand Challenges. This paper presents a system for real-time feature detection and subsequent path planning based on multiple stereoscopic and monoscopic vision cues. The algorithm is, in principle, suitable for arbitrary environments as the features are not tailored to a particular application. A slightly modified version of the system described here has been succesfully used in the Qualifications and the Final Race of the Grand Challenge 2005 within the Desert Buckeyes' autonomous vehicle.</td>
</tr>
<tr id="rev_1689624" class="review noshow">
	<td colspan="6"><b>Review</b>: Intelligent Vehicles Symposium 2006, June 13-15, 2006, Tokyo, Japan 4-4 Vision-based path-planning in unstructured environments Britta Hummel, Soren Kammel, Thao Dang, Christian Duchow and Christoph Stiller Institut fuir Mess- und Regelungstechnik Universitat Karlsruhe (TH) D-76131 Karlsruhe, Germany Email: name@mrt.uka.de Abstract- Autonomous driving in unstructed environments event, testing the vehicles' abilities to autonomously navigate has attracted an unprecedented level of attention when the and avoid obstacles. In 2005, from 200 initial participants 40 DARPA announced the Grand Challenge Competitions in 2004 and 2005. Autonomous driving involves (at least) three major were selected for the qualifying, 20 of whom were chosen for subtasks: perception of the environment, path planning and the final race. subsequent vehicle control. Whereas the latter has proven a solved problem, the first two constituted, apart from hardware failures, the most prominent source of errors in both Grand Challenges. This paper presents a system for real-time feature detection and subsequent path planning based on multiple stereoscopic and monoscopic vision cues. The algorithm is, in principle, suitable for arbitrary environments as the features are not tailored to a particular application. A slightly modified version of the system described here has been succesfully used in the Qualifications and the Final Fig. 1. The Grand Challenge 2005 Qualifying event: The Desert Buckeyes Race of the Grand Challenge 2005 within the Desert Buckeyes' autonomous vehicle successfully navigating through a tunnel (left, onboard autonomous vehicle. camera) and a narrow gate bounded by reflecting obstacles (right, spectator's camera). I. INTRODUCTION Path planning is concerned with the problem of moving an entity from an initial configuration to a goal configuration. The This article introduces a fast path planning algorithm for resulting route may include intermediate tasks and assignments unstructured environments based on multiple, complementary that must be completed before the entity reaches the goal stereoscopic and monoscopic vision cues. Further incorpora- configuration. External sensors provide input to the path tion of additional, arbitrary sensor information, e. g. lidar or planner, the most common of which include radar, is straightforward.monoscopic and stereoscopic vision sensors and range finders, based The algorithm's path planning strategy is based on theon sonar, radar or laser light. following assumptions: Path planning problems have been excessively studied wi- . A good path is maximally even. thin the robotics community, with applications ranging from . The transition between scene components involves a non- robot manipulator navigation for medical or manufacturing smooth change of color. applications to autonomous exploration in unknown environ- * The road exhibits a preferred texture orientation in driving ment, e.g. for military or planetary exploration purposes. [2] direction due to antecedent vehicles passing (this can be is an excellent survey on relevant work since the 1980's and observed even in the case of paved roads). proposes a classification scheme for path planning algorithms. The algorithm is thus suitable to any environments where these [3] summarizes work on vision-based navigation and mapping. assumptions at least roughly hold. Each assumption is tested The Grand Challenge turned out as an excellent testbed for for validity for each possible path by specially tailored feature comparison of different sensor data processing and path plan- extractors. A fast path planning strategy is introduced which ning strategies (Fig. 1). It is an open contest for autonomous is based upon a probabilistic grid map using an active testing land vehicles that has been announced in 2004 and 2005 by the model for efficient computation. US Defense Advanced Research Projects Agency (DARPA). It This document is structured as follows: First, we give a requires autonomous robotic ground vehicles to successfully brief overview of the system architecture. Next, the used navigate a course of roughly 200 miles of off- and on-road vision cues and the corresponding feature extraction schemes terrain from Barstow, CA to Primm, NV. The course is roughly are examined. The next section focuses on the path planner, defined by GPS-waypoints that are published two hours before followed by real-time issues concerning the search strategy. the race. Prior to the Grand Challenge race is a qualifying We conclude by providing results from the system's intense 176<p></td>
</tr>
<tr id="bib_1689624" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{1689624,
  author = {B. Hummel and S. Kammel and Thao Dang and C. Duchow and C. Stiller},
  title = {Vision-based path-planning in unstructured environments},
  booktitle = {2006 IEEE Intelligent Vehicles Symposium},
  year = {2006},
  pages = {176-181},
  doi = {http://dx.doi.org/10.1109/IVS.2006.1689624}
}
</pre></td>
</tr>
<tr id="6907455" class="entry">
	<td>Kikkeri, H., Parent, G., Jalobeanu, M. and Birchfield, S.</td>
	<td>An inexpensive method for evaluating the localization performance of a mobile robot navigation system <p class="infolinks">[<a href="javascript:toggleInfo('6907455','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6907455','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 4100-4107&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2014.6907455">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6907455" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— We propose a method for evaluating the localiza- tion accuracy of an indoor navigation system in arbitrarily large environments. Instead of using externally mounted sensors, as required by most ground-truth systems, our approach involves mounting only landmarks consisting of distinct patterns printed on inexpensive foam boards. A pose estimation algorithm computes the pose of the robot with respect to the land- mark using the image obtained by an on-board camera. We demonstrate that such an approach is capable of providing accurate estimates of a mobile robot’s position and orientation with respect to the landmarks in arbitrarily-sized environments over arbitrarily-long trials. Furthermore, because the approach involves minimal outfitting of the environment, we show that only a small amount of setup time is needed to apply the method to a new environment. Experiments involving a state-of-the-art navigation system demonstrate the ability of the method to facilitate accurate localization measurements over arbitrarily long periods of time.</td>
</tr>
<tr id="bib_6907455" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6907455,
  author = {H. Kikkeri and G. Parent and M. Jalobeanu and S. Birchfield},
  title = {An inexpensive method for evaluating the localization performance of a mobile robot navigation system},
  booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  year = {2014},
  pages = {4100-4107},
  doi = {http://dx.doi.org/10.1109/ICRA.2014.6907455}
}
</pre></td>
</tr>
<tr id="6578219" class="entry">
	<td>Kim, D., Kim, K. and Hong, S.</td>
	<td>Robust navigation control and synchronization of networked robots <p class="infolinks">[<a href="javascript:toggleInfo('6578219','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6578219','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Systems, Applications and Technology Conference (LISAT), 2013 IEEE Long Island, pp. 1-7&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/LISAT.2013.6578219">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6578219" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: In an environment where a large number of networked robots are actively providing service, the navigation control and synchronization between the robots become a very important factor in terms of time it takes for the robots to complete tasks they are given especially in physically large-scale areas. The large-scale environment needs to be divided into multiple cells, each of which covers a specific area within the service area to ensure a proper communication link with robots. Using a relay functionality of the each cell, a centralized system can seamlessly control robots navigation. We assume that the path information for robots, called as segment in this paper, is given from a separate path planning system. The path is divided into two types: one without deadline constraint and one with deadline constraint. Due to randomness of events that prevent uninterrupted navigation, the robots can rarely navigate to the target position with a uniform speed. This severely affects the path planning system for choosing the most optimal robot and for planning a path for it while attempting to meet the service deadline constraints. In this paper, we make an attempt to minimize (1) the difference between the actual navigation time and the time that the system identifies, (2) the difference between the deadline to complete a segment and the time that the robot navigates the segment through, and (3) to seamlessly navigate robots from one cell to another.</td>
</tr>
<tr id="bib_6578219" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6578219,
  author = {D. Kim and K. Kim and S. Hong},
  title = {Robust navigation control and synchronization of networked robots},
  booktitle = {Systems, Applications and Technology Conference (LISAT), 2013 IEEE Long Island},
  year = {2013},
  pages = {1-7},
  doi = {http://dx.doi.org/10.1109/LISAT.2013.6578219}
}
</pre></td>
</tr>
<tr id="6907451" class="entry">
	<td>Kjærgaard, M., Andersen, N.A. and Ravn, O.</td>
	<td>Generic trajectory representation and trajectory following for wheeled robots <p class="infolinks">[<a href="javascript:toggleInfo('6907451','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 4073-4080&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2014.6907451">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_6907451" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6907451,
  author = {M. Kjærgaard and N. A. Andersen and O. Ravn},
  title = {Generic trajectory representation and trajectory following for wheeled robots},
  booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  year = {2014},
  pages = {4073-4080},
  doi = {http://dx.doi.org/10.1109/ICRA.2014.6907451}
}
</pre></td>
</tr>
<tr id="6766591" class="entry">
	<td>Krajník, T., Pedre, S. and Přeučil, L.</td>
	<td>Monocular navigation for long-term autonomy <p class="infolinks">[<a href="javascript:toggleInfo('6766591','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6766591','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Advanced Robotics (ICAR), 2013 16th International Conference on, pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICAR.2013.6766591">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6766591" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: We present a reliable and robust monocular navigation system for an autonomous vehicle. The proposed method is computationally efficient, needs off-the-shelf equipment only and does not require any additional infrastructure like radio beacons or GPS. Contrary to traditional localization algorithms, which use advanced mathematical methods to determine vehicle position, our method uses a more practical approach. In our case, an image-feature-based monocular vision technique determines only the heading of the vehicle while the vehicle's odometry is used to estimate the distance traveled. We present a mathematical proof and experimental evidence indicating that the localization error of a robot guided by this principle is bound. The experiments demonstrate that the method can cope with variable illumination, lighting deficiency and both short- and long-term environment changes. This makes the method especially suitable for deployment in scenarios which require long-term autonomous operation.</td>
</tr>
<tr id="bib_6766591" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6766591,
  author = {T. Krajník and S. Pedre and L. Přeučil},
  title = {Monocular navigation for long-term autonomy},
  booktitle = {Advanced Robotics (ICAR), 2013 16th International Conference on},
  year = {2013},
  pages = {1-6},
  doi = {http://dx.doi.org/10.1109/ICAR.2013.6766591}
}
</pre></td>
</tr>
<tr id="kruse2013human" class="entry">
	<td>Kruse, T., Pandey, A.K., Alami, R. and Kirsch, A.</td>
	<td>Human-aware robot navigation: A survey <p class="infolinks">[<a href="javascript:toggleInfo('kruse2013human','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('kruse2013human','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 61(12), pp. 1726-1743&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_kruse2013human" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Navigation is a basic skill for autonomous robots. In the last years human–robot interaction has become an important research field that spans all of the robot capabilities including perception, reasoning, learning, manipulation and navigation. For navigation, the presence of humans requires novel approaches that take into account the constraints of human comfort as well as social rules. Besides these constraints, putting robots among humans opens new interaction possibilities for robots, also for navigation tasks, such as robot guides. This paper provides a survey of existing approaches to human-aware navigation and offers a general classification scheme for the presented methods.</td>
</tr>
<tr id="bib_kruse2013human" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{kruse2013human,
  author = {Kruse, Thibault and Pandey, Amit Kumar and Alami, Rachid and Kirsch, Alexandra},
  title = {Human-aware robot navigation: A survey},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier},
  year = {2013},
  volume = {61},
  number = {12},
  pages = {1726--1743}
}
</pre></td>
</tr>
<tr id="Ku¨mmerle2013" class="entry">
	<td>Ku¨mmerle, R., Ruhnke, M., Steder, B., Stachniss, C. and Burgard, W.</td>
	<td>A Navigation System for Robots Operating in Crowded Urban Environments <p class="infolinks">[<a href="javascript:toggleInfo('Ku¨mmerle2013','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ku¨mmerle2013','review')">Review</a>] [<a href="javascript:toggleInfo('Ku¨mmerle2013','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>2013 IEEE International Conference on Robotics and Automation (ICRA) Karlsruhe, Germany, May 6-10, 2013&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Ku¨mmerle2013" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Over the past years, there has been a tremendous progress in the area of robot navigation. Most of the systems developed thus far, however, are restricted to indoor scenarios, non-urban outdoor environments, or road usage with cars. Urban areas introduce numerous challenges to autonomous mobile robots as they are highly complex and in addition to that dynamic. In this paper, we present a navigation system for pedestrian-like autonomous navigation with mobile robots in city environments. We describe different components including a SLAM system for dealing with huge maps of city centers, a planning approach for inferring feasible paths taking also into account the traversability and type of terrain, and a method for accurate localization in dynamic environments. The navigation system has been implemented and tested in several large-scale field tests in which the robot Obelix managed to autonomously navigate from our university campus over a 3.3 km long route to the city center of Freiburg.</td>
</tr>
<tr id="rev_Ku¨mmerle2013" class="review noshow">
	<td colspan="6"><b>Review</b>: 2013 IEEE International Conference on Robotics and Automation (ICRA) Karlsruhe, Germany, May 6-10, 2013 A Navigation System for Robots Operating in Crowded Urban Environments Rainer Ku¨mmerle Michael Ruhnke Bastian Steder Cyrill Stachniss Wolfram Burgard Abstract— Over the past years, there has been a tremendous progress in the area of robot navigation. Most of the systems developed thus far, however, are restricted to indoor scenarios, non-urban outdoor environments, or road usage with cars. Urban areas introduce numerous challenges to autonomous mobile robots as they are highly complex and in addition to that dynamic. In this paper, we present a navigation system for pedestrian-like autonomous navigation with mobile robots in city environments. We describe different components including a SLAM system for dealing with huge maps of city centers, a planning approach for inferring feasible paths taking also into account the traversability and type of terrain, and a method for accurate localization in dynamic environments. The navigation system has been implemented and tested in several large-scale field tests in which the robot Obelix managed to autonomously navigate from our university campus over a 3.3 km long route to the city center of Freiburg. I. IN 500 mTRODUCTION Navigation is a central capability of mobile robots and substantial progress has been made in the area of autonomous Fig. 1. Example trajectory traveled by our robot navigating in an urban environment that also includes a pedestrian zone with a large number of navigation over the past years. The majority of navigation people. Map data on the left from OpenStreetMap (©c OpenStreetMap systems developed thus far, however, focuses on navigation contributors). in indoor environments, through rough outdoor terrain, or based on road usage. Only few systems have been designed over 3km. The trajectory taken by the robot and two pictures for robot navigation in populated urban environments such taken during its run are depicted in Fig. 1. as pedestrian zones, for example, the autonomous city ex Thus, the aim of this paper is to not only describe the- plorer [1]. Robots that are able to successfully navigate in relevant components but also to highlight the capabilities that urban environments and pedestrian zones have to cope with can be achieved with a system like that. We try to motivate a series of challenges including complex three-dimensional our design decisions, critical aspects, as well as limitations settings and highly dynamic scenes paired with unreliable of the current setup. GPS information. II. RELATED WORK In this paper, we describe a navigation system that enables mobile robots to autonomously navigate through The problem of autonomous navigation in populated ar-city-center scenes. Our system builds upon and extends existing tech eas has been studied intensively in the past. One of the- nology f pioneering systems were the robots RHINO [2] and Min-or autonomous navigation. In particular, it contains a SLAM system for learning accurate map erva [3] which operated as interactive mobile tour-guides ins of urban city areas, a dedicated map d crowded museums. An extension of this tour-guide conceptata structure for dealing with large-scale maps, a vari to interactive multi-robot systems was the RoboX systemant of Monte-Carlo localization that utilizes this data structure, and a dedicated approach for terrain analysi developed by Siegwart et al. [4] for the Expo’02 Swisss National Exhibition. Gross et al. [5] installed a robot as that deals with vegetation, dynamic objects, and negative obstacles. We furthermore describe how these individual a shopping assistant that provided wayfinding assistancein home improvement stores. Although these systems were components are integrated. Additionally, we will present the result of a l able to robustly navigate in heavily crowded environments,arge-scale experiment during which the robot Obelix traveled autonomously from our university camp they were restricted to two-dimensional representations ofus the environment and assumed that the robots operated in a to the city center of Freiburg during a busy day in August 2012. During that trial, the robot had to master a distance of relatively confined planar area.Relatively few robotic systems have been developed for This work has been supported by the EC under FP7-231888-EUROPA autonomous navigation in city centers. The concept closest. All authors are with the Dept. of Comp. Science, University of Freiburg. to the one described in this paper probably is the one of 978-1-4673-5643-5/13/$31.00 ©2013 IEEE 3225<p></td>
</tr>
<tr id="bib_Ku¨mmerle2013" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Ku¨mmerle2013,
  author = {Rainer Ku¨mmerle and Michael Ruhnke and Bastian Steder and Cyrill Stachniss and Wolfram Burgard},
  title = {A Navigation System for Robots Operating in Crowded Urban Environments},
  booktitle = {2013 IEEE International Conference on Robotics and Automation (ICRA) Karlsruhe, Germany, May 6-10, 2013},
  publisher = {IEEE},
  year = {2013}
}
</pre></td>
</tr>
<tr id="Kuemmerle2014" class="entry">
	<td>Kümmerle, R., Ruhnke, M., Steder, B., Stachniss, C. and Burgard, W.</td>
	<td>Autonomous Robot Navigation in Highly Populated Pedestrian Zones <p class="infolinks">[<a href="javascript:toggleInfo('Kuemmerle2014','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kuemmerle2014','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>Journal of Field Robotics<br/>Vol. 32(4), pp. 565–589&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1002/rob.21534">DOI</a> <a href="http://dx.doi.org/10.1002/rob.21534">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Kuemmerle2014" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In the past, there has been a tremendous progress in the area of autonomous robot naviga- tion and a large variety of robots have been developed who demonstrated robust navigation capabilities indoors, in non-urban outdoor environments, or on roads and relatively few ap- proaches focus on navigation in urban environments such as city centers. Urban areas, how- ever, introduce numerous challenges for autonomous robots as they are rather unstructured and dynamic. In this paper, we present a navigation system for mobile robots designed to operate in crowded city environments and pedestrian zones. We describe the different com- ponents of this system including a SLAM module for dealing with huge maps of city centers, a planning component for inferring feasible paths taking also into account the traversability and type of terrain, a module for accurate localization in dynamic environments, and means for calibrating and monitoring the platform. Our navigation system has been implemented and tested in several large-scale field tests, in which a real robot autonomously navigated over several kilometers in a complex urban environment. This also included a public demon- stration, during which the robot autonomously traveled along a more than three kilometer long route through the city center of Freiburg, Germany.</td>
</tr>
<tr id="bib_Kuemmerle2014" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Kuemmerle2014,
  author = {Kümmerle, Rainer and Ruhnke, Michael and Steder, Bastian and Stachniss, Cyrill and Burgard, Wolfram},
  title = {Autonomous Robot Navigation in Highly Populated Pedestrian Zones},
  journal = {Journal of Field Robotics},
  publisher = {Wiley-Blackwell},
  year = {2014},
  volume = {32},
  number = {4},
  pages = {565–589},
  url = {http://dx.doi.org/10.1002/rob.21534},
  doi = {http://dx.doi.org/10.1002/rob.21534}
}
</pre></td>
</tr>
<tr id="620221" class="entry">
	<td>Lambert, A. and Fort-Piat, N.L.</td>
	<td>Local map design for local navigation planning <p class="infolinks">[<a href="javascript:toggleInfo('620221','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('620221','review')">Review</a>] [<a href="javascript:toggleInfo('620221','bibtex')">BibTeX</a>]</p></td>
	<td>1997</td>
	<td>Advanced Robotics, 1997. ICAR '97. Proceedings., 8th International Conference on, pp. 453-458&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICAR.1997.620221">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_620221" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: ABSTRACT This paper deals with the &amp;finition of robust tasks for displacement missions of a mobile robot in an indoor environment. For that, the concept of local map is introduced as a set of best landmarks used for planning an executing safe motions. The goal is to plan actions (path following) as w11 as observations (local maps), leading the robot to configurations where pertinent features can be sensed and thus allowing a best localization of the robot relative to its environment. At execution time, local navigation instead of global navigation is peformed using local maps for the robot localization. For each mission, the definition of the local maps and their corresponding robot-tasks is realized automatically during the planning process. The local map design is based on a clustering method developed by Fisher(1958).</td>
</tr>
<tr id="rev_620221" class="review noshow">
	<td colspan="6"><b>Review</b>: lCAR '97 Monterey, CA, July 7-9, 1997 Local map design for local navigation planning Alain Lambert, Nadine Le Fort-Piat UTCIHEUDIASYC, UMR CNRS 6599 BP 529,60205 Compi2gne, FRANCE e-mail : Alain.Lamber@hds.utc.fr ABSTRACT Brooks thinks [Bro 851 that it is not appropriate for a This paper deals with the &amp;finition of robust tasks for mobile robot to use a global reference frame : a set of displacement missions of a mobile robot in an indoor local reference frames (defined by local maps) linked via environment. For that, the concept of local map is uncertain transformations is better. Such a introduced as a set of best landmarks used for planning transformation has already been studied by [Smi 861. The an executing safe motions. The goal is to plan actions planning method proposed builds a set of local maps (path following) as w11 as observations (local maps), where local navigation is performed. Local navigation leading the robot to configurations where pertinent seems to be a good way to cope with small uncertainties, features can be sensed and thus allowing a best as described in [San 961 where local perception maps are localization of the robot relative to its environment. At used to performed reliable local navigation (but not execution time, local navigation instead of global localization). Thus our planner allows to generate safe navigation is peformed using local maps for the robot paths (by meaus of local navigation) and simplifies the localization. For each mission, the definition of the local matching phase during control execution by focusing the maps and their corresponding robot-tasks is realized robot perception on best landmarks (local maps). The automatically during the planning process. The local planning method developed takes into account map design is based on a clustering method developed by uncertainty in position, orientation and control of a non- Fisher. holonomic mobile robot and uses a clustering method for Kevwords the generation of local maps. Mobile robotics, task planning, localization, local map. Next section aims at describing how both environment and sensors models have been built. In section 3 is 1. Introduction described how a path and its associated landmarks, taking into account uncertainty. can be computed in a In mobile robot navigation, failures are aften caused by modeled world. Section 4 then explains how it is possible errors in the robot localization relative to its to design local maps from previous path using the Fisher environment, So to reduce considerably these errors, it is algorithm. Then section 5 shows examples of local maps necessary to plan paths taking the robot trough positions and an execution of robot tasks. Finally section 6 draws where landmarks can be sensed. Variant of landmarks conclusions and focuses on possible extensions and concept have been proposed in the literature like improvements of the work performed so far. landmark area Bou 951. landmark region [Bec 951 and landmark validity region [Bet %I. In order to achieve robust missions, different planning approaches are 2. Problem statement interested by taking into aCcount uncertainty at sensory There is a strong need to model the interactions between and control levels in order to cope with the world reality. world and sensors in order to be able to extract Among these methods we can cite approaches based on localization information for planning robust paths. pre-image backchaining, potential uncertainty field [Col 941, contact-space motions, or motions commands 2.1 Environment model combined with corrective sensor-based motions. In the The planner uses an ideal 2D world map of the indoor same way, our objective is to plan paths allowing a better environment where walls and obstacles are represented as localization of the robot during its motion. But contrarily polygonal lines. Figure 2 is a map of a part of Compi2gne with approaches previously mentioned, the set U€ university, where bold lines represent detectable walls landmarks, also called local map, used for the and dashed lines represent undetectable obstacles (in localization d the robot during its mission is defined refereoce to the remote on-board sensors used). In order automatically. Local map design has already been studied to use a path finding algorithm, the space is discretised by [Col 941 and is improved by our work with a simpler by a grid. where each cell represents a possible methodology which leads to an optimal solution. configuration of the mobile robot. 0-7803-416 0-0-7/97 $10.00 0 1997 IEEE 453 <p></td>
</tr>
<tr id="bib_620221" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{620221,
  author = {A. Lambert and N. Le Fort-Piat},
  title = {Local map design for local navigation planning},
  booktitle = {Advanced Robotics, 1997. ICAR '97. Proceedings., 8th International Conference on},
  year = {1997},
  pages = {453-458},
  doi = {http://dx.doi.org/10.1109/ICAR.1997.620221}
}
</pre></td>
</tr>
<tr id="7293353" class="entry">
	<td>Lee, S., Tewolde, G.S., Lim, J. and Kwon, J.</td>
	<td>Vision based localization for multiple mobile robots using low-cost vision sensor <p class="infolinks">[<a href="javascript:toggleInfo('7293353','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7293353','review')">Review</a>] [<a href="javascript:toggleInfo('7293353','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 IEEE International Conference on Electro/Information Technology (EIT), pp. 280-285&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/EIT.2015.7293353">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7293353" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper presents an efficient approach for a vision based localization of multiple mobile robots in an indoor environment by using a low cost vision sensor. The proposed vision sensor system that uses a single camera mounted over the mobile robots field takes advantages of small size, low energy consumption, and high flexibility to play an important role in the field of robotics. The nRF24L01 RF transceiver is connected to the vision system to enable wireless communication with multiple devices through 6 different data pipes. The downward-facing camera provides excellent performance that has the ability to identify a number of objects based on color codes, which form colored landmarks that provide mobile robots with useful image information for localization in the image view, which is then transformed to real world coordinates. Experimental results are given to show that the proposed method can obtain good localization performance in multi-mobile robots setting.</td>
</tr>
<tr id="rev_7293353" class="review noshow">
	<td colspan="6"><b>Review</b>: 280 Vision Based Localization for Multiple Mobile Robots Using Low-cost Vision Sensor Seokju Lee, Girma S. Tewolde, Jongil Lim, and Jaerock Kwon Electrical and Computer Engineering Kettering University Flint, MI, USA lee7704, gtewolde, lim7722, jkwon@kettering.edu Abstract-This paper presents an efficient approach for a vision multi-mobile robots. A camera so-called “Pixy” that based localization of multiple mobile robots in an indoor implements a hue-based filtering algorithm is used to detect environment by using a low cost vision sensor. The proposed objects of a specified color. This camera is designed to be low vision sensor system that uses a single camera mounted over the mobile robots field takes advantages of small size, low energy cost, fully programmable, and found to be appropriate for consumption, and high flexibility to play an important role in real-time processing with enough flexibility to be connected the field of robotics. The nRF24L01 RF transceiver is connected directly to most microcontroller-based systems without any to the vision system to enable wireless communication with additional electronics. The advantages of small size and real- multiple devices through 6 different data pipes. The downward- time performance make it possible to apply embedded vision facing camera provides excellent performance that has the ability to identify a number of objects based on color codes, to the robotics. which form colored landmarks that provide mobile robots with The image information in the ground is obtained by the useful image information for localization in the image view, downward-facing camera over the field and color codes are which is then transformed to real world coordinates. placed on the mobile robot as shown in Fig. 1 (A). The main Experimental results are given to show that the proposed advantage of the vision system in this paper is that the vision method can obtain good localization performance in multi- mobile robots setting. sensor can be incorporated directly with an inexpensive microcontroller, which results in compact and light weight Index Terms— Multi-mobile robot localization, Vision vision system. The proposed vision sensor is used to identify Sensor, Color Code and track the mobile robots that move within the field of view I. INTRODUCTION of the camera. The built in image processing unit in the vision An essential and one of the most challenging components system provides the identified object color code’s id, its x and of mobile robots is their localization and navigation system. y coordinates of the center of color code, its height, and width, All mobile robots must preferentially be able to estimate their and angle from the vision sensor. This information can be position in a given environment in order to navigate read to a microcontroller in real time used to estimate the autonomously. Since the early days of mobile robotics real-world position of the mobile robot. localization research vision-based method, among others, has been one of the techniques being explored by researchers. Vision sensors are one of the most versatile as they can be used in many environments such as indoor, outdoor and even in underwater applications [1]. They can provide useful image information about detected shape or color in their field of view. This information is particularly useful for helping the mobile robot localize. Therefore, the authors propose a localization method of identifying each mobile robot and obtaining its relative position and heading direction in the limited filed using vision sensor. Two important papers [2], [3] provide a good survey of various aspects of the progress made so far in vision based navigation and localization methods. Unfortunately, vision based localization requires complex algorithms and high quality hardware resources when related to general environment features. However, using simple landmarks can reduce dramatically the cost and the Fig. 1. (A) Illustration of how the camera should be placed in real complexity of the recognition system. We propose to use environment. (B) Block diagram illustrating the system architecture. Vision color code which is combination of two or more color tags sensor system provides actual positions and orientations to mobile robots through wireless communication. placed close together as a simple landmark to differentiate 978-1-4799-8802-0/15/$31.00 ©2015 IEEE<p></td>
</tr>
<tr id="bib_7293353" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7293353,
  author = {S. Lee and G. S. Tewolde and J. Lim and J. Kwon},
  title = {Vision based localization for multiple mobile robots using low-cost vision sensor},
  booktitle = {2015 IEEE International Conference on Electro/Information Technology (EIT)},
  year = {2015},
  pages = {280-285},
  doi = {http://dx.doi.org/10.1109/EIT.2015.7293353}
}
</pre></td>
</tr>
<tr id="Lee2015" class="entry">
	<td>Lee, Y.-C.</td>
	<td>A Reliable Range-free Indoor Localization Method for Mobile Robots <p class="infolinks">[<a href="javascript:toggleInfo('Lee2015','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Lee2015','review')">Review</a>] [<a href="javascript:toggleInfo('Lee2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 IEEE International Conference on Automation Science and Engineering (CASE) Aug 24-28, 2015. Gothenburg, Sweden&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Lee2015" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— This paper presents an indoor localization method for the mobile robots using the radio signal values and the geometry path on the map. It is divided into three parts, the building the maps, the estimating the position of the robots, and the experiment. First, as the map generation, we build two kinds of the maps which are a radio-based map and a topological map. The radio-based map consists of the radio signals of the Wi-Fi access points at the certain locations. The geometry path map is composed of the topological data that the mobile robots can make as the motion trajectories. Second, as the localization process, we use the fingerprint estimation and the multi- hypothesis tracking (MHT) method. The fingerprint estimation can find the absolute area where the robot is placed by matching the radio-based map and the online observations of the Wi-Fi signals. The MHT method can obtain the optimal position in the topological map by considering the dead-reckoning motion. Finally, when it comes to the experiment, we performed the proposed localization method with a real mobile robot in an office environment to verify its effectiveness and performance. The experimental results show that the proposed method can estimate the accurate position of the robots even though they do not use the expensive range sensors such as the laser range finder.</td>
</tr>
<tr id="rev_Lee2015" class="review noshow">
	<td colspan="6"><b>Review</b>: 2015 IEEE International Conference on Automation Science and Engineering (CASE) Aug 24-28, 2015. Gothenburg, Sweden A Reliable Range-free Indoor Localization Method for Mobile Robots Yu-Cheol Lee1 Abstract— This paper presents an indoor localization method the proposed method using the fingerprint estimation with for the mobile robots using the radio signal values and the the Wi-Fi access points can reduce the expenses to equip geometry path on the map. It is divided into three parts, the the localization system. In addition, as the practical aspects, building the maps, the estimating the position of the robots, and the experiment. First, as the map generation, we build two kinds the proposed localization method can apply to the dynamic of the maps which are a radio-based map and a topological map. environments to estimate the positions of the mobile robots. The radio-based map consists of the radio signals of the Wi-Fi There is only a limit that the fingerprint method based the access points at the certain locations. The geometry path map Wi-Fi RSSI values is to use in the space where crowed is composed of the topological data that the mobile robots can with people or frequently changes the shape of structure [4]. make as the motion trajectories. Second, as the localization process, we use the fingerprint estimation and the multi- This study developed the multi-hypothesis tracking (MHT) hypothesis tracking (MHT) method. The fingerprint estimation approach with the geometrical paths in order to complement can find the absolute area where the robot is placed by matching the inconstant performance of the fingerprint estimation the radio-based map and the online observations of the Wi-Fi depending on the space circumstances. The MHT method signals. The MHT method can obtain the optimal position in can produce a reliable performance, even though the map the topological map by considering the dead-reckoning motion. Finally, when it comes to the experiment, we performed the data is not updated in the dynamic environments because it proposed localization method with a real mobile robot in an matches the local trajectories between the topological map office environment to verify its effectiveness and performance. and the dead-reckoning observation. The proposed method The experimental results show that the proposed method can is an appropriate way for the robot localization in a variety estimate the accurate position of the robots even though they of a real environment. do not use the expensive range sensors such as the laser range finder. This research makes two main contributions. First, we de- fine the map data and develop the map building method used I. INTRODUCTION for the robot localization in the dynamic spaces. The map data consist of the radio-based map and the topological map. This paper proposes the range-free localization method for The radio-based map for the fingerprint estimation contains the mobile robots in the indoor environments. The proposed the basic radio information including the acquisition location, method can estimate the accurate position of the mobile the RSSI value, and the media access control (MAC) address robots that use the Wi-Fi access points to communicate with corresponding to the Wi-Fi access point. The topological the robots or the operators by fusing the received signal map for the MHT stores the geometrical path connectivity strength indication (RSSI) values and the appropriate maps. consisting of the nodes and the links as the motion candidates It can be possible to expand the various navigation services on the specific locations. And then we build the maps using such as the surveillance, the monitoring, the delivery, and the scan matching [5][6] and the graph-based optimization etc. for the mobile robots by providing the precise positions [7] according to the defined representations of the maps. to the robots. Second, we designed a localization framework consisted The proposed localization method has several potential of the fingerprint estimation and the MHT method which advantages. As the cost aspect, it is an appropriate way to im- are worked with the mutual complementary to improving the plementing the low-priced localization system for the mobile accuracy of the estimated position. The fingerprint estimation robots. The range sensors such as laser ranger finder (LRF) can find the absolute region where the robot exists by match- [1] or the specially designed sensors such as ultra wide band ing the radio-based map and the current observations of the (UWB) [2], radio-frequency identification (RFID), ZigBee Wi-Fi signals. And the MHT method can determine a certain and etc. [3] are normally used for the robot localization, but trajectory into some area by using the topological map and they require the additional cost to install the devices in the the sequential motion changes. The fingerprint estimation robots and their working places. contributes to finding a specific area to select the candidate Most of the mobile robots use the Wi-Fi system for group of the trajectories, and then the MHT method can communicating between the operator and other robots, thus extract an optimal trajectory considering the motion of the robot. Moreover, the MHT method can calculate the accurate This work was supported by the Robot R&amp;D program of MOTIE/KEIT. [10051155, The Development of Robot Based Logistics Systems Applicable position of the robot on the predetermined trajectory. to Hospital-wide Environment]. The paper is organized as followings. Section II defines the 1Yu-Cheol Lee is with Senior Researcher of Intelligent Cognitive Tech- map data and explains the map building method. Section III nology Research Department, Electronics and Telecommunications Re- search Institute (ETRI), 161 Gajeong-Dong, Yuseong-gu, Daejeon, 305-700, presents the localization method consisting of the fingerprint Korea yclee@etri.re.kr estimation and the MHT method. Section IV evaluates the 978-1-4673-8183-3/15/$31.00 ©2015 IEEE 720<p></td>
</tr>
<tr id="bib_Lee2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Lee2015,
  author = {Yu-Cheol Lee},
  title = {A Reliable Range-free Indoor Localization Method for Mobile Robots},
  booktitle = {2015 IEEE International Conference on Automation Science and Engineering (CASE) Aug 24-28, 2015. Gothenburg, Sweden},
  publisher = {IEEE},
  year = {2015}
}
</pre></td>
</tr>
<tr id="Loevsky2010" class="entry">
	<td>Loevsky, I. and Shimshoni, I.</td>
	<td>Reliable and efficient landmark-based localization for mobile robots <p class="infolinks">[<a href="javascript:toggleInfo('Loevsky2010','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Loevsky2010','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 58(5), pp. 520–528&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2010.01.006">DOI</a> <a href="http://dx.doi.org/10.1016/j.robot.2010.01.006">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Loevsky2010" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: abstract This paper describes an efficient and robust localization system for indoor mobile robots and AGVs. The system utilizes a sensor that measures bearings to artificial landmarks, and an efficient triangulation method. We present a calibration method for the system components and overcome typical problems for sensors of the mentioned type, which are localization in motion and incorrect identification of landmarks. The resulting localization system was tested on a mobile robot. It consumes less than 4% of a Pentium4 3.2 GHz processing power while providing an accurate and reliable localization result every 0.5 s. The system was successfully incorporated within a real mobile robot system which performs many other computational tasks in parallel.</td>
</tr>
<tr id="bib_Loevsky2010" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Loevsky2010,
  author = {Loevsky, I. and Shimshoni, I.},
  title = {Reliable and efficient landmark-based localization for mobile robots},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier BV},
  year = {2010},
  volume = {58},
  number = {5},
  pages = {520–528},
  url = {http://dx.doi.org/10.1016/j.robot.2010.01.006},
  doi = {http://dx.doi.org/10.1016/j.robot.2010.01.006}
}
</pre></td>
</tr>
<tr id="6030374" class="entry">
	<td>Lou, L., Xu, X., Cao, J., Chen, Z. and Xu, Y.</td>
	<td>Sensor fusion-based attitude estimation using low-cost MEMS-IMU for mobile robot navigation <p class="infolinks">[<a href="javascript:toggleInfo('6030374','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6030374','review')">Review</a>] [<a href="javascript:toggleInfo('6030374','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td><br/>Vol. 22011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference, pp. 465-468&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ITAIC.2011.6030374">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6030374" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Recently, many low-cost micro electro mechanical systems (MEMS) IMUs have emerged for only several hundred US dollars. In comparison to high-end IMUs, an entire Inertial Navigation System (INS) can be implemented with smaller size/volume, lower weight and costs. On the other hand, they have a relatively lower accuracy due to their larger systematic errors, such as bias, scale factor and drift, which highly depend on disturbance and temperature. Consequently, the original signal output of low-cost IMU must be processed to reconstruct smooth attitude estimation. For the application of mobile robot navigation, the algorithms need to be run on embedded processors with low memory and processing resources. This paper analyses various error sources in the attitude measurement for Mobile Robot using low-cost MEMS-IMU and discusses how to improve measurement accuracy by minimising the errors and optimising fusion algorithms. It presents the following aspects: investigating a cheap open source MEMS-IMU, enhancing ADC resolution by oversampling and averaging, filtering the noise caused by vibration, improving attitude estimation using sensor fusing.</td>
</tr>
<tr id="rev_6030374" class="review noshow">
	<td colspan="6"><b>Review</b>: Sensor Fusion-Based Attitude Estimation Using Low-Cost MEMS-IMU for Mobile Robot Navigation Lu Lou∗, Xin Xu†, Juan Cao∗, Zhili Chen‡ and Yi Xu∗ ∗College of Information Science and Engineering Chongqing Jiaotong University, Chongqing, China, 400074 Email: cloudlou@163.com †Library of Chongqing Jiaotong University Chongqing, China, 400074 Emai1: xx1771@163.com ‡Faculty of Information and Control Engineering Shenyang Jianzhu University, Shenyang, China, 110168 Emai1: chenzhili@sjzu.edu.cn Abstract—Recently, many low-cost micro electro mechanical is less sensitive to linear mechanical movements due to its systems (MEMS) IMUs have emerged for only several hundred capability of rotation measurement. But the accelerometer US dollars. In comparison to high-end IMUs, an entire Inertial seriously suffers from the type of noise caused by linear me- Navigation System (INS) can be implemented with smaller size/volume, lower weight and costs. On the other hand, they have chanical movements. In addition, gyros have other problems a relatively lower accuracy due to their larger systematic errors, like drift (i.e. they do not come back to zero-rate value when such as bias, scale factor and drift, which highly depend on rotation stops). Consequently, we can obtain a relatively better disturbance and temperature. Consequently, the original signal estimation of the vehicle attitude by averaging data from the output of low-cost IMU must be processed to reconstruct smooth accelerometer and gyro instead of using the accelerometer or attitude estimation. For the application of mobile robot naviga- tion, the algorithms need to be run on embedded processors gyro data separately. In order to overcome disadvantages of with low memory and processing resources. This paper analyses sensors, many sensor fusion methods have been developed. various error sources in the attitude measurement for Mobile The approach to mobile robot attitude estimation using two Robot using low-cost MEMS-IMU and discusses how to improve accelerometers and three gyros was developed [3]. In [4], the measurement accuracy by minimising the errors and optimising method for low level sensor fusion using both accelerometer fusion algorithms. It presents the following aspects: investigating a cheap open source MEMS-IMU, enhancing ADC resolution and odometer, was developed. Using inertial sensors, odometry by oversampling and averaging, ﬁltering the noise caused by and D-GPS, road vehicle state estimation has been proposed vibration, improving attitude estimation using sensor fusing. [5]. The estimation accuracy of IMUs highly depends on the sensor fusion algorithm. I. INTRODUCTION Unlike other related work where the COTS MEMS-IMU An Inertial Measurement Unit (IMU) is an electronic device was used as a testbed, we adopt a more ﬂexible and thorough to measure vehicle states like attitude, orientation, velocity, approach to improve the attitude measurement accuracy from and position. However, these states are not directly measurable lower (ﬁrmware of board) to higher levels (fusion and ﬁltering) with the current COTS IMU sensors. It has to be estimated by means of an open source MEMS-IMU. In this paper we from a set of correlated states like angular rate by the gyro, analyse various error sources in the attitude measurement for linear acceleration by accelerometer and heading angle by mobile robot using MEMS-IMU and discuss how to improve magnetometer. measurement accuracy by minimising the errors and optimis- Recently, many low-cost micro electro mechanical systems ing fusion algorithms. We present the following aspects: in- (MEMS) IMUs have emerged for only several hundred US vestigating a cheap open source MEMS-IMU, enhancing ADC dollars [1]. These MEMS-IMUs usually consist of three-axis resolution by oversampling and averaging, and ﬁltering the accelerometers, three-axis gyros or three-axis magnetometers. noise caused by vibration, and improving attitude estimation The accuracy of these three-axis sensors is not as good as more using sensor fusing. expensive IMUs. In addition, the acceleration and angular rate II. MINIMISING THE ERRORS OF MEMS-IMU are generally sensitive to measurement noise and the accuracy of attitude information degrades with time [2]. A. The Inertial navigation system of wheeled Mobile robot No sensor is perfect and no sensor suits all the applications. For reasons of convenience and economy, we select a However, these sensors have their own distinctive characters. cheap open source MEMS-IMU, 9DOF Razor IMU, provided For example, although the gyro is not free from noise, it by SparkFun Electronics. This IMU board costs only about ___________________________________ 978-1-4244-8625-0/11/$26.00 ©2011 IEEE <p></td>
</tr>
<tr id="bib_6030374" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6030374,
  author = {L. Lou and X. Xu and J. Cao and Z. Chen and Y. Xu},
  title = {Sensor fusion-based attitude estimation using low-cost MEMS-IMU for mobile robot navigation},
  booktitle = {2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference},
  year = {2011},
  volume = {2},
  pages = {465-468},
  doi = {http://dx.doi.org/10.1109/ITAIC.2011.6030374}
}
</pre></td>
</tr>
<tr id="Lowry2016" class="entry">
	<td>Lowry, S., Sunderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P. and Milford, M.J.</td>
	<td>Visual Place Recognition: A Survey <p class="infolinks">[<a href="javascript:toggleInfo('Lowry2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Lowry2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>IEEE Transactions on Robotics<br/>Vol. 32(1), pp. 1–19&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/tro.2015.2496823">DOI</a> <a href="http://dx.doi.org/10.1109/TRO.2015.2496823">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Lowry2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract—Visual place recognition is a challenging problem due to the vast range of ways in which the appearance of real-world places can vary. In recent years, improvements in visual sensing capabilities, an ever-increasing focus on long-term mobile robot au- tonomy, and the ability to draw on state-of-the-art research in other disciplines—particularly recognition in computer vision and ani- mal navigation in neuroscience—have all contributed to significant advances in visual place recognition systems. This paper presents a survey of the visual place recognition research landscape. We start by introducing the concepts behind place recognition—the role of place recognition in the animal kingdom, how a “place” is defined in a robotics context, and the major components of a place recognition system. Long-term robot operations have revealed that changing appearance can be a significant factor in visual place recognition failure; therefore, we discuss how place recognition solutions can implicitly or explicitly account for appearance change within the environment. Finally, we close with a discussion on the future of visual place recognition, in particular with respect to the rapid ad- vances being made in the related fields of deep learning, semantic scene understanding, and video description.</td>
</tr>
<tr id="bib_Lowry2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Lowry2016,
  author = {Lowry, Stephanie and Sunderhauf, Niko and Newman, Paul and Leonard, John J. and Cox, David and Corke, Peter and Milford, Michael J.},
  title = {Visual Place Recognition: A Survey},
  journal = {IEEE Transactions on Robotics},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2016},
  volume = {32},
  number = {1},
  pages = {1–19},
  url = {http://dx.doi.org/10.1109/TRO.2015.2496823},
  doi = {http://dx.doi.org/10.1109/tro.2015.2496823}
}
</pre></td>
</tr>
<tr id="Maaref20021" class="entry">
	<td>Maaref, H. and Barret, C.</td>
	<td>Sensor-based navigation of a mobile robot in an indoor environment  <p class="infolinks">[<a href="javascript:toggleInfo('Maaref20021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Maaref20021','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td>Robotics and Autonomous Systems <br/>Vol. 38(1), pp. 1 - 18&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S0921-8890(01)00165-8">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0921889001001658">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Maaref20021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The work presented in this paper deals with the problem of the navigation of a mobile robot either in unknown indoor environment or in a partially known one. A navigation method in an unknown environment based on the combination of elementary behaviors has been developed. Most of these behaviors are achieved by means of fuzzy inference systems. The proposed navigator combines two types of obstacle avoidance behaviors, one for the convex obstacles and one for the concave ones. The use of zero-order Takagi–Sugeno fuzzy inference systems to generate the elementary behaviors such as “reaching the middle of the collision-free space” and “wall-following” is quite simple and natural. However, one can always fear that the rules deduced from a simple human expertise are more or less sub-optimal. This is why we have tried to obtain these rules automatically. A technique based on a back-propagation-like algorithm is used which permits the on-line optimization of the parameters of a fuzzy inference system, through the minimization of a cost function. This last point is particularly important in order to extract a set of rules from the experimental data without having recourse to any empirical approach. In the case of a partially known environment, a hybrid method is used in order to exploit the advantages of global and local navigation strategies. The coordination of these strategies is based on a fuzzy inference system by an on-line comparison between the real scene and a memorized one. The planning of the itinerary is done by visibility graph and A∗ algorithm. Fuzzy controllers are achieved, on the one hand, for the following of the planned path by the virtual robot in the theoretical environment and, on the other hand, for the navigation of the real robot when the real environment is locally identical to the memorized one. Both the methods have been implemented on the miniature mobile robot Khepera® that is equipped with rough sensors. The good results obtained illustrate the robustness of a fuzzy logic approach with regard to sensor imperfections. </td>
</tr>
<tr id="bib_Maaref20021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Maaref20021,
  author = {H. Maaref and C. Barret},
  title = {Sensor-based navigation of a mobile robot in an indoor environment },
  journal = {Robotics and Autonomous Systems },
  year = {2002},
  volume = {38},
  number = {1},
  pages = {1 - 18},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889001001658},
  doi = {http://dx.doi.org/10.1016/S0921-8890(01)00165-8}
}
</pre></td>
</tr>
<tr id="Mac201613" class="entry">
	<td>Mac, T.T., Copot, C., Tran, D.T. and Keyser, R.D.</td>
	<td>Heuristic approaches in robot path planning: A survey  <p class="infolinks">[<a href="javascript:toggleInfo('Mac201613','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Mac201613','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Robotics and Autonomous Systems <br/>Vol. 86, pp. 13 - 28&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2016.08.001">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0921889015300671">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Mac201613" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Autonomous navigation of a robot is a promising research domain due to its extensive applications. The navigation consists of four essential requirements known as perception, localization, cognition and path planning, and motion control in which path planning is the most important and interesting part. The proposed path planning techniques are classified into two main categories: classical methods and heuristic methods. The classical methods consist of cell decomposition, potential field method, subgoal network and road map. The approaches are simple; however, they commonly consume expensive computation and may possibly fail when the robot confronts with uncertainty. This survey concentrates on heuristic-based algorithms in robot path planning which are comprised of neural network, fuzzy logic, nature-inspired algorithms and hybrid algorithms. In addition, potential field method is also considered due to the good results. The strengths and drawbacks of each algorithm are discussed and future outline is provided.</td>
</tr>
<tr id="bib_Mac201613" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Mac201613,
  author = {Thi Thoa Mac and Cosmin Copot and Duc Trung Tran and Robin De Keyser},
  title = {Heuristic approaches in robot path planning: A survey },
  journal = {Robotics and Autonomous Systems },
  year = {2016},
  volume = {86},
  pages = {13 - 28},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889015300671},
  doi = {http://dx.doi.org/10.1016/j.robot.2016.08.001}
}
</pre></td>
</tr>
<tr id="6386186" class="entry">
	<td>Maddern, W., Milford, M. and Wyeth, G.</td>
	<td>Towards persistent indoor appearance-based localization, mapping and navigation using CAT-Graph <p class="infolinks">[<a href="javascript:toggleInfo('6386186','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6386186','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4224-4230&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.2012.6386186">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6386186" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: The challenge of persistent appearance-based navigation and mapping is to develop an autonomous robotic vision system that can simultaneously localize, map and navigate over the lifetime of the robot. However, the computation time and memory requirements of current appearance-based methods typically scale not only with the size of the environment but also with the operation time of the platform; also, repeated revisits to locations will develop multiple competing representations which reduce recall performance. In this paper we present a solution to the persistent localization, mapping and global path planning problem in the context of a delivery robot in an office environment over a one-week period. Using a graphical appearance-based SLAM algorithm, CAT-Graph, we demonstrate constant time and memory loop closure detection with minimal degradation during repeated revisits to locations, along with topological path planning that improves over time without using a global metric representation. We compare the localization performance of CAT-Graph to openFABMAP, an appearance-only SLAM algorithm, and the path planning performance to occupancy-grid based metric SLAM. We discuss the limitations of the algorithm with regard to environment change over time and illustrate how the topological graph representation can be coupled with local movement behaviors for persistent autonomous robot navigation.</td>
</tr>
<tr id="bib_6386186" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6386186,
  author = {W. Maddern and M. Milford and G. Wyeth},
  title = {Towards persistent indoor appearance-based localization, mapping and navigation using CAT-Graph},
  booktitle = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2012},
  pages = {4224-4230},
  doi = {http://dx.doi.org/10.1109/IROS.2012.6386186}
}
</pre></td>
</tr>
<tr id="Matveev201621" class="entry">
	<td>Matveev, A.S., Savkin, A.V., Hoy, M. and Wang, C.</td>
	<td>3 - Survey of algorithms for safe navigation of mobile robots in complex environments  <p class="infolinks">[<a href="javascript:toggleInfo('Matveev201621','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Matveev201621','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Safe Robot Navigation Among Moving and Steady Obstacles , pp. 21 - 49&nbsp;</td>
	<td>incollection</td>
	<td><a href="http://dx.doi.org/10.1016/B978-0-12-803730-0.00003-2">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/B9780128037300000032">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Matveev201621" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract This chapter provides a review of techniques related to navigation of unmanned vehicles through unknown environments cluttered with obstacles, especially those that rigorously ensure collision avoidance (given certain assumptions about the system). This topic continues to be an active area of research, and we highlight some directions in which available approaches may be improved. The chapter discusses models of the sensors and vehicle kinematics, as well as assumptions about the environment and performance criteria. Methods applicable to stationary obstacles, moving obstacles, and scenarios with multiple vehicles are covered. In preference to global approaches based on full knowledge of the environment, particular attention is given to reactive methods based on only local sensory data, with a special focus on recently proposed navigation laws based on the sliding mode and model predictive control.</td>
</tr>
<tr id="bib_Matveev201621" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Matveev201621,
  author = {Alexey S. Matveev and Andrey V. Savkin and Michael Hoy and Chao Wang},
  title = {3 - Survey of algorithms for safe navigation of mobile robots in complex environments },
  booktitle = {Safe Robot Navigation Among Moving and Steady Obstacles },
  publisher = {Butterworth-Heinemann},
  year = {2016},
  pages = {21 - 49},
  url = {http://www.sciencedirect.com/science/article/pii/B9780128037300000032},
  doi = {http://dx.doi.org/10.1016/B978-0-12-803730-0.00003-2}
}
</pre></td>
</tr>
<tr id="Matveev201663" class="entry">
	<td>Matveev, A.S., Savkin, A.V., Hoy, M. and Wang, C.</td>
	<td>5 - Reactive navigation of wheeled robots for border patrolling  <p class="infolinks">[<a href="javascript:toggleInfo('Matveev201663','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Matveev201663','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Safe Robot Navigation Among Moving and Steady Obstacles , pp. 63 - 111&nbsp;</td>
	<td>incollection</td>
	<td><a href="http://dx.doi.org/10.1016/B978-0-12-803730-0.00005-6">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/B9780128037300000056">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Matveev201663" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract This chapter discusses the problem of reactively navigating a Dubins-car like robot along an equidistant curve of an environmental object or, otherwise stated, following the boundary of this object with a predefined range margin. Two sensing scenarios are considered. In one of them, navigation is based on access to the distance to the nearest point of the boundary. The other scenario assumes the distance to the boundary is measured perpendicularly to the robot’s centerline, and the angle of incidence of this perpendicular to the boundary is also accessible. For both scenarios, reactive sliding mode control laws are proposed that drive the robot at a prespecified distance from the boundary and thereafter maintain this distance. Mathematically rigorous analysis of the proposed control laws is provided. Computer simulations and experiments with real-wheeled robots confirm the applicability and performance of the proposed guidance approach. </td>
</tr>
<tr id="bib_Matveev201663" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Matveev201663,
  author = {Alexey S. Matveev and Andrey V. Savkin and Michael Hoy and Chao Wang},
  title = {5 - Reactive navigation of wheeled robots for border patrolling },
  booktitle = {Safe Robot Navigation Among Moving and Steady Obstacles },
  publisher = {Butterworth-Heinemann},
  year = {2016},
  pages = {63 - 111},
  url = {http://www.sciencedirect.com/science/article/pii/B9780128037300000056},
  doi = {http://dx.doi.org/10.1016/B978-0-12-803730-0.00005-6}
}
</pre></td>
</tr>
<tr id="6906961" class="entry">
	<td>McManus, C., Churchill, W., Maddern, W., Stewart, A.D. and Newman, P.</td>
	<td>Shady dealings: Robust, long-term visual localisation using illumination invariance <p class="infolinks">[<a href="javascript:toggleInfo('6906961','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6906961','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 901-906&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICRA.2014.6906961">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6906961" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper is about extending the reach and endurance of outdoor localisation using stereo vision. At the heart of the localisation is the fundamental task of discovering feature correspondences between recorded and live images. One aspect of this problem involves deciding where to look for correspondences in an image and the second is deciding what to look for. This latter point, which is the main focus of our paper, requires understanding how and why the appearance of visual features can change over time. In particular, such knowledge allows us to better deal with abrupt and challenging changes in lighting. We show how by instantiating a parallel image processing stream which operates on illumination-invariant images, we can substantially improve the performance of an outdoor visual navigation system. We will demonstrate, explain and analyse the effect of the RGB to illumination-invariant transformation and suggest that for little cost it becomes a viable tool for those concerned with having robots operate for long periods outdoors.</td>
</tr>
<tr id="bib_6906961" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6906961,
  author = {C. McManus and W. Churchill and W. Maddern and A. D. Stewart and P. Newman},
  title = {Shady dealings: Robust, long-term visual localisation using illumination invariance},
  booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  year = {2014},
  pages = {901-906},
  doi = {http://dx.doi.org/10.1109/ICRA.2014.6906961}
}
</pre></td>
</tr>
<tr id="McManus2015" class="entry">
	<td>McManus, C., Upcroft, B. and Newman, P.</td>
	<td>Learning place-dependant features for long-term vision-based localisation <p class="infolinks">[<a href="javascript:toggleInfo('McManus2015','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('McManus2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>Autonomous Robots<br/>Vol. 39(3), pp. 363-387&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/s10514-015-9463-y">DOI</a> <a href="http://dx.doi.org/10.1007/s10514-015-9463-y">URL</a>&nbsp;</td>
</tr>
<tr id="abs_McManus2015" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper presents an alternative approach to the problem of outdoor, persistent visual localisation against a known map. Instead of blindly applying a feature detector/descriptor combination over all images of all places, we leverage prior experiences of a place to learn place-dependent feature detectors (i.e., features that are unique to each place in our map and used for localisation). Furthermore, as these features do not represent low-level structure, like edges or corners, but are in fact mid-level patches representing distinctive visual elements (e.g., windows, buildings, or silhouettes), we are able to localise across extreme appearance changes. Note that there is no requirement that the features posses semantic meaning, only that they are optimal for the task of localisation. This work is an extension on previous work (McManus et al. in Proceedings of robotics science and systems, 2014b) in the following ways: (i) we have included a landmark refinement and outlier rejection step during the learning phase, (ii) we have implemented an asynchronous pipeline design, (iii) we have tested on data collected in an urban environment, and (iv) we have implemented a purely monocular system. Using over 100 km worth of data for training, we present localisation results from Begbroke Science Park and central Oxford.</td>
</tr>
<tr id="bib_McManus2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{McManus2015,
  author = {McManus, Colin and Upcroft, Ben and Newman, Paul},
  title = {Learning place-dependant features for long-term vision-based localisation},
  journal = {Autonomous Robots},
  year = {2015},
  volume = {39},
  number = {3},
  pages = {363--387},
  url = {http://dx.doi.org/10.1007/s10514-015-9463-y},
  doi = {http://dx.doi.org/10.1007/s10514-015-9463-y}
}
</pre></td>
</tr>
<tr id="Melo2013" class="entry">
	<td>Melo, L.F.d., Rosário, J.M. and Junior, A.F.d.S.</td>
	<td>Mobile Robot Indoor Autonomous Navigation with Position Estimation Using RF Signal Triangulation <p class="infolinks">[<a href="javascript:toggleInfo('Melo2013','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Melo2013','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Positioning<br/>Vol. 04(01), pp. 20–35&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.4236/pos.2013.41004">DOI</a> <a href="http://dx.doi.org/10.4236/pos.2013.41004">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Melo2013" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: ABSTRACT In the mobile robotic systems a precise estimate of the robot pose (Cartesian [x y] position plus orientation angle theta) with the intention of the path planning optimization is essential for the correct performance, on the part of the robots, for tasks that are destined to it, especially when intention is for mobile robot autonomous navigation. This work uses a ToF (Time-of-Flight) of the RF digital signal interacting with beacons for computational triangulation in the way to provide a pose estimative at bi-dimensional indoor environment, where GPS system is out of range. It’s a new technol- ogy utilization making good use of old ultrasonic ToF methodology that takes advantage of high performance multicore DSP processors to calculate ToF of the order about ns. Sensors data like odometry, compass and the result of triangula- tion Cartesian estimative, are fused in a Kalman filter in the way to perform optimal estimation and correct robot pose. A mobile robot platform with differential drive and nonholonomic constraints is used as base for state space, plants and measurements models that are used in the simulations and for validation the experiments.</td>
</tr>
<tr id="bib_Melo2013" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Melo2013,
  author = {Melo, Leonimer Flávio de and Rosário, João Mauricio and Junior, Almiro Franco da Silveira},
  title = {Mobile Robot Indoor Autonomous Navigation with Position Estimation Using RF Signal Triangulation},
  journal = {Positioning},
  publisher = {Scientific Research Publishing, Inc,},
  year = {2013},
  volume = {04},
  number = {01},
  pages = {20–35},
  url = {http://dx.doi.org/10.4236/pos.2013.41004},
  doi = {http://dx.doi.org/10.4236/pos.2013.41004}
}
</pre></td>
</tr>
<tr id="Meyer2003283" class="entry">
	<td>Meyer, J.-A. and Filliat, D.</td>
	<td>Map-based navigation in mobile robots:: II. A review of map-learning and path-planning strategies  <p class="infolinks">[<a href="javascript:toggleInfo('Meyer2003283','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Meyer2003283','bibtex')">BibTeX</a>]</p></td>
	<td>2003</td>
	<td>Cognitive Systems Research <br/>Vol. 4(4), pp. 283 - 317&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S1389-0417(03)00007-X">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S138904170300007X">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Meyer2003283" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This article reviews map-learning and path-planning strategies within the context of map-based navigation in mobile robots. Concerning map-learning, it distinguishes metric maps from topological maps and describes procedures that help maintain the coherency of these maps. Concerning path-planning, it distinguishes continuous from discretized spaces and describes procedures applicable when the execution of a plan fails. It insists on the need for an integrated conception of such procedures, which must be tightly tailored to the specific robot that is used, notably to the capacities and limitations of its sensory-motor equipment, and to the specific environment that is experienced. A hierarchy of navigation strategies is outlined in the discussion, together with the sort of adaptive capacities each affords to cope with unexpected obstacles or dangers encountered on an animat or robot’s way to its goal. </td>
</tr>
<tr id="bib_Meyer2003283" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Meyer2003283,
  author = {Jean-Arcady Meyer and David Filliat},
  title = {Map-based navigation in mobile robots:: II. A review of map-learning and path-planning strategies },
  journal = {Cognitive Systems Research },
  year = {2003},
  volume = {4},
  number = {4},
  pages = {283 - 317},
  url = {http://www.sciencedirect.com/science/article/pii/S138904170300007X},
  doi = {http://dx.doi.org/10.1016/S1389-0417(03)00007-X}
}
</pre></td>
</tr>
<tr id="Modules2015" class="entry">
	<td>Modules, P.-P., for Autonomous, Vehicles:, Status, C. and Challenges</td>
	<td>Int’l Conf. on Advanced Mechantronics, Intelligent Manufactur, and Industrial Application 2015 (ICAMIMIA 2015) Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia, on October <p class="infolinks">[<a href="javascript:toggleInfo('Modules2015','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Modules2015','review')">Review</a>] [<a href="javascript:toggleInfo('Modules2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Modules2015" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: A detailed survey of the available literature on path planning of Autonomous Ground Vehicle (AGV) is conducted, including the overview of single-robot control architectures, different path-planning approaches, analyses of current sensor systems and different velocity estimation techniques. In order to achieve the full autonomous operation of a mobile robot, path or motion planning, i.e., the planning of a collision-free path from a start to goal position through a collection of obstacles, is the fundamental task in the field of autonomous control systems. As AGVs are used in a wide variety of applications to perform autonomous tasks, organising their intelligence plays a key role in successfully programming a robot for a particular application and applying the right control architecture makes the autonomous control problem easier to solve. For autonomous vehicles, sensors play an important role in acquiring different attributes of the working environment and, by extracting meaningful information from these data, the autonomous system can acquire knowledge about its environment. Moreover, different velocity estimation techniques are reviewed in the context of dealing with the dynamic obstacles. A brief review of the available literature on path-planning approaches and techniques is provided.</td>
</tr>
<tr id="rev_Modules2015" class="review noshow">
	<td colspan="6"><b>Review</b>: Int’l Conf. on Advanced Mechantronics, Intelligent Manufactur, and Industrial Application 2015 (ICAMIMIA 2015) Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia, on October 15-17, 2015 Path-Planning Modules for Autonomous Vehicles: Current Status and Challenges Sreenatha G Anavatti SEIT, UNSW Canberra ACT, 2600, Australia s.anavatti@adfa.edu.au Sobers LX Francis SEIT, UNSW Canberra ACT, 2600, Australia soberslxf@gmail.com Matthew Garratt SEIT, UNSW Canberra ACT, 2600, Australia Email: m.garratt@adfa.edu.au Abstract—A detailed survey of the available literature on path environments. These challenges limit its use in numerous ap- planning of Autonomous Ground Vehicle (AGV) is conducted, plications, including flights of micro air vehicles through urban including the overview of single-robot control architectures, landscapes, automated mining exploration, digital mapping, different path-planning approaches, analyses of current sensor systems and different velocity estimation techniques. In order to environmental monitoring, military surveillance and reconnais- achieve the full autonomous operation of a mobile robot, path sance, search and rescue missions, underwater applications and or motion planning, i.e., the planning of a collision-free path industrial automation, which have all been hot topics in many from a start to goal position through a collection of obstacles, industrial and military fields [1]. is the fundamental task in the field of autonomous control A broad review was conducted of the developments in path systems. As AGVs are used in a wide variety of applications to perform autonomous tasks, organising their intelligence plays planning approaches from 1970 up to now. Mashehian’s and a key role in successfully programming a robot for a particular Sedighizadeh’s chronological review of motion planning over application and applying the right control architecture makes the 35 years was a helpful starting point. Path planning algorithms autonomous control problem easier to solve. For autonomous are often described as belonging to the classical algorithms vehicles, sensors play an important role in acquiring different class or intelligent algorithm class. The difference being in- attributes of the working environment and, by extracting mean- ingful information from these data, the autonomous system can telligent algorithms use meta-heuristics, changing conditional acquire knowledge about its environment. Moreover, different rules, to optimize an initial solution. Classical algorithms in velocity estimation techniques are reviewed in the context of comparison only use heuristics, fixed conditional rules, to dealing with the dynamic obstacles. A brief review of the restrict the application of the base algorithm. available literature on path-planning approaches and techniques The majority of papers separate the classical algorithms into is provided. three main approaches. Cell decomposition approach, Potential field approach and Roadmap approach being the three most I. I common classical approaches. Each method has advantageousNTRODUCTION and disadvantageous and the differences relate to how the There is increased attention in the scientific community to algorithm interprets the environment. enhance the intelligence of automation systems for different The path or motion planning methods have been described applications in hazardous work environments, such as chemi- in detail by many authors in the fields of artificial intelligence cally contaminated areas and regions with harsh temperatures [2], autonomous systems [3], [4], and computer science [5]. which are dangerous for humans to work in. The interest in The path-planning requirement in an unknown environment is mobile robotics stems mainly from the need to explore areas to plan the best possible path in such a way that the robot can that humans cannot explore safely. traverse it, re-plan it whenever it senses obstacles in its way As any autonomous system involving mobility needs path and repeat this process until it reaches its goal [6]. Unlike planning, this has been the main focus in the field of au- unmanned telerobotics, autonomous vehicles do not require tonomous control over the last few years. Since mobile robots any human supervisor to remotely control their motions. are used in a wide range of applications, several researchers Path planning of mobile robots relies greatly on known have been working on different methods for effectively fitting information about the immediate environment and the motion their requirements to overcome some of the significant chal- constraints of robotic kinematics and dynamics. If the envi- lenges facing the use of autonomous navigation in cluttered ronment is constant, well-structured and completely known, 1 205<p></td>
</tr>
<tr id="bib_Modules2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Modules2015,
  author = {Path-Planning Modules and for Autonomous and Vehicles: and Current Status and Challenges },
  title = {Int’l Conf. on Advanced Mechantronics, Intelligent Manufactur, and Industrial Application 2015 (ICAMIMIA 2015) Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia, on October},
  year = {2015}
}
</pre></td>
</tr>
<tr id="Mohanty2014" class="entry">
	<td>Mohanty, P.K. and Parhi, D.R.</td>
	<td>Path Planning Strategy for Mobile Robot Navigation Using MANFIS Controller <p class="infolinks">[<a href="javascript:toggleInfo('Mohanty2014','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>Proceedings of the International Conference on Frontiers of Intelligent Computing: Theory and Applications (FICTA) 2013, pp. 353-361&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://dx.doi.org/10.1007/978-3-319-02931-3_40">DOI</a> <a href="http://dx.doi.org/10.1007/978-3-319-02931-3_40">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Mohanty2014" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Mohanty2014,
  author = {Mohanty, Prases Kumar and Parhi, Dayal R.},
  title = {Path Planning Strategy for Mobile Robot Navigation Using MANFIS Controller},
  booktitle = {Proceedings of the International Conference on Frontiers of Intelligent Computing: Theory and Applications (FICTA) 2013},
  publisher = {Springer International Publishing},
  year = {2014},
  pages = {353--361},
  url = {http://dx.doi.org/10.1007/978-3-319-02931-3_40},
  doi = {http://dx.doi.org/10.1007/978-3-319-02931-3_40}
}
</pre></td>
</tr>
<tr id="Möller98insectstrategies" class="entry">
	<td>Möller, R., Lambrinos, D., Pfeifer, R. and Wehner, R.</td>
	<td>Insect Strategies of Visual Homing in Mobile Robots <p class="infolinks">[<a href="javascript:toggleInfo('Möller98insectstrategies','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Möller98insectstrategies','review')">Review</a>] [<a href="javascript:toggleInfo('Möller98insectstrategies','bibtex')">BibTeX</a>]</p></td>
	<td>1998</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Möller98insectstrategies" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. Insects, such as desert ants, employ visual homing strategies for returning to important places in their environment. A model that reproduces aspects of the insects’ navigation behavior is the “snapshot model”. It is based on the assumption that insects store a visual snapshot of the surroundings at the target location, and derive a home direction from a comparison of the current image with this snapshot. In this study, the snapshot model was adapted for robot navigation, extended with image processing routines, and tested on the mobile robot Sahabot 2. The precision of the visual homing achieved in the robot experiments is comparable to that of desert ants. On one hand, the experimental results confirm that the snapshot model is an appropriate model of insect navigation even under real-world conditions. On the other hand, they demonstrate that the parsimonious navigation strategies used by insects might be used as a guideline for the design of algorithms for robot navigation.</td>
</tr>
<tr id="rev_Möller98insectstrategies" class="review noshow">
	<td colspan="6"><b>Review</b>: Abstract. Insects, such as desert ants, employ visual homing strategies for returning to important places in their environment. A model that reproduces aspects of the insects’ navigation behavior is the “snapshot model”. It is based on the assumption that insects store a visual snapshot of the surroundings at the target location, and derive a home direction from a comparison of the current image with this snapshot. In this study, the snapshot model was adapted for robot navigation, extended with image processing routines, and tested on the mobile robot Sahabot 2. The precision of the visual homing achieved in the robot experiments is comparable to that of desert ants. On one hand, the experimental results confirm that the snapshot model is an appropriate model of insect navigation even under real-world conditions. On the other hand, they demonstrate that the parsimonious navigation strategies used by insects might be used as a guideline for the design of algorithms for robot navigation.</td>
</tr>
<tr id="bib_Möller98insectstrategies" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Möller98insectstrategies,
  author = {Ralf Möller and Dimitrios Lambrinos and Rolf Pfeifer and Rüdiger Wehner},
  title = {Insect Strategies of Visual Homing in Mobile Robots},
  year = {1998}
}
</pre></td>
</tr>
<tr id="Mujahed2016" class="entry">
	<td>Mujahed, M., Fischer, D. and Mertsching, B.</td>
	<td>Tangential Gap Flow (TGF) navigation: A new reactive obstacle avoidance approach for highly cluttered environments <p class="infolinks">[<a href="javascript:toggleInfo('Mujahed2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Mujahed2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 84, pp. 15–30&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2016.07.001">DOI</a> <a href="http://dx.doi.org/10.1016/j.robot.2016.07.001">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Mujahed2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract This paper presents a novel reactive collision avoidance method for mobile robots moving in dense and cluttered environments. The proposed method, entitled Tangential Gap flow (TGF), simplifies the navigation problem using a divide and conquer strategy inspired by the well-known Nearness-Diagram Navigation (ND) techniques. At each control cycle, the TGF extracts free openings surrounding the robot and identifies the suitable heading which makes the best progress towards the goal. This heading is then adjusted to avoid the risk of collision with nearby obstacles based on two concepts namely, tangential and gap flow navigation. The tangential navigation steers the robot parallel to the boundary of the closest obstacle while still emphasizing the progress towards the goal. The gap flow navigation safely and smoothly drives the robot towards the free area in between obstacles that lead to the target. The resultant trajectory is faster, shorter and less-oscillatory when compared to the ND methods. Furthermore, identifying the avoidance maneuver is extended to consider all nearby obstacle points and generate an avoidance rule applicable for all obstacle configurations. Consequently, a smoother yet much more stable behavior is achieved. The stability of the motion controller, that guides the robot towards the desired goal, is proved in the Lyapunov sense. Experimental results including a performance evaluation in very dense and complex environments demonstrate the power of the proposed approach. Additionally, a discussion and comparison with existing Nearness-Diagram Navigation variants is presented.</td>
</tr>
<tr id="bib_Mujahed2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Mujahed2016,
  author = {Mujahed, Muhannad and Fischer, Dirk and Mertsching, Bärbel},
  title = {Tangential Gap Flow (TGF) navigation: A new reactive obstacle avoidance approach for highly cluttered environments},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier BV},
  year = {2016},
  volume = {84},
  pages = {15–30},
  url = {http://dx.doi.org/10.1016/j.robot.2016.07.001},
  doi = {http://dx.doi.org/10.1016/j.robot.2016.07.001}
}
</pre></td>
</tr>
<tr id="Munoz2016" class="entry">
	<td>Muñoz, P., R-Moreno, M.D. and Barrero, D.F.</td>
	<td>Unified framework for path-planning and task-planning for autonomous robots <p class="infolinks">[<a href="javascript:toggleInfo('Munoz2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Munoz2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 82, pp. 1–14&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2016.04.010">DOI</a> <a href="http://dx.doi.org/10.1016/j.robot.2016.04.010">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Munoz2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Most of the robotic systems are designed to move and perform tasks in a variety of environments. Some of these environments are controllable and well-defined, and the tasks to be performed are generally everyday ones. However, exploration missions also enclose hard constraints such as driving vehicles to many locations in a surface of several kilometres to collect and/or analyse interesting samples. Therefore, a critical aspect for the mission is to optimally (or sub-optimally) plan the path that a robot should follow while performing scientific tasks. In this paper, we present up2ta, a new AI planner that interleaves path-planning and task-planning for mobile robotics applications. The planner is the result of integrating a modified PDDL planner with a path-planning algorithm, combining domain-independent heuristics and a domain-specific heuristic for path-planning. Then, up2ta can exploit capabilities of both planners to generate shorter paths while performing scientific tasks in an efficient ordered way. The planner has been tested in two domains: an exploration mission consisting of pictures acquisition, and a more challenging one that includes samples delivering. Also, up2ta has been integrated and tested in a real robotic platform for both domains.</td>
</tr>
<tr id="bib_Munoz2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Munoz2016,
  author = {Muñoz, Pablo and R-Moreno, María D. and Barrero, David F.},
  title = {Unified framework for path-planning and task-planning for autonomous robots},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier BV},
  year = {2016},
  volume = {82},
  pages = {1–14},
  url = {http://dx.doi.org/10.1016/j.robot.2016.04.010},
  doi = {http://dx.doi.org/10.1016/j.robot.2016.04.010}
}
</pre></td>
</tr>
<tr id="6787001" class="entry">
	<td>Naldi, R., Torre, A. and Marconi, L.</td>
	<td>Robust Control of a Miniature Ducted-Fan Aerial Robot for Blind Navigation in Unknown Populated Environments <p class="infolinks">[<a href="javascript:toggleInfo('6787001','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6787001','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>IEEE Transactions on Control Systems Technology<br/>Vol. 23(1), pp. 64-79&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/TCST.2014.2312929">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6787001" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper proposes a control strategy for a miniature ducted-fan aerial robot to safely perform flight missions in an unknown densely populated environment. The main novelty of the proposed framework is that the vehicle is assumed to be totally blind, namely the obstacles cannot be sensed a priori. Therefore, the presence of possible accidental contacts with the surrounding environment has to be taken into account. To maintain stability in such a complex scenario, mechanics, and control are co-designed. The proposed control strategy relies on some mechanical properties of the airframe, namely on the relative position of the contact points and of the onboard actuators, and on the design of a supervisor able to detect the presence of a contact only by observing the behavior of the flight control loop. The effectiveness of the obtained results is then demonstrated using experiments conducted on a ducted-fan prototype.</td>
</tr>
<tr id="bib_6787001" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{6787001,
  author = {R. Naldi and A. Torre and L. Marconi},
  title = {Robust Control of a Miniature Ducted-Fan Aerial Robot for Blind Navigation in Unknown Populated Environments},
  journal = {IEEE Transactions on Control Systems Technology},
  year = {2015},
  volume = {23},
  number = {1},
  pages = {64-79},
  doi = {http://dx.doi.org/10.1109/TCST.2014.2312929}
}
</pre></td>
</tr>
<tr id="Navigation2016" class="entry">
	<td>Navigation, R., of Techniques, R. and Challenges, R.</td>
	<td>Robot Navigation: Review of Techniques and Research Challenges <p class="infolinks">[<a href="javascript:toggleInfo('Navigation2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Navigation2016','review')">Review</a>] [<a href="javascript:toggleInfo('Navigation2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Proceedings of the 10th INDIACom; INDIACom-2016; IEEE Conference ID: 37465 2016 3rd International Conference on “Computing for Sustainable Global Development”, 16th - 18th March, 2016 &nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Navigation2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: – Robot navigation has multi-spectral applications have presented numerous solutions to the sub-tasks of the across a plethora of industries. Being one of the fastest evolving Navigation Problem but very few have been able to merge that field of Artificial intelligence, it has garnered a lot of speculation into a complete, wholesome and a restraint free solution. Most and the problem of efficient Robot navigation has become a of the completed work in this field focuses primarily on the talking point in the “Artificial Intelligence research community”. Robot Navigation can be thought of as a collection of sub- hardware component of the problem and treats the Robot as a problems that when solved efficiently will (most likely) give the physical entity. This instills a prominent restraint in the complete and the most efficient solution. While the main problem- that of uncertainty in the change in the environment Navigation problem can be divided into numerous smaller ones the robot is subjected to. While the ultimate goal of Robot some of the prevalent (sub)-tasks associated with Robot Navigation is to implement it in the real world, artificial Navigation are Path Planning, Collision Prevention, Search simulation would enable us to optimise the solution before its Algorithm and an appropriate pictorial (graphical) representation real implementation. of the given environment. Path Planning gives us the most optimal The first step to attaining a concrete (complete) solution would path finding approach while keeping the dynamism of the be to put together the current techniques of all the sub- environment and the objects in mind. Collision Prevention ensures the Robot reaches its goal without colliding with any of the objects problems underlining their advantages and anomalies. present in the environment. Collision Prevention techniques’ II. LITERATURE REVIEW vitality increases considerably when the number of objects in the input space is large (>10, approximately). Search Algorithms are The authors found the following to be the core sub-problems of the functional units of this problem as they determine the path the the Robot Navigation problem- Robot follows while traveling to its destination. Since the 1. Path Planning environment greatly affects the choice of technique for all the 2. Collision Prevention other tasks it is vital to have a clear, concise and a non-ambiguous 3. Search Algorithms representation of the same. The main aim of the paper is to summarise the development of various techniques in the multiple 4. State-Space representation of the Environment domains of the Robot Navigation problem in the last fifteen years Some other important work areas in the domain of the given (2000-2015) while stating the scope and the restriction of each of problem were - Image analysis[6] for the efficient working of them. the sensors (receptor area), Switching technique[7] -used to</td>
</tr>
<tr id="rev_Navigation2016" class="review noshow">
	<td colspan="6"><b>Review</b>: Proceedings of the 10th INDIACom; INDIACom-2016; IEEE Conference ID: 37465 2016 3rd International Conference on “Computing for Sustainable Global Development”, 16th - 18th March, 2016 Bharati Vidyapeeth's Institute of Computer Applications and Management (BVICAM), New Delhi (INDIA) Robot Navigation: Review of Techniques and Research Challenges Dr. Swati Aggarwal* Kushagra Sharma Manisha Priyadarshini Department of Computer Department of Computer Department of Computer Engineering, NSIT, Delhi University, Engineering, NSIT, Delhi University, Engineering, NSIT, Delhi University, New Delhi, India New Delhi, India New Delhi, India *Corresponding Author Email Id: sharma.kushagra7@gmail.com Email Id: manisha9735@gmail.com Email Id: swati1178@gmail.com Abstract – Robot navigation has multi-spectral applications have presented numerous solutions to the sub-tasks of the across a plethora of industries. Being one of the fastest evolving Navigation Problem but very few have been able to merge that field of Artificial intelligence, it has garnered a lot of speculation into a complete, wholesome and a restraint free solution. Most and the problem of efficient Robot navigation has become a of the completed work in this field focuses primarily on the talking point in the “Artificial Intelligence research community”. Robot Navigation can be thought of as a collection of sub- hardware component of the problem and treats the Robot as a problems that when solved efficiently will (most likely) give the physical entity. This instills a prominent restraint in the complete and the most efficient solution. While the main problem- that of uncertainty in the change in the environment Navigation problem can be divided into numerous smaller ones the robot is subjected to. While the ultimate goal of Robot some of the prevalent (sub)-tasks associated with Robot Navigation is to implement it in the real world, artificial Navigation are Path Planning, Collision Prevention, Search simulation would enable us to optimise the solution before its Algorithm and an appropriate pictorial (graphical) representation real implementation. of the given environment. Path Planning gives us the most optimal The first step to attaining a concrete (complete) solution would path finding approach while keeping the dynamism of the be to put together the current techniques of all the sub- environment and the objects in mind. Collision Prevention ensures the Robot reaches its goal without colliding with any of the objects problems underlining their advantages and anomalies. present in the environment. Collision Prevention techniques’ II. LITERATURE REVIEW vitality increases considerably when the number of objects in the input space is large (>10, approximately). Search Algorithms are The authors found the following to be the core sub-problems of the functional units of this problem as they determine the path the the Robot Navigation problem- Robot follows while traveling to its destination. Since the 1. Path Planning environment greatly affects the choice of technique for all the 2. Collision Prevention other tasks it is vital to have a clear, concise and a non-ambiguous 3. Search Algorithms representation of the same. The main aim of the paper is to summarise the development of various techniques in the multiple 4. State-Space representation of the Environment domains of the Robot Navigation problem in the last fifteen years Some other important work areas in the domain of the given (2000-2015) while stating the scope and the restriction of each of problem were - Image analysis[6] for the efficient working of them. the sensors (receptor area), Switching technique[7] -used to switch between multiple path finding algorithms, and Scope of Keywords– Robot Navigation; Robot Path Planning; Robot actions of the Robot - the kind of actions a Robot can be made Collision prevention; Robot Search Algorithms to perform after the all the other aspects have been put to use. Image analysis not only plays an important role in the visual I. INTRODUCTION reception of the robot[6] (further aiding its navigation) but it Robot Navigation finds extensive use in many real time also helps the user to get a clear picture of the spatial domains. Research areas like Nano-bots[1] and robotic Arm[2] representation of the obstacles and the path. Since, Robot have picked up speed and carry the potential of revolutionizing Navigation is a complex problem with inherent intricacies of the field of surgery and cancer treatment. Other fields that have uncertainties and dynamism it is pragmatic to use multiple benefited from the growth in Robot Navigation are Data search algorithms for a given environment. The choice of a Mining[3], Automation in Manufacturing[4] and CAD[5]. particular algorithm at a specific instant time is determined by Robotics in Artificial Intelligence has come a long way but a an objective function and the transition from one technique to lot still needs to be done. While independent works have been another is governed by a proper switching technique[7]. done on each of the problem a hybrid- modernistic approach is Since Path Planning is widely accepted as the first step in the yet to be formed. A lot of existing papers under this domain solution building process the paper also begins with the same. The techniques reviewed under this are Deterministic Path 978-9-3805-4421-2/16/$31.00©c 2016 IEEE 3660<p></td>
</tr>
<tr id="bib_Navigation2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Navigation2016,
  author = {Robot Navigation and Review of Techniques and Research Challenges},
  title = {Robot Navigation: Review of Techniques and Research Challenges},
  booktitle = {Proceedings of the 10th INDIACom; INDIACom-2016; IEEE Conference ID: 37465 2016 3rd International Conference on “Computing for Sustainable Global Development”, 16th - 18th March, 2016 },
  publisher = {IEEE},
  year = {2016}
}
</pre></td>
</tr>
<tr id="Noh2015" class="entry">
	<td>Noh, S.W., Seo, D.J., Kim, T.G., Jeong, S.D. and Kim, K.J.</td>
	<td>Implementation of Autonomous Navigation Using a Mobile Robot Indoor <p class="infolinks">[<a href="javascript:toggleInfo('Noh2015','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Noh2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>Advances in Computer Science and Ubiquitous Computing: CSA &amp; CUTE, pp. 751-756&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://dx.doi.org/10.1007/978-981-10-0281-6_106">DOI</a> <a href="http://dx.doi.org/10.1007/978-981-10-0281-6_106">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Noh2015" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper describes an implementation of autonomous navigation of a mobile robot indoors. The implementation includes map building, path planning, localization, local path planning and obstacle avoidance, and path tracking. ICP(Iterative closest point) is employed to build grid based map using scanned range data. Dijkstra algorithm plans path from an initial location to a goal position. Particle filter estimates the robot position and orientation using the scanned range data. Elastic force is used for local path planning and obstacle avoidance towards a goal position. The algorithms are combined for autonomous navigation in a work area of 100m x 40m, which comprises rooms, corridors, obstacles like passers-by, and many furniture and exhibition area. The robot ran at the maximum speed of l.0 m/sec, and passed all the way points and reached to goal location through the path of the length 165m in 255 seconds, with the average speed of O.65m/sec.</td>
</tr>
<tr id="bib_Noh2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Noh2015,
  author = {Noh, Sung Woo and Seo, Dong Jin and Kim, Tae Gyun and Jeong, Seong Dae and Kim, Kwang Jin},
  title = {Implementation of Autonomous Navigation Using a Mobile Robot Indoor},
  booktitle = {Advances in Computer Science and Ubiquitous Computing: CSA &amp; CUTE},
  publisher = {Springer Singapore},
  year = {2015},
  pages = {751--756},
  url = {http://dx.doi.org/10.1007/978-981-10-0281-6_106},
  doi = {http://dx.doi.org/10.1007/978-981-10-0281-6_106}
}
</pre></td>
</tr>
<tr id="5744468" class="entry">
	<td>Paterega, I.</td>
	<td>Artificial evolution mechanisms in robot navigation <p class="infolinks">[<a href="javascript:toggleInfo('5744468','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>CAD Systems in Microelectronics (CADSM), 2011 11th International Conference The Experience of Designing and Application of, pp. 281-286&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_5744468" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{5744468,
  author = {I. Paterega},
  title = {Artificial evolution mechanisms in robot navigation},
  booktitle = {CAD Systems in Microelectronics (CADSM), 2011 11th International Conference The Experience of Designing and Application of},
  year = {2011},
  pages = {281-286}
}
</pre></td>
</tr>
<tr id="Pazderski2002" class="entry">
	<td>Pazderski, D., Dutkiewicz, P., University, P. and of Technology</td>
	<td>Low-cost GPS Receivers in Navigation of Mobile Robots <p class="infolinks">[<a href="javascript:toggleInfo('Pazderski2002','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pazderski2002','review')">Review</a>] [<a href="javascript:toggleInfo('Pazderski2002','bibtex')">BibTeX</a>]</p></td>
	<td>2002</td>
	<td>&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Pazderski2002" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: In the paper, the satellite navigation system using low-cost GPS receivers is presented. The aim of the presented research was to verify usefulness of such receivers in navigation systems of mobile robots. Results of positioning errors using single receivers and simple DGPS system are shown.</td>
</tr>
<tr id="rev_Pazderski2002" class="review noshow">
	<td colspan="6"><b>Review</b>: Low-cost GPS Receivers in Navigation of Mobile Robots Dariusz Pazderski, Piotr Dutkiewicz Poznari University of Technology Institute of Control and Systems Engineering ul. Piotrowo 3a, 60-965 Poznari, Poland e-mail: Piotr.Dutkiewicz@put.poznan.pl Abstract interesting for mobile robots, because of the nature of absolute positioning. In the paper, the satellite navigation system using For example, this type of positioning is. imple- low-cost GPS receivers is presented. The aim of the mented in the most popular system called presented research was to verib usefulness of such Global Positioning System (GPS). GPS has receivers in navigation systems of mobile robots. demonstrated a significant potential for the civil Results of Positioning errors using single receivers and simple DGPS system are shown. community in an increasingly large variety of applications. 1 Introduction 2 Introduction to GPS The navigation subsystem is very important for autonomous mobile robots. Almost all of such The GPS includes three segments: ' Space devices use odometry systems to find their Segment, Control Segment and End-User position and orientation in a selected reference Segment. The Space Segment consists of at system. This kind of navigation is called least 24 operational satellites transmitting relative navigation. The main disadvantage of it navigation messages in form of the Coarse/ is unlimited increase of errors resulting in bad /Acquisition (C/A) code. Each satellite can be long-term accuracy. identified as it generates a unique code. The Therefore it is necessary to use absolute navigation message includes information about navigation and positioning that allows to obtain time t.?, referenced to the UTC (Universal global and time-independent information. There Coordinated Time), determining when the are many absolute navigation systems using ranging signal was transmitted from the vision systems, artificial beacons, ultrasonic or satellite. laser rangefinders, and radio systems [3]. The GPS receiver decodes information Development of the military navigation systems generated by satellites and uses them to calcu- resulted in space-based radionavigation. The late pseudo range PRN, defined as follows: satellite navigation allows to obtain global positioning in the reference system fixed to the PRN = c ,A t , , (1) Earth. They provide medium or high time- At, = t , - t , , (2) independent accuracy of positioning. The main drawback of the satellite navigation is immunity where: to jamming and signal outages. Reliability and t , - time that ranging measurement was recei- continuity are also much worse than those of ved at the user location, relative navigation systems. In spite of these c - speed of electromagnetic wave. limitations, satellite navigation seems to be very The main problem is that the clock of receiver is not synchronized with clocks of satellites and Third International Workshop on Robot Motion and Control, November 9-1 1,2002 119 <p></td>
</tr>
<tr id="bib_Pazderski2002" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Pazderski2002,
  author = {Dariusz Pazderski and Piotr Dutkiewicz and Poznari University and of Technology},
  title = {Low-cost GPS Receivers in Navigation of Mobile Robots},
  year = {2002}
}
</pre></td>
</tr>
<tr id="Pe´rez2014" class="entry">
	<td>Pe´rez, J., Caballero, F. and Merino, L.</td>
	<td>Integration of Monte Carlo Localization and Place Recognition for Reliable Long-Term Robot Localization <p class="infolinks">[<a href="javascript:toggleInfo('Pe´rez2014','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pe´rez2014','review')">Review</a>] [<a href="javascript:toggleInfo('Pe´rez2014','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) May 14-15, Espinho, Portugal&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Pe´rez2014" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— This paper proposes extending Monte Carlo Lo- calization methods with visual information in order to build a long term robot localization system. This system is aimed to work in crowded and non-planar scenarios, where 2D laser rangefinders may not always be enough to match the robot position with the map. Thus, visual place recognition will be used in order to obtain robot position clues that can be used to detect when the robot is lost and also to reset its positions to the right one. The paper presents experimental results based on datasets gathered with a real robot in challenging scenarios.</td>
</tr>
<tr id="rev_Pe´rez2014" class="review noshow">
	<td colspan="6"><b>Review</b>: 2014 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) May 14-15, Espinho, Portugal Integration of Monte Carlo Localization and Place Recognition for Reliable Long-Term Robot Localization Javier Pe´rez1, Fernando Caballero2 and Luis Merino1 Abstract— This paper proposes extending Monte Carlo Lo- calization methods with visual information in order to build a long term robot localization system. This system is aimed to work in crowded and non-planar scenarios, where 2D laser rangefinders may not always be enough to match the robot position with the map. Thus, visual place recognition will be used in order to obtain robot position clues that can be used to detect when the robot is lost and also to reset its positions to the right one. The paper presents experimental results based Fig. 1. The FROG project aims to deploy a guiding robot with a fun on datasets gathered with a real robot in challenging scenarios. personality, considering social feedback, in the Royal Alcazar of Seville and the Zoo of Lisbon. Young visitors surrounding the robot in the Royal Alcazar, interfering in sensor readings and interrupting robot’s trajectory. I. INTRODUCTION The work of this paper is part of larger project, the project FROG3, that aims to deploy a guiding robot in touris- it can perform poorly when large variations are present, as tic sites involving outdoor and partially outdoor scenarios. it can be seen in crowded and dynamic environments like While robot guides have been developed since more than the Lisbon Zoo and the Royal Alcazar, where people may a decade [1], the project considers as new contributions approach and surround the robot driven by curiosity (see the development of social behaviors and their adaptation by Figure 1) or while they are being guided. integrating social feedback, as well as the robust operation in Several approaches have been considered to enhance the outdoors crowded scenarios. It aims to demonstrate a long- robustness of localization systems. Thus, Hentschel and term operation of the robot in the Lisbon Zoo and the Royal Wagner [4] and Dayoub and Duckett [5] present in their Alcazar in Seville (see Figure 1). works environmental representations for autonomous mobile Navigating in these crowded places (the Royal Alcazar robots that continuously adapt over time, inspired by human may have more than 5000 visits per day) requires a robust lo- memory and storing the current as well as past knowledge of calization system. Achieving long-term localization involves the environment, using sensory memory, short-term memory several issues, like handling of variant environments, error and long-term memory. recovery, efficient place recognition, etc. Furthermore, those Online loop-detection algorithms based on scene- algorithms based on vision and visual place-recognition have recognition like OpenFabMap2 [6], DLoopDetector [7], and to deal with illumination changes, different weather and others [8] that use structures based on Bag-of-Words [9] daylight conditions, etc. Besides that, these scenarios may have been presented to look for revisited places, what is present a highly variable environment with partial sensor helpful for recovering from localization errors. Corke et occlusions due to the visitors, which can cause troubles al. [10] present an algorithm for getting invariant images to map-based localization using laser readings and dead for long-term localization based on scene appearance. They reckoning [2]. describe how to convert different time outdoor colour images Scan matching approaches based on 2D lasers are the most to greyscale invariant ones by considering the response of extended localization algorithms, due to their high accuracy the colour channels in trichromatic vision and removing compared to other sensors like ultrasonic sensors, and with illumination effect. a low processing cost compared to vision sensors [3]. These These visual algorithms can be easily used to provide addi- algorithms make use of a geometric map and scan matching tional localization hypotheses to the pose estimated by using to guess the new position of the robot from previous ones and other sensorial modalities, like laser rangefinders. These new dead reckoning. Scan matching can handle small variations hypotheses can be used to enhance the robustness of the in the environment, such as changes of state of doors, but localization system. In this paper we propose a localization algorithm based on a Monte Carlo Localization filter fed with This work is partially funded by the European Commission 7th Frame- particles from appearance clues obtained from images, which work Programme under grant agreement no. 288235 (FROG) and the project PAIS-MultiRobot, funded by the Junta de Andalucı´a (TIC-7390) will be able to recover from possible errors in localization, 1 Javier Pe´rez and Luis Merino are with the Pablo de Olavide University, combining the high accuracy of lasers with a re-localization Seville (Spain) jiperlar,lmercab@upo.es process. 2 Fernando Caballero is with University of Seville, Seville (Spain) fcaballero@us.es The structure of the paper is as follows: next section 3 http://www.frogrobot.eu describes the robotic platform used for tests. Then, Section 978-1-4799-4254-1/14/$31.00 ©2014 IEEE 85<p></td>
</tr>
<tr id="bib_Pe´rez2014" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Pe´rez2014,
  author = {Javier Pe´rez and Fernando Caballero and Luis Merino},
  title = {Integration of Monte Carlo Localization and Place Recognition for Reliable Long-Term Robot Localization},
  booktitle = {2014 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) May 14-15, Espinho, Portugal},
  publisher = {IEEE},
  year = {2014}
}
</pre></td>
</tr>
<tr id="Pivtoraiko2009" class="entry">
	<td>Pivtoraiko, M.</td>
	<td>Adaptive Anytime Motion Planning for Robust Robot Navigation in Natural Environments <p class="infolinks">[<a href="javascript:toggleInfo('Pivtoraiko2009','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pivtoraiko2009','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>2009 Advanced Technologies for Enhanced Quality of Life&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/at-equal.2009.33">DOI</a> <a href="http://dx.doi.org/10.1109/AT-EQUAL.2009.33">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Pivtoraiko2009" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— The problem of robot navigation is treated under constraints of limited perception horizon in complex, cluttered, natural environments. We propose a solution based on our pre- vious work in fast constrained motion planning, where arbitrary mobility constraints could be satisfied while the planning problem is reduced to unconstrained heuristic search in state lattices. By trading off optimality, we improve planner run-times and increase robustness through achieving anytime planning quality, such that it becomes possible to integrate the planner within the high speed navigation framework. We show that using a planner in navigation works well and fast enough for real vehicle implementation, while it presents a number of important benefits over state-of-the-art in navigation.</td>
</tr>
<tr id="bib_Pivtoraiko2009" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Pivtoraiko2009,
  author = {Pivtoraiko, Mihail},
  title = {Adaptive Anytime Motion Planning for Robust Robot Navigation in Natural Environments},
  journal = {2009 Advanced Technologies for Enhanced Quality of Life},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2009},
  url = {http://dx.doi.org/10.1109/AT-EQUAL.2009.33},
  doi = {http://dx.doi.org/10.1109/at-equal.2009.33}
}
</pre></td>
</tr>
<tr id="7150956" class="entry">
	<td>Pol, R.S. and Murugan, M.</td>
	<td>A review on indoor human aware autonomous mobile robot navigation through a dynamic environment survey of different path planning algorithm and methods <p class="infolinks">[<a href="javascript:toggleInfo('7150956','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7150956','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>Industrial Instrumentation and Control (ICIC), 2015 International Conference on, pp. 1339-1344&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IIC.2015.7150956">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7150956" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract : Practical realistic environment for path and continuous motion planning problems normally consist of numerous working areas such as in indoor application consist of number of bedrooms, hallways, multiple doorways with many static and dynamic obstacle in between. Disintegration of such environment into small areas, or regions shows impact on the quality of adaptive path planning in dynamic environment. Many algorithms are developed for solving problems involving narrow passages and multiple regions with optimal solution. Autonomous mobile robot system must have sense of balance of its potential, steadfastness and sturdiness issue with task and the final goals while generating and executing an adaptive as well as effective strategy with optimal solution. Navigation algorithms approaching to a certain maturity in the field of autonomous mobile robot, so most of research is now focused more advance task like adaptive path planning and navigation through dynamic environments. Adaptive path planning and navigation needs to set learning rate, rules for classifying spaces and defining proposed library parameters. The aim of this survey is to informing the progress of human sentient manipulation planner. Keyword — Autonomous mobile robot navigation, navigation through dynamic environment, adaptive path planning, human machine interaction, human aware navigation.</td>
</tr>
<tr id="bib_7150956" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7150956,
  author = {R. S. Pol and M. Murugan},
  title = {A review on indoor human aware autonomous mobile robot navigation through a dynamic environment survey of different path planning algorithm and methods},
  booktitle = {Industrial Instrumentation and Control (ICIC), 2015 International Conference on},
  year = {2015},
  pages = {1339-1344},
  doi = {http://dx.doi.org/10.1109/IIC.2015.7150956}
}
</pre></td>
</tr>
<tr id="Rady2016" class="entry">
	<td>Rady, S.</td>
	<td>Vision-Based Hybrid Map-Building and Robot Localization in Unstructured and Moderately Dynamic Environments <p class="infolinks">[<a href="javascript:toggleInfo('Rady2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Rady2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Novel Applications of Intelligent Systems, pp. 231–250&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/978-3-319-14194-7_12">DOI</a> <a href="http://dx.doi.org/10.1007/978-3-319-14194-7_12">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Rady2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract This work focuses on developing efficient environment representation and localization for mobile robots. A solution-approach is proposed for hybrid map-building and localization, which suits operating environments with unstruc- turedness and moderate dynamics. The solution-approach is vision-based and includes two phases. In the first phase, the map-building reduces the domain of extracted point features from local places through an information-theoretic analysis. The analysis simultaneously selects the most distinctive features only. The selected features are further compressed into codewords. The uncompressed features are also tagged with their metric position. In such a way, a unified map is created with hybrid data representation. In the second phase, the map is used to localize the robot. For fast topological localization, features extracted from the local place are compared to the codewords. To extend the localization into a metric pose, trian- gulation is executed hierarchically for the identified topological place with the use of the positional metric data of features. To ensure accurate position estimate, the dynamics of the environment are detected through the spatial layout of features and are isolated at the metric localization level. The proposed map-building and localization solution enables for a fast hybrid localization without degenerating the accuracy of localization.</td>
</tr>
<tr id="bib_Rady2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Rady2016,
  author = {Rady, Sherine},
  title = {Vision-Based Hybrid Map-Building and Robot Localization in Unstructured and Moderately Dynamic Environments},
  journal = {Novel Applications of Intelligent Systems},
  publisher = {Springer Science + Business Media},
  year = {2016},
  pages = {231–250},
  url = {http://dx.doi.org/10.1007/978-3-319-14194-7_12},
  doi = {http://dx.doi.org/10.1007/978-3-319-14194-7_12}
}
</pre></td>
</tr>
<tr id="rao1993robot" class="entry">
	<td>Rao, N.S., Kareti, S., Shi, W. and Iyengar, S.S.</td>
	<td>Robot navigation in unknown terrains: Introductory survey of non-heuristic algorithms <p class="infolinks">[<a href="javascript:toggleInfo('rao1993robot','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('rao1993robot','bibtex')">BibTeX</a>]</p></td>
	<td>1993</td>
	<td>&nbsp;</td>
	<td>techreport</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_rao1993robot" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A formal framework for navigating a robot in a geometric terrain populated by an unknown set of obstacles is considered. Here the terrain model is not a priori known, but the robot is equipped with a sensor system (vision or touch) employed for the purpose of navigation. Our focus is restricted to the non-heuristic algorithms which can be theoretically shown to be correct within a given framework of models for the robot, terrain and sensor system. These formulations, although abstract and sim- pli ed compared to real-life scenarios, provide foundations for practical systems by highlighting the underlying critical issues. First, we consider the algorithms that are shown to navigate correctly without much consideration given to the performance parameters such as distance traversed, etc. Second, we consider non-heuristic algo- rithms that guarantee bounds on the distance traversed or the ratio of the distance traversed to the shortest path length (computed if the terrain model is known). Then we consider the navigation of robots with very limited computational capabilities such as nite automata, etc.</td>
</tr>
<tr id="bib_rao1993robot" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@techreport{rao1993robot,
  author = {Rao, Nagewara SV and Kareti, Srikumar and Shi, Weimin and Iyengar, S Sitharama},
  title = {Robot navigation in unknown terrains: Introductory survey of non-heuristic algorithms},
  year = {1993}
}
</pre></td>
</tr>
<tr id="rashid2013path" class="entry">
	<td>Rashid, A.T., Ali, A.A., Frasca, M. and Fortuna, L.</td>
	<td>Path planning with obstacle avoidance based on visibility binary tree algorithm <p class="infolinks">[<a href="javascript:toggleInfo('rashid2013path','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 61(12), pp. 1440-1449&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_rashid2013path" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{rashid2013path,
  author = {Rashid, Abdulmuttalib Turky and Ali, Abduladhem Abdulkareem and Frasca, Mattia and Fortuna, Luigi},
  title = {Path planning with obstacle avoidance based on visibility binary tree algorithm},
  journal = {Robotics and Autonomous Systems},
  publisher = {North-Holland},
  year = {2013},
  volume = {61},
  number = {12},
  pages = {1440--1449}
}
</pre></td>
</tr>
<tr id="724262" class="entry">
	<td>Rendas, M.J. and Rolfes, S.</td>
	<td>Path planning in extended uncertain environments <p class="infolinks">[<a href="javascript:toggleInfo('724262','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('724262','bibtex')">BibTeX</a>]</p></td>
	<td>1998</td>
	<td><br/>Vol. 2Industrial Electronics Society, 1998. IECON '98. Proceedings of the 24th Annual Conference of the IEEE, pp. 1152-1157 vol.2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IECON.1998.724262">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_724262" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: This paper presents a new approach to the problem of planning the motion of a mobile robot in extended uncertain environments. All knowledge of the environment has been acquired by the robot during the current (or a previous) operation, such that the environment description reflects the accumulated error of the robot's pose during periods of dead-reckoning navigation. In this uncertain environment, the robot searches for trajectories that maximize the probability of attaining a desired target region. For that purpose we identify a discrete set of robot positions in order to construct a routing graph, whose arcs represent the probability of reaching a new position. In that way the search for an optimal trajectory is solved by searching for a minimum weight path in a routing graph. The method is based on a probabilistic model of all the errors/uncertainties affecting the reliability of the planned trajectory.</td>
</tr>
<tr id="bib_724262" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{724262,
  author = {M. J. Rendas and S. Rolfes},
  title = {Path planning in extended uncertain environments},
  booktitle = {Industrial Electronics Society, 1998. IECON '98. Proceedings of the 24th Annual Conference of the IEEE},
  year = {1998},
  volume = {2},
  pages = {1152-1157 vol.2},
  doi = {http://dx.doi.org/10.1109/IECON.1998.724262}
}
</pre></td>
</tr>
<tr id="6232811" class="entry">
	<td>Sadeghi-Tehran, P., Behera, S., Angelov, P. and Andreu, J.</td>
	<td>Autonomous visual self-localization in completely unknown environment <p class="infolinks">[<a href="javascript:toggleInfo('6232811','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6232811','review')">Review</a>] [<a href="javascript:toggleInfo('6232811','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>2012 IEEE Conference on Evolving and Adaptive Intelligent Systems, pp. 90-95&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/EAIS.2012.6232811">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6232811" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract - In this paper, a novel approach to visual self­ localization in an unknown environment is presented. The proposed method makes possible the recognition of new landmark without using GPS or any other communication links or pre-training. An image-based self-localization technique is used to automatically label landmarks that are detected in real-time using a computationally efficient and recursive algorithm. Real-time experiments are carried in outdoor environment at Lancaster University using a real mobile robot Pioneer 3DX in order to build a map the local environment without using any communication links. The presented experimental results in real situations show the effectiveness of the proposed method.</td>
</tr>
<tr id="rev_6232811" class="review noshow">
	<td colspan="6"><b>Review</b>: Autonomous Visual Self-localization in Completely Unknown Environment Pouria Sadeghi-Tehran, Sasmita Behera, Plamen Angelov, and Javier Andreu School of Computing and Communications, InfoLab21, Lancaster University, United Kingdom, LAI 4WA Abstract - In this paper, a novel approach to visual self­ recognition is always a controversial topic among the localization in an unknown environment is presented. The research and industrial communities. proposed method makes possible the recognition of new landmark without using GPS or any other communication One of the common techniques for landmark links or pre-training. An image-based self-localization recognition is using image-based techniques in which technique is used to automatically label landmarks that are landmarks are represented by collections of images which detected in real-time using a computationally efficient and capture the "typical" appearance of the object. The recursive algorithm. Real-time experiments are carried in information most relevant to recognition is extracted from outdoor environment at Lancaster University using a real the collection of raw images and used as the model for mobile robot Pioneer 3DX in order to build a map the local recognition. This process is often referred to as ''visual environment without using any communication links. The presented experimental results in real situations show the learning" [3]. effectiveness of the proposed method. Visual navigation in an outdoor environment is more complex and it is a challenging problem than navigation Keywords- visual-based landmarks, mobile robot; in an indoor environment due to lack of determined autonomous navigation, KDE, RDE Cauchy Kernel features and objects such as walls, comers, corridors, etc. [4-6]. The main obstacle ahead for navigation is the scope of prospect in an outdoor environment which is vaster than indoor environment. Another challenge for I. INTRODUCTION navigation in outdoor environment is the fact that natural During the last decade, autonomous mobile robots landmarks (such as rocks, trees, etc.) are subject to have drawn an extensive attention in the scientific illumination changes, seasonal changes, etc. [7] which community as well as in industry. The role of autonomous makes the analysis of an outdoor environment more mobile robots operated in dangerous tasks such as complex. Consequently, successful outdoor terrain defence, security, etc. applications has grown navigation requires an on-line autonomous system for significantly. In many cases, when the new environment is self-localization and supplying location map. In order to difficult to explore by a human or beyond the scope of satisfy the autonomy requirements, using unsupervised human reach due to some difficulties or the human life is learning approaches is vital. In the other words, exploring at risk, using autonomous mobile robots is inevitable and an unknown environment using mobile robots requires using a reliable navigation system for such an autonomous unsupervised leaming methods. That means the robot has mobile robot is vital. Terrain navigation requires a map to move along the scene, grab the frames and analyse and absolute coordinates, or landmarks which is either them in order to determine the landmarks existing in the artificial [I] or extracted from the environment. If the map scene. Additionally, the mentioned method should be and absolute coordinates are unavailable or unreliable, a computationally efficient, inexpensive and suitable for mobile robot can use the surrounding environment such as real-time implementations. walls, trees, rocks, etc. to extract knowledge and use them as landmarks [2]. In this paper, an efficient image-based technique is used by the mobile robot to automatically label new Landmark recognition in sequences of images is a landmark while it is exploring a new environment using challenging task for number of reasons. First, and main only its on-board sensors and computational device. No reason, is that the appearance of any given landmark communication link or positioning devices (such as varies considerably from one observation to the next. The GPS/Glonass/Galileo) is used neither any features of the other difficulties can be listed such as illumination pre-defined landmark nor pre-installed knowledge. changes, external clutter, and changing geometry of the imaging devices. For those reasons, using reliable object The remainder of the paper is organised as follows. First, in Section IT some related works on landmark 978-1-4673-1727-6/12/$31.00 ©2013 IEEE 90 <p></td>
</tr>
<tr id="bib_6232811" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6232811,
  author = {P. Sadeghi-Tehran and S. Behera and P. Angelov and J. Andreu},
  title = {Autonomous visual self-localization in completely unknown environment},
  booktitle = {2012 IEEE Conference on Evolving and Adaptive Intelligent Systems},
  year = {2012},
  pages = {90-95},
  doi = {http://dx.doi.org/10.1109/EAIS.2012.6232811}
}
</pre></td>
</tr>
<tr id="Schmitt2012" class="entry">
	<td>Schmitt, S., Will, H., Aschenbrenner, B., Hillebrandt, T., Kyas, M., Universita¨t, F. and Berlin</td>
	<td>A Reference System for Indoor Localization Testbeds <p class="infolinks">[<a href="javascript:toggleInfo('Schmitt2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Schmitt2012','review')">Review</a>] [<a href="javascript:toggleInfo('Schmitt2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>2012 International Conference on Indoor Positioning and Indoor Navigation, 13-15th November 2012&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Schmitt2012" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract—We present a low-cost robot system capable of performing robust indoor localization while carrying components of another system which shall be evaluated. Using off-the-shelf components, the ground truth positioning data provided by the robot can be used to evaluate a variety of localization systems and algorithms. Not needing any pre-installed components in its environment, it is very easy to setup. The robot system relies on wheel-odometry data of a Roomba robot, and visual distance measurements of two Kinects. The Robot Operating System (ROS) is used for the localization process according to a precise pre-drawn floor plan that may be enhanced with Simultaneous Localization and Mapping (SLAM). The system is able to estimate its position with an average error of 6.7 cm. It records its own positioning data as well as the data from the system under evaluation and provides simple means for analysis. It is also able to re-drive a previous test run if reproducable conditions are needed.</td>
</tr>
<tr id="rev_Schmitt2012" class="review noshow">
	<td colspan="6"><b>Review</b>: 2012 International Conference on Indoor Positioning and Indoor Navigation, 13-15th November 2012 A Reference System for Indoor Localization Testbeds Simon Schmitt, Heiko Will, Benjamin Aschenbrenner, Thomas Hillebrandt and Marcel Kyas Freie Universita¨t Berlin AG Computer Systems &amp; Telematics, Berlin, Germany simon.schmitt, heiko.will, benjamin.aschenbrenner, thomas.hillebrandt, marcel.kyas@fu-berlin.de While moving through rooms and corridors, both systems Abstract—We present a low-cost robot system capable of must thereby not interfere in performing their localization. performing robust indoor localization while carrying components For example, nearby people controlling the RS during a of another system which shall be evaluated. Using off-the-shelf components, the ground truth positioning data provided by the run can disturb a SUE. For that reason, the RS has to be robot can be used to evaluate a variety of localization systems capable of moving autonomous or remote controlled during an and algorithms. Not needing any pre-installed components in experiment. Also, the used radio frequencies and bandwidth its environment, it is very easy to setup. The robot system must not interfere with the SUE. The RS should not need any relies on wheel-odometry data of a Roomba robot, and visual pre-installed infrastructure in its environment, e.g. deployed distance measurements of two Kinects. The Robot Operating System (ROS) is used for the localization process according cameras or beacons enabling the localization. Therefore, the to a precise pre-drawn floor plan that may be enhanced with RS has to be able to estimate its own position in relation Simultaneous Localization and Mapping (SLAM). The system is to a given coordinate system. The position estimation error able to estimate its position with an average error of 6.7 cm. during the performance has to be an order lower than expected It records its own positioning data as well as the data from the errors of a SUE in order to allow a fine grained comparison system under evaluation and provides simple means for analysis. It is also able to re-drive a previous test run if reproducable of different localization approaches. conditions are needed. We present a precise and inexpensive mobile RS capable Index Terms—Indoor Localization, Robot Operating System, of performing robust indoor localization on floors in most Kinect, Simultaneous Localization and Mapping, Reference Sys- common office-like environments using Robot Operating Sys- tem tem (ROS) [1]. The benefit of this system is that it does not need any pre-installed infrastructure and can easily be I. INTRODUCTION used in various buildings. It consists of a Roomba cleaning While widely accepted simulations of indoor localization robot [2] and a laptop which is mounted on top the Roomba. systems and algorithms provide significant insight into their The software running on the computer is able to estimate behavior, modeling a sufficient level of detail can often be the robot’s position relative to a coordinate frame, which difficult. But frequent analysis under real-world conditions is is defined by a pre-drawn floor plan. For the localization, essential to optimize new algorithms for best results. Real- odometry data from the Roomba is combined with visual world experiments in this domain are hard to evaluate because distance measurements taken by a Kinect depth sensor [3] a Reference System (RS) which provides a more precise lo- which is also mounted on the robot. The use of a rack allows calization capability than the System Under Evaluation (SUE) the additional mounting of the mobile component of the SUE. is needed to get ground truth data. With such a system one The use of open-source software assures a high customizability can evaluate various localization techniques - for example for hard- and software. We implemented a middleware that based on time-of-flight measurements. Without such a RS, allows us to collect data produced by a SUE as well as the real-world positions of a SUE would have to be collected by ground truth positions from the RS itself. We are able to hand, which is difficult and time consuming considering not continuously calculate the robot’s position with an average only the position itself, but also the exact time at which the position estimation error of 6.7 cm. The system was evaluated position was measured or estimated. This is most important by driving along a grid of known positions while performing if a continuously moving component shall be tracked. The self-localization. Furthermore, we show how Simultaneous gathered ground truth data and the estimated positions of Localization and Mapping (SLAM) improves localization in the SUE can then be synchronized by using timestamps for rooms essentially, and we argue the need for re-running tests further analysis. With such a RS, various localization systems, regarding the timing of the initial run. algorithms, and their configurations can easily be evaluated and compared to one another. II. RELATED WORK In order to evaluate another system, such a mobile RS Simulation is still dominant when it comes to evaluating has to be able to carry the needed components of the SUE. indoor positioning algorithms and techniques. When perform- 978-1-4673-1954-6/12/$31.00 ©c 2012 IEEE<p></td>
</tr>
<tr id="bib_Schmitt2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Schmitt2012,
  author = {Simon Schmitt and Heiko Will and Benjamin Aschenbrenner and Thomas Hillebrandt and Marcel Kyas and Freie Universita¨t and Berlin },
  title = {A Reference System for Indoor Localization Testbeds},
  booktitle = {2012 International Conference on Indoor Positioning and Indoor Navigation, 13-15th November 2012},
  publisher = {IEEE},
  year = {2012}
}
</pre></td>
</tr>
<tr id="Schroeter2004" class="entry">
	<td>Schroeter, C., Boehme, H.-J., Gross, H.-M., University, I.T. and Germany</td>
	<td>Robust Map Building for an Autonomous Robot using Low-cost Sensors <p class="infolinks">[<a href="javascript:toggleInfo('Schroeter2004','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Schroeter2004','review')">Review</a>] [<a href="javascript:toggleInfo('Schroeter2004','bibtex')">BibTeX</a>]</p></td>
	<td>2004</td>
	<td>2004 IEEE International Conference on Systems, Man and Cybernetics&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Schroeter2004" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: The paper describes an approach for building a map of an indoor environment with a mobile robot, using a combination of odometry and sonar range sensors. Aiming for real-time large scale mapping on low-cost platforms with limited sensory and computational equipment, we discard high-complexity techniques like probabilistic SLAM. Instead, the algorithms presented here involve odometry correction and automatic pose recalibration, enabling us to build a coherent map that can be used for navigation and self-localization. Experimental results from different environments prove the efficiency of our approach.</td>
</tr>
<tr id="rev_Schroeter2004" class="review noshow">
	<td colspan="6"><b>Review</b>: 2004 IEEE International Conference on Systems, Man and Cybernetics Robust Map Building for an Autonomous Robot using Low-cost Sensors* Christof Schroeter, Hans-Joacllim Boehme, Horst-Michael Gross Ilmeiiau Technical University, Germany christof.sc1iroeterQtu-ilmeiiau.de Abstract - The paper describes an. approach for build- ing odometry (egomotion measurements) as main pose ing a map of an indoor environment with a mobile robot, information and combining i t with internal map align- using a combination of odomety and sonar range sen- ment and visual input for increased accuracy. The re- SOTS. Aiming for real-time large scale mapping on low- mainder of the paper is structured as follows. In section cost platforms with limited senso y and computational 2 we give an overview of related research work i n t.lie equipment, we discard high-complerity techniques like field of pose estimat.ion. Section 3 explains in det,ail probabilistic SLAM. Instead, the algorithms presented the algorithms used in our approach and demonstrat,es here involve odometry correction and automatic pose re- results of mapping different em-ironmeiits. Section 4 calibration, e n a b h g us to build a coherent m.ap that can contains our coiiclusions and plans for fnrther research. be used for iiavigation. and self-localization. Experimen- tal results from different environments prove the e f i - 2 Related Work ciency Of OUT approach. Usually, a mobile robot is equipped with wheel en- Keywords : Odometry correction, localization, map- coders that enable i t to measure its own motioii and ping determine the current posit,ion by dead-reackoiiing, i.e. integrating incremental motion iiiformat.ion over time. 1 Introduction Odometry is widely used because it provides high sam- pling rates and good short-term accuracy for a low price. Self-Localization and Map-Building are two of t,he However, i t inevitably leads to accumulatioii of system- key requirements for an autonomous mobile robot. The atic aiid non-systematic measurement errors: resulting robot must know ahere it is located within a certain ref- in a growing difference between believed aud real po- erence frame and it must be aware of its environment by sition. Therefore, uncorrected odometry alone is not a means of an eiivironment model (map). Tlie'purpose of reliable method for tracking a mobile robot's pose and the map is to enable a robot t,o act reasonably within its building consistent large-scale maps. eiivironment. Therefore; i t must contain those features Borenstein et al. described calibration for a robot's that are required for the desired behaviour. Since the odometry system' in [l]. Their approach focussed on behaviour of an autonomous robot is based on its sai- identifying possible error sources for a differential drive sorical input, the environment model preferrably should robot and determining parameters t o explicitly cor- be built from sensor readings t,oo, instead of providing rect those errors. Martinelli [SI presented a strategy a designer model. for experimentally determining the systematic and non- For a mobile robot, localization and mapping bear syst,ematic errors in a synchro-drive robot, estimating mutual interdependencies. %1t i' the pose known, the error parameters from several observables. robot can integrate sensor readings into a common External sensors have been used to increase the ac- frame as it moves around, iteratively updat.iiig its en- curacy of odometry. A very popular approach is scan vironment model. Likewise, with a known map, i t is matching, where overlapping sensor 'readings from dif- possible to determine the robot pose by comparison of ferent locations are compared and matched to compen- sensor input and features stored in the map. In the ab- sate for the error aquired while moving from one posi- sence of accurate pose information as well as a model of tion to the next one [ 5 ] . Scan matching depends on high the environment, both localization and mapping present accuracy and resolution of the sensor for. good matching complex tasks. results. Hence, usually laser scanners are used for this In this paper we will focus on the aim of learning a task. consistent geometric map from sonar range readings, us- As aforementioned, another possible approach to lo- *0-7803-8566-7/04/$20.0@0 2004 IEEE. calization is using a given map to determine the current 5398 <p></td>
</tr>
<tr id="bib_Schroeter2004" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Schroeter2004,
  author = {Christof Schroeter and Hans-Joacllim Boehme and Horst-Michael Gross and Ilmeiiau Technical University and Germany},
  title = {Robust Map Building for an Autonomous Robot using Low-cost Sensors},
  booktitle = {2004 IEEE International Conference on Systems, Man and Cybernetics},
  publisher = {IEEE},
  year = {2004}
}
</pre></td>
</tr>
<tr id="Shah2011" class="entry">
	<td>Shah, D.C., Campbell, M.E., of Mechanical Engineering, D., University, C., Ithaca and NY</td>
	<td>A Robust Qualitative Planner for Mobile Robot Navigation Using Human-Provided Maps <p class="infolinks">[<a href="javascript:toggleInfo('Shah2011','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Shah2011','review')">Review</a>] [<a href="javascript:toggleInfo('Shah2011','bibtex')">BibTeX</a>]</p></td>
	<td>2011</td>
	<td>2011 IEEE International Conference on Robotics and Automation Shanghai International Conference Center May 9-13, 2011, Shanghai, China&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Shah2011" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A novel method for controlling a mobile robot sketched trajectory, a corresponding waypoint in the robot’s using qualitative inputs in the context of an approximate map, environment is calculated using quadratic optimization to such as one sketched by a human, is presented. By defining a d best maintain its spatial relationships to all landmarks. Thisesired trajectory with respect to observable landmarks, human operators can send semi-autonomous robots into areas approach provides an on-line, dynamic planner that accounts for which a truth map is not available. Waypoint planning is for localization errors (i.e. uncertainty in the true landmarks formulated as a quadratic optimization problem, resulting in positions) as well as missing or unobserved landmarks; robot trajectories in the true environment that are qualitatively can accommodate arbitrary trajectories (e.g. not limited to similar to those provided by the human. The algorithm is implemented both in simulation and on a mobile robot pl straight-line paths); and is robust to sketch distortions.atform in several different environments. A sensitivity analysis is per- f II. BACKGROUND AND RELATED WORKormed, illustrating how the method is robust to uncertainties, even large sketch distortions, and allows the robot to adapt and Robot navigation using qualitative maps has been ad- re-plan according to its most current perception of the world. dressed in recent years. Navigation using topological dia-<br></td>
</tr>
<tr id="rev_Shah2011" class="review noshow">
	<td colspan="6"><b>Review</b>: 2011 IEEE International Conference on Robotics and Automation Shanghai International Conference Center May 9-13, 2011, Shanghai, China A Robust Qualitative Planner for Mobile Robot Navigation Using Human-Provided Maps Danelle C. Shah, Mark E. Campbell Department of Mechanical Engineering, Cornell University, Ithaca, NY dcs45,mc288@cornell.edu Abstract—A novel method for controlling a mobile robot sketched trajectory, a corresponding waypoint in the robot’s using qualitative inputs in the context of an approximate map, environment is calculated using quadratic optimization to such as one sketched by a human, is presented. By defining a d best maintain its spatial relationships to all landmarks. Thisesired trajectory with respect to observable landmarks, human operators can send semi-autonomous robots into areas approach provides an on-line, dynamic planner that accounts for which a truth map is not available. Waypoint planning is for localization errors (i.e. uncertainty in the true landmarks formulated as a quadratic optimization problem, resulting in positions) as well as missing or unobserved landmarks; robot trajectories in the true environment that are qualitatively can accommodate arbitrary trajectories (e.g. not limited to similar to those provided by the human. The algorithm is implemented both in simulation and on a mobile robot pl straight-line paths); and is robust to sketch distortions.atform in several different environments. A sensitivity analysis is per- f II. BACKGROUND AND RELATED WORKormed, illustrating how the method is robust to uncertainties, even large sketch distortions, and allows the robot to adapt and Robot navigation using qualitative maps has been ad- re-plan according to its most current perception of the world. dressed in recent years. Navigation using topological dia- grams of structured environments has been presented in [3], I. INTRODUCTION AND MOTIVATION [4], [5] and [6]. In these works, schematic maps are used to In recent years, significant effort has been applied towards encode qualitative spatial information about the physical en- developing mobile robots for performing many tasks once vironment. Navigation is accomplished by performing spatial undertaken solely by humans. In hazardous or inaccessible reasoning and matching sensory data with modeled sensor environments, such as those encountered in disaster-relief behavior at intermediate goal points along the route. These operations or planetary exploration, mobile robots are often approaches rely on structured environments (such as an office able to navigate areas that humans cannot [1]. In the future, building) and are not robust to large map inaccuracies. autonomous urban vehicles and domestic assistance robots In [7], an operator works from a rough initial map indicat- plan to offer increased convenience and independence to ing the approximate current location of the robot and a path their human users by performing navigation tasks semi- or of ‘via points’ to a goal. The relations to expected visible completely autonomously [2]. landmarks (encoded in the Landmark Egosphere, LES) and As mobile robots become more ubiquitous, communi- sensed landmarks (encoded in the Sensory Egosphere, SES) cation between such agents and their human counterparts are compared. A via point is considered reached if the LES should be intuitive and robust, emulating the way humans matches the SES to within some tolerance. interact with each other. For example, humans often com- Similarly, in [8], [9] and [10] a sketch containing approx- municate basic navigation tasks using approximate spatial imate landmarks and a path is drawn on a PDA by a human relationships to observable landmarks, without requiring a operator. At ‘crucial nodes’ along the sketched route, spatial precise map (“walk past the computers and take a left at the relations between the robot and surrounding objects define elevator”). This type of human-robot communication would Qualitative Landmark States (QLS’s) and associated robot be particularly useful when a true map is unavailable or the commands. As the robot navigates the true environment, environment is changing with time. For example, a robot it identifies and matches the observed QLS’s with those operating around an earthquake site may not be able to extracted from the sketched route, and executes the appro- navigate using a city map in global coordinates, and should priate commands. This approach can account for a certain instead plan its path with respect to observable landmarks degree of uncertainty and inconsistencies in sketching, but is such as cars, trees, and buildings. generally limited to straight-line paths, is sensitive to missing In this paper, a novel method is presented for controlling a landmarks, and is not able to recover if the robot strays too mobile robot using a qualitative map, such as one sketched by far from the desired route. a human. The sketch need not contain complete information In contrast to previous approaches, the method described about the environment, only information relevant to the in this paper does not require extraction and matching of navigation task. Additionally, the sketched map may not be local landmark templates. The proposed algorithm makes use quantitatively accurate, but should be qualitatively similar of probabilistic mapping strategies such as SLAM (Simulta- to the true environment (such that it could be understood neous Localization and Mapping [11]) to plan arbitrarily- and used by another human). For each waypoint along the shaped trajectories with respect to uncertain landmarks. 978-1-61284-385-8/11/$26.00 ©2011 IEEE 2580<p></td>
</tr>
<tr id="bib_Shah2011" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Shah2011,
  author = {Danelle C. Shah and Mark E. Campbell and Department of Mechanical Engineering and Cornell University and Ithaca and NY},
  title = {A Robust Qualitative Planner for Mobile Robot Navigation Using Human-Provided Maps},
  booktitle = {2011 IEEE International Conference on Robotics and Automation Shanghai International Conference Center May 9-13, 2011, Shanghai, China},
  publisher = {IEEE},
  year = {2011}
}
</pre></td>
</tr>
<tr id="Shayestegan2012" class="entry">
	<td>Shayestegan, M. and Marhaban, M.H.</td>
	<td>A Braitenberg Approach to Mobile Robot Navigation in Unknown Environments <p class="infolinks">[<a href="javascript:toggleInfo('Shayestegan2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Trends in Intelligent Robotics, Automation, and Manufacturing: First International Conference, IRAM 2012, Kuala Lumpur, Malaysia, November 28-30, 2012. Proceedings, pp. 75-93&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://dx.doi.org/10.1007/978-3-642-35197-6_9">DOI</a> <a href="http://dx.doi.org/10.1007/978-3-642-35197-6_9">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Shayestegan2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Shayestegan2012,
  author = {Shayestegan, Mohsen and Marhaban, Mohammad Hamiruce},
  title = {A Braitenberg Approach to Mobile Robot Navigation in Unknown Environments},
  booktitle = {Trends in Intelligent Robotics, Automation, and Manufacturing: First International Conference, IRAM 2012, Kuala Lumpur, Malaysia, November 28-30, 2012. Proceedings},
  publisher = {Springer Berlin Heidelberg},
  year = {2012},
  pages = {75--93},
  url = {http://dx.doi.org/10.1007/978-3-642-35197-6_9},
  doi = {http://dx.doi.org/10.1007/978-3-642-35197-6_9}
}
</pre></td>
</tr>
<tr id="Shepelev2015" class="entry">
	<td>Shepelev, D. and Ustyuzhanin, A.</td>
	<td>Towards Development of Reliable Mobile Robot Navigation System <p class="infolinks">[<a href="javascript:toggleInfo('Shepelev2015','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 2nd International Conference on Information Science and Control Engineering&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/icisce.2015.227">DOI</a> <a href="http://dx.doi.org/10.1109/ICISCE.2015.227">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Shepelev2015" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Shepelev2015,
  author = {Shepelev, Denis and Ustyuzhanin, Andrey},
  title = {Towards Development of Reliable Mobile Robot Navigation System},
  journal = {2015 2nd International Conference on Information Science and Control Engineering},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2015},
  url = {http://dx.doi.org/10.1109/ICISCE.2015.227},
  doi = {http://dx.doi.org/10.1109/icisce.2015.227}
}
</pre></td>
</tr>
<tr id="Shi2010" class="entry">
	<td>Shi, C., Wang, Y. and Yang, J.</td>
	<td>A local obstacle avoidance method for mobile robots in partially known environment <p class="infolinks">[<a href="javascript:toggleInfo('Shi2010','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Shi2010','bibtex')">BibTeX</a>]</p></td>
	<td>2010</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 58(5), pp. 425–434&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2010.02.005">DOI</a> <a href="http://dx.doi.org/10.1016/j.robot.2010.02.005">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Shi2010" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Local obstacle avoidance is a principle capability for mobile robots in unknown or partially known environment. A series of velocity space methods including the curvature velocity method (CVM), the lane curvature method (LCM) and the beam curvature method (BCM) formulate the local obstacle avoidance problem as one of constrained optimization in the velocity space by taking the physical constraints of the environment and the dynamics of the vehicle into account. We present a new local obstacle avoidance approach that combines the prediction model of collision with the improved BCM. Not only does this method inherit the quickness of BCM and the safety of LCM, but also the proposed prediction based BCM (PBCM) can be used to avoid moving obstacles in dynamic environments.</td>
</tr>
<tr id="bib_Shi2010" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Shi2010,
  author = {Shi, Chaoxia and Wang, Yanqing and Yang, Jingyu},
  title = {A local obstacle avoidance method for mobile robots in partially known environment},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier BV},
  year = {2010},
  volume = {58},
  number = {5},
  pages = {425–434},
  url = {http://dx.doi.org/10.1016/j.robot.2010.02.005},
  doi = {http://dx.doi.org/10.1016/j.robot.2010.02.005}
}
</pre></td>
</tr>
<tr id="Simmons:1995:PRN:1643031.1643040" class="entry">
	<td>Simmons, R. and Koenig, S.</td>
	<td>Probabilistic Robot Navigation in Partially Observable Environments <p class="infolinks">[<a href="javascript:toggleInfo('Simmons:1995:PRN:1643031.1643040','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Simmons:1995:PRN:1643031.1643040','review')">Review</a>] [<a href="javascript:toggleInfo('Simmons:1995:PRN:1643031.1643040','bibtex')">BibTeX</a>]</p></td>
	<td>1995</td>
	<td>Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2, pp. 1080-1087&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dl.acm.org/citation.cfm?id=1643031.1643040">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Simmons:1995:PRN:1643031.1643040" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Autonomous mobile robots need very reliable navigation capabilities in order to operate unattended for long periods of time. This paper reports on first results of a research program that uses par tially observable Markov models to robustly track a robots location in office environments and to direct its goal-oriented actions. The approach explicitly maintains a probability distribution over the possible locations of the robot taking into account various sources of uncertainly including approximate knowledge of the environment and actuator and sensor uncertainty. A novel feature of our approach is its integration of topological map information with approximate metric information. We demonstrate the robustness of this approach in controlling an actual indoor mobile robot navigating corridors.</td>
</tr>
<tr id="rev_Simmons:1995:PRN:1643031.1643040" class="review noshow">
	<td colspan="6"><b>Review</b>:   Probabilistic Robot Navigation in Partially Observable Environments Reid Simmons and Sven Koenig Carnegie Mellon University School of Computer Science Pittsburgh, PA 15213-3890 reids@cs.cmu.edu, skoenig@cs.cmu.edu Abstract cision process (POMDP) model is constructed from topolog- ical information about the connectivity of the environment, Autonomous mobile robots need very reliable nav- approximate distance information, plus sensor and actuator igation capabilities in order to operate unattended characteristics. The Markov model estimates the position of for long periods of time. This paper reports on the robot in the form of probability distributions. The proba- first results of a research program that uses par- bilities are updated when the robot reports that it has moved tially observable Markov models to robustly track or turned, and when it observes features such as walls and a robot’s location in office environments and to di- corridor junctions. To direct the robot’s behavior, a planner rect its goal-oriented actions. The approach ex- associates a directive (e.g., turn or stop) with every Markov plicitly maintains a probability distribution over the state. Whenever the probability distribution of the Markov possible locations of the robot, taking into account model is updated, the total probability mass for each directive various sources of uncertainty, including approxi- is calculated, and the robot executes the one with the largest mate knowledge of the environment, and actuator probability mass. and sensor uncertainty. A novel feature of our ap- Our approach has several features that make it well-suited proach is its integration of topological map infor- for the office navigation task. It explicitly accounts for uncer- mation with approximate metric information. We tainty in actuation, sensor data and their interpretation, and demonstrate the robustness of this approach in con- the robot’s position. It can utilize all available sensor in- trolling an actual indoor mobile robot navigating formation to track position, and is particularly amenable to corridors. adding new sources of sensor information. It seamlessly com- bines topological and metric map information, enabling the 1 Introduction robot to utilize as much, or as little, metric information as it has available. It is also very reactive – once the robot believes We are interested in the task of long-term autonomous nav- igation in an office environment (with corridors, fo it has strayed from the nominal (optimal) path, it will auto-yers, and matically execute corrective actions. On the other hand, it is rooms). While the state of the art in autonomous office nav- igation is fairly relatively immune to temporary uncertainty in position. Foradvanced, it is not generally good enough to permit robots to traverse corridors for long periods example, even if the robot does not know for certain whichof time without getting lost. Evidence for of two parallel corridors it is traversing, it does not stop andthis can be seen in re- cent AAAI-sponsored robot competitions [Konolige, 1994; replan, as long as the control directives associated with both Simmons, 1995], where the robots often got confused corridors are the same. In this way, it can continue makingas to progress towards its desired goal, while at the same time col- where they were, and had difficulty relocalizing once that oc- lecting sensor readings to help disambiguate its true location. curred. We contend that navigation can be made more reliable by An important aspect of this work is that it must run in real ha time on board an actual robot. Problems include not onlyving the robot explicitly represent spatial and sensor uncer- tainty. To this end, we have developed a navigation technique how to model the navigation problem as a POMDP, but also that how to deal with memory and time constraints. While stilluses Markov models to robustly track the robot’s posi- tion and direct its preliminary, our experimental results, both in simulation andcourse. A partially observable Markov de- on the actual robot, are encouraging. In particular, they indi-  This research was supported in part by NASA under contract cate that the approach produces very robust navigation, even NAGW-1175 and by the Wright Laboratory and ARPA under grant number F33615-93-1-1330. The when using estimates of the actual sensor and action mod-views and conclusions contained in this document are those of the authors and should not be interpreted els. While, to date, we have concentrated more on imple- as representing the official policies, either expressed or implied, of mentation and validation aspects of the approach, our work NASA, the Wright Laboratory, or the United States government. opens up new application areas for more theoretical results<p></td>
</tr>
<tr id="bib_Simmons:1995:PRN:1643031.1643040" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Simmons:1995:PRN:1643031.1643040,
  author = {Simmons, Reid and Koenig, Sven},
  title = {Probabilistic Robot Navigation in Partially Observable Environments},
  booktitle = {Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2},
  publisher = {Morgan Kaufmann Publishers Inc.},
  year = {1995},
  pages = {1080--1087},
  url = {http://dl.acm.org/citation.cfm?id=1643031.1643040}
}
</pre></td>
</tr>
<tr id="7514569" class="entry">
	<td>Singh, P., Tiwari, R. and Bhattacharya, M.</td>
	<td>Navigation in Multi Robot system using cooperative learning: A survey <p class="infolinks">[<a href="javascript:toggleInfo('7514569','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7514569','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT), pp. 145-150&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ICCTICT.2016.7514569">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7514569" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract: Multi-Robot system became an important research area in the Robotics and Artificial Intelligence. In the presence of obstacles, uncertainty and incomplete information Multi-Robot system is used to accomplish the task in more efficient way as compared to single robot system. Navigation of robots in its surrounding is essential to avoid unacceptable situation such as avoiding obstacles, trajectory planning. Cooperative behavior of multi-robots provides efficient way to avoid collision. It is a matter of concern that how a group of mobile robots should be controlled so that they can move in a cohesive way toward a single direction. For the problem of cooperation among robots, flocking strategy is a good solution. To learn cooperation among robots, various machine learning strategies have been developed. One of the machine learning techniques is called reinforcement learning. It is a very challenging issue in the area of robotics and artificial intelligence. Combining cooperative and learning strategy collision avoidance can be improved. Survey of multi-agent reinforcement learning and flocking control is presented in this paper.</td>
</tr>
<tr id="bib_7514569" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7514569,
  author = {P. Singh and R. Tiwari and M. Bhattacharya},
  title = {Navigation in Multi Robot system using cooperative learning: A survey},
  booktitle = {2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT)},
  year = {2016},
  pages = {145-150},
  doi = {http://dx.doi.org/10.1109/ICCTICT.2016.7514569}
}
</pre></td>
</tr>
<tr id="Sogo2001" class="entry">
	<td>Sogo, T., Ishiguro, H. and Ishida, T.</td>
	<td>Mobile robot navigation by a Distributed Vision System <p class="infolinks">[<a href="javascript:toggleInfo('Sogo2001','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Sogo2001','bibtex')">BibTeX</a>]</p></td>
	<td>2001</td>
	<td>New Generation Computing<br/>Vol. 19(2), pp. 121-137&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/BF03037250">DOI</a> <a href="http://dx.doi.org/10.1007/BF03037250">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Sogo2001" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper proposes aDistributed Vision System (DVS), which is an intelligent infrastructure for mobile robots consisting of manyvision agents (VAs) embedded in an environment. The system monitors the environment from various viewing points with the VAs, maintains the dynamic environment models, and provides various information to robots. Based on this concept, we have developed a prototype of the DVS which consists of sixteen vision agents and simultaneously navigates two robots in a model town.</td>
</tr>
<tr id="bib_Sogo2001" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Sogo2001,
  author = {Sogo, Takushi and Ishiguro, Hiroshi and Ishida, Toru},
  title = {Mobile robot navigation by a Distributed Vision System},
  journal = {New Generation Computing},
  year = {2001},
  volume = {19},
  number = {2},
  pages = {121--137},
  url = {http://dx.doi.org/10.1007/BF03037250},
  doi = {http://dx.doi.org/10.1007/BF03037250}
}
</pre></td>
</tr>
<tr id="Solanki2012" class="entry">
	<td>Solanki, D. and Khare, V.</td>
	<td>Optical Navigation System for Robotics Application <p class="infolinks">[<a href="javascript:toggleInfo('Solanki2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Solanki2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>2012 Third International Conference on Intelligent Systems Modelling and Simulation&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/isms.2012.40">DOI</a> <a href="http://dx.doi.org/10.1109/ISMS.2012.40">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Solanki2012" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract— Frequently, robots find themselves asking this question. Knowing your location?? And being able to navigate to other locations is extremely important for autonomous robots. The act of finding one's location against a map is known as localization. So how can a robot localize itself? The most common form of intelligent localization and navigation is to use a map, combined with sensor readings and some form of closed-loop motion feedback. But a robot needs to do so much more than just localizing itself. Often, we’d like our robots to be able to build their own maps, since map building by hand is tedious, boring, and error-prone. The field of robotics that studies localization and mapping is typically called SLAM (simultaneous localization and mapping) [1]. Robot cists around the globe have been working to find a solution to localization for more than 20 years; however, only in the past 4-5 years we have seen some promising results. In this work, we describe a first-of-a-kind, breakthrough technology for pose finding for localization that requires only one low-cost camera and a powerful ARM based micro-controller. Because of its low-cost and robust performance in realistic environments, this technology is particularly well-suited for use in consumer and commercial applications.</td>
</tr>
<tr id="bib_Solanki2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Solanki2012,
  author = {Solanki, Deepak and Khare, Vanchhit},
  title = {Optical Navigation System for Robotics Application},
  journal = {2012 Third International Conference on Intelligent Systems Modelling and Simulation},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2012},
  url = {http://dx.doi.org/10.1109/ISMS.2012.40},
  doi = {http://dx.doi.org/10.1109/isms.2012.40}
}
</pre></td>
</tr>
<tr id="10.1109/CSIE.2009.854" class="entry">
	<td>Sourabh Rungta, Anupam Shukla, Ritu Tiwari, R.R. Janghel and Rahul Kala</td>
	<td>Mobile Robot Navigation Control in Moving Obstacle Environment Using Genetic Algorithm, Artificial Neural Networks and A* Algorithm <p class="infolinks">[<a href="javascript:toggleInfo('10.1109/CSIE.2009.854','bibtex')">BibTeX</a>]</p></td>
	<td>2009</td>
	<td>2009 WRI World Congress on Computer Science and Information Engineering, CSIE<br/>Vol. 04(undefined), pp. 705-713&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1109/CSIE.2009.854">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_10.1109/CSIE.2009.854" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{10.1109/CSIE.2009.854,
  author = {Sourabh Rungta, and Anupam Shukla, and Ritu Tiwari, and R.R. Janghel, and Rahul Kala, },
  title = {Mobile Robot Navigation Control in Moving Obstacle Environment Using Genetic Algorithm, Artificial Neural Networks and A* Algorithm},
  journal = {2009 WRI World Congress on Computer Science and Information Engineering, CSIE},
  publisher = {IEEE Computer Society},
  year = {2009},
  volume = {04},
  number = {undefined},
  pages = {705-713},
  doi = {http://dx.doi.org/10.1109/CSIE.2009.854}
}
</pre></td>
</tr>
<tr id="7546355" class="entry">
	<td>Tan, P. and Cai, Z.</td>
	<td>Modelling and Planning of Mobile Robot Navigation Control in Unknown Environment <p class="infolinks">[<a href="javascript:toggleInfo('7546355','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('7546355','bibtex')">BibTeX</a>]</p></td>
	<td>2015</td>
	<td>2015 International Conference on Computational Intelligence and Communication Networks (CICN), pp. 1532-1536&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/CICN.2015.292">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_7546355" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The navigation system of mobile robot should have the capability of environment cognition, action decision, motion control, and state monitoring. This paper presents a design of mobile robot control architecture and a survey about the navigation control method. An environmental model of mobile robots is built with an improved Voronoi Diagram method. This method embodies the network structure of the environment-free area with fewer nodes, so the complexity of path planning is reduced largely. Hybrid navigation strategy composed of deliberative planning and local optimization in unknown environment is studied. An improved D algorithm for deliberative planning in complex situation is proposed for avoiding local minima trap through searching a path from leave point. The reverse D algorithm can decrease the calculation largely compared with the traditional D algorithm in unknown environment.</td>
</tr>
<tr id="bib_7546355" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{7546355,
  author = {P. Tan and Z. Cai},
  title = {Modelling and Planning of Mobile Robot Navigation Control in Unknown Environment},
  booktitle = {2015 International Conference on Computational Intelligence and Communication Networks (CICN)},
  year = {2015},
  pages = {1532-1536},
  doi = {http://dx.doi.org/10.1109/CICN.2015.292}
}
</pre></td>
</tr>
<tr id="THRUN200199" class="entry">
	<td>Thrun, S., Fox, D., Burgard, W. and Dellaert, F.</td>
	<td>Robust Monte Carlo localization for mobile robots <p class="infolinks">[<a href="javascript:toggleInfo('THRUN200199','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('THRUN200199','bibtex')">BibTeX</a>]</p></td>
	<td>2001</td>
	<td>Artificial Intelligence<br/>Vol. 128(1), pp. 99 - 141&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/S0004-3702(01)00069-8">DOI</a> <a href="http://www.sciencedirect.com/science/article/pii/S0004370201000698">URL</a>&nbsp;</td>
</tr>
<tr id="abs_THRUN200199" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Mobile robot localization is the problem of determining a robot's pose from sensor data. This article presents a family of probabilistic localization algorithms known as Monte Carlo Localization (MCL). MCL algorithms represent a robot's belief by a set of weighted hypotheses (samples), which approximate the posterior under a common Bayesian formulation of the localization problem. Building on the basic MCL algorithm, this article develops a more robust algorithm called Mixture-MCL, which integrates two complimentary ways of generating samples in the estimation. To apply this algorithm to mobile robots equipped with range finders, a kernel density tree is learned that permits fast sampling. Systematic empirical results illustrate the robustness and computational efficiency of the approach.</td>
</tr>
<tr id="bib_THRUN200199" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{THRUN200199,
  author = {Sebastian Thrun and Dieter Fox and Wolfram Burgard and Frank Dellaert},
  title = {Robust Monte Carlo localization for mobile robots},
  journal = {Artificial Intelligence},
  year = {2001},
  volume = {128},
  number = {1},
  pages = {99 - 141},
  url = {http://www.sciencedirect.com/science/article/pii/S0004370201000698},
  doi = {http://dx.doi.org/10.1016/S0004-3702(01)00069-8}
}
</pre></td>
</tr>
<tr id="Volume2016" class="entry">
	<td>Volume and Pages</td>
	<td>Procedia Computer Science <p class="infolinks">[<a href="javascript:toggleInfo('Volume2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Volume2016','review')">Review</a>] [<a href="javascript:toggleInfo('Volume2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Volume2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper presents an implementation of an evolutionary algorithm to control a robot with autonomous navigation in avoiding obstacles. The paper describes how the evolutionary system controls the sensors and motors in order to complete this task. A simulator was developed to test the algorithm and its conﬁgurations. The tests were performed in a simulated environment containing a set of barriers that were observed by means of a set of sensors. The solution obtained in the simulator was embedded in a real robot, which was tested in an arena containing obstacles. The robot was able to navigate and avoid the obstacles in this environment.</td>
</tr>
<tr id="rev_Volume2016" class="review noshow">
	<td colspan="6"><b>Review</b>: Procedia Computer Science Volume 80, 2016, Pages 2261–2265 ICCS 2016. The International Conference on Computational Science An Evolutionary Algorithm for Autonomous Robot Navigation Lucas da Silva Assis1, Anderson da Silva Soares1, Clarimar Jose´ Coelho2, and Jeﬀrey Van Baalen3 1 Instituto de Informa´tica, Universidade Federal de Goia´s, Brasil anderson@inf.ufg.br 2 Departamento de Cieˆncia da Computac¸a˜o, Pontif´ıcia Universidade Cato´lica de Goia´s, Brasil 3 Computer Science Departament, University of Wyoming, U. S. A Abstract This paper presents an implementation of an evolutionary algorithm to control a robot with autonomous navigation in avoiding obstacles. The paper describes how the evolutionary system controls the sensors and motors in order to complete this task. A simulator was developed to test the algorithm and its conﬁgurations. The tests were performed in a simulated environment containing a set of barriers that were observed by means of a set of sensors. The solution obtained in the simulator was embedded in a real robot, which was tested in an arena containing obstacles. The robot was able to navigate and avoid the obstacles in this environment. Keywords: Evolutionary Algorithm, Autonomous Navigation, Artiﬁcial Intelligence, Simulation 1 Introduction The navigation problem in mobile robotics is the problem of making navigation decisions for one or more autonomous mobile robots, placed in an arbitrary environment, to accomplish certain predeﬁned tasks[5]. There are many aspects of this problem: environment settings, application peculiarities, robot characteristics, and task priorities. Many techniques such as fuzzy systems and evolutionary algorithms have been used in an attempt to solve this problem. Evolutionary Algorithms (EAs) are a computing strategy that solves diﬃcult optimization problems. EAs are inspired by biology, more speciﬁcally in the Darwinian Theory of Evolution. They abstract and mimic some of the traits of natural evolution to produce functional adaptive processes [1]. Genetic algorithms are intrinsically parallel because the search enables discovery of multiple solutions, and can control a population of robots that work simultaneously. This paper describes a genetic algorithm, where the population exists as actual robots that exchange genetic information in order to adapt to solve a particular problem. The goal is to train a robot to interact with an unknown environment. Our main contribution is a novel chromosome encoding for mobile robotics and also a simulator for this task. As a case study, Selection and peer-review under responsibility of the Scientiﬁc Programme Committee of ICCS 2016 2261 ©c The Authors. Published by Elsevier B.V. doi: 10.1016/j.procs.2016.05.404 <p></td>
</tr>
<tr id="bib_Volume2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Volume2016,
  author = {Volume and Pages},
  title = {Procedia Computer Science},
  year = {2016}
}
</pre></td>
</tr>
<tr id="6957415" class="entry">
	<td>Wang, Y.T., Shen, C.A. and Yang, J.S.</td>
	<td>Calibrated kinect sensors for robot simultaneous localization and mapping <p class="infolinks">[<a href="javascript:toggleInfo('6957415','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6957415','review')">Review</a>] [<a href="javascript:toggleInfo('6957415','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>2014 19th International Conference on Methods and Models in Automation and Robotics (MMAR), pp. 560-565&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/MMAR.2014.6957415">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6957415" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract:<br>In this paper, we present an algorithm for robot simultaneous localization and mapping (SLAM) using a Kinect sensor, which is a red-green-blue and depth (RGB-D) sensor. The distortions of the RGB and depth images are calibrated before the sensor is used as a measuring device for robot navigation. The calibration procedure includes the correction of the RGB image as well as alignment of the RGB lens with the depth lens. In SLAM tasks, the speeded-up robust features (SURFs) are detected from the RGB image and used as landmarks for building the environment map. The depth image further provides the stereo information to initialize the three-dimensional coordinates of each landmark. Meanwhile, the robot estimates its own state and landmark locations using the extended Kalman filter (EKF). Two SLAM experiments have been carried out in this study and the results showed that the Kinect sensors could provide reliable measurement information for mobile robots navigating in unknown environments.</td>
</tr>
<tr id="rev_6957415" class="review noshow">
	<td colspan="6"><b>Review</b>: Calibrated Kinect Sensors for Robot Simultaneous Localization and Mapping* Yin-Tien Wang, Member, IEEE, Chin-An Shen, and Jr-Syu Yang Department of Mechanical and Electro-Mechanical Engineering Tamkang University Tamsui, New Taipei City, TAIWAN 25137 ytwang@mail; 499350238@s99; 096034@mail.tku.edu.tw Abstract—In this paper, we present an algorithm for robot recording the laser speckle in a different position and distance, simultaneous localization and mapping (SLAM) using a Kinect followed by comparative and statistical analyses [2]. Microsoft sensor, which is a red-green-blue and depth (RGB-D) sensor. The Kinect sensor has several advantages, including low price, distortions of the RGB and depth images are calibrated before multiple sensing capability, and the availability of a free the sensor is used as a measuring device for robot navigation. The software development toolkit. Such sensor is suitable for 3D calibration procedure includes the correction of the RGB image modeling [3] and robot navigation in the environment because as well as alignment of the RGB lens with the depth lens. In of its functions and low price. This study uses Kinect to capture SLAM tasks, the speeded-up robust features (SURFs) are detected from the RGB image and used as landmarks for color and depth images as environmental information for building the environment map. The depth image further provides mobile robot navigation. the stereo information to initialize the three-dimensional The distortions of RGB and depth images need to be coordinates of each landmark. Meanwhile, the robot estimates its calibrated before the Kinect is applied as a measuring device. own state and landmark locations using the extended Kalman The distortion of the Kinect’s RGB image depends on the lens filter (EKF). Two SLAM experiments have been carried out in structure of the camera. In the literature, many procedures have this study and the results showed that the Kinect sensors could been developed to calibrate the RGB image by determining the provide reliable measurement information for mobile robots camera intrinsic parameters [4-6]. These procedures moved the navigating in unknown environments. camera or objects arbitrarily and obtained the conversion Keywords—Sensor calibration; Simultaneous localization and relationship of different images to determine the camera mapping (SLAM); Speeded-up robust features (SURF) intrinsic parameters and external transformation parameters. Zhang carried out a complete derivation of the conversion relationship between the images and objects, and then used the I. INTRODUCTION Levenberg-Marquardt optimization method to obtain accurate When a robot is navigating in an unknown environment, it parameters [4]. Heikkila and Silven established the image relies on sensors to recognize the outside world and then correction model to obtain the corresponding parameters [5]. A estimate the state of the robot itself to achieve the task of well-known Matlab toolbox based on these calibration autonomous navigation. Commonly used sensors include the algorithms has been released [6]. In this study, we use these laser range finder (LRF) and vision sensor. LRF can offer high- algorithms and toolbox to deal with the calibration of the RGB precision measurement data, but it is too expensive to be images. On the other hand, the distortion of the Kinect’s depth extensively used. The vision sensor has a relatively wide range image is due to the misalignment of the RGB sensor against the of cost, from cheap low-end to expensive high-order products, depth sensor. However, there is no popular method of aligning being generally applied in a robot's sensing devices. However, these two sensors’ lenses [7]. In this study, we propose a novel vision sensors capture only two-dimensional images that have procedure to transfer and align the depth image with the RGB no depth information of environmental objects. One must image. The transformation of the sensor location is modeled spend a lot of calculation cost to recover the depth information using a mathematical interpolation model. We choose the for visual measurement. origin of the RGB camera as the reference frame and then transform the depth image to align with the RGB camera frame. Recently, Microsoft has released an RGB-D sensor called Kinect, which has an RGB image sensor and a depth sensor [1]. The image features detected from Kinect RGB images can The RGB sensor captures color images of the environment. be used to represent the landmarks in the environment and The depth sensor uses an infrared transmitter and a CMOS build an environmental map for robot navigation. A detection camcorder to detect the depth of the corresponding objects in method based on the scale-invariant feature was developed by RGB images. When infrared light reaches rough objects or Lindeberg [8]. He established image Hessian matrices, whose penetrates through frosted glass, the reflection spots or random elements are the convolution of the Gaussian second-order scatterings, called laser speckle, are measured using the CMOS derivative with the image. An image feature is selected by camcorder. The depth information is then generated by examining the determinant of the Hessian matrix based on the *Research supported by the Ministry of Science and Technology of Taiwan under grant nos. NSC102-2815-C-032-024-E, MOST103-2221-E- 032-041 and MOST103-2632-E-032-001-MY3. 978-1-4799-5081-2/14/$31.00 ©2014 IEEE 560<p></td>
</tr>
<tr id="bib_6957415" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6957415,
  author = {Y. T. Wang and C. A. Shen and J. S. Yang},
  title = {Calibrated kinect sensors for robot simultaneous localization and mapping},
  booktitle = {2014 19th International Conference on Methods and Models in Automation and Robotics (MMAR)},
  year = {2014},
  pages = {560-565},
  doi = {http://dx.doi.org/10.1109/MMAR.2014.6957415}
}
</pre></td>
</tr>
<tr id="407627" class="entry">
	<td>Wienkop, U., Lawitzky, G. and Feiten, W.</td>
	<td>Intelligent low-cost mobility <p class="infolinks">[<a href="javascript:toggleInfo('407627','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('407627','review')">Review</a>] [<a href="javascript:toggleInfo('407627','bibtex')">BibTeX</a>]</p></td>
	<td>1994</td>
	<td><br/>Vol. 3Intelligent Robots and Systems '94. 'Advanced Robotic Systems and the Real World', IROS '94. Proceedings of the IEEE/RSJ/GI International Conference on, pp. 1708-1715 vol.3&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/IROS.1994.407627">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_407627" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: ABSTRACT: Autonomous low-cost mobility of robots has been a challeng- ing problem for quite a long time. In this paper the typical prob- lems of sonar based autonomous navigation and our solutions to overcome them will be discussed. We have created adequate, robust modules for sonar data fusion and safe steering which significantly improve known methods. There are furthermore robot control behaviors which offer specific competence to solve high-level tasks. These behaviors build a hierarchical ar- chitecture but have the ability to assess their respective task and autonomously suggest a different, more competent behavior to continue. Thus, the behaviors work together as distributed competencies. The concept described here is being evaluated system on our experimental robot ROAMER. The available modules already operate robustly in cluttered office environ- ments.</td>
</tr>
<tr id="rev_407627" class="review noshow">
	<td colspan="6"><b>Review</b>: Intelligent Low-cost Mobility Uwe Wienkop, Gisbert Lawitzky, Wendelin Feiten Siemens Corporate Research and Development, 81 730 Munich, Germany ABSTRACT: Autonomous low-cost mobility of robots has been a challeng- Global Control Layer ing problem for quite a long time. In this paper the typical prob- lems of sonar based autonomous navigation and our solutions I Intelligent Behavior Layer to overcome them will be discussed. We have created adequate, I robust modules for sonar data fusion and safe steering which I Communication Layer significantly improve known methods. There are furthermore I robot control behaviors which offer specific competence to solve high-level tasks. These behaviors build a hierarchical ar- Local Behavior Layer chitecture but have the ability to assess their respective task and autonomously suggest a different, more competent behavior to Sensor and Safe Steering Layer continue. Thus, the behaviors work together as distributed competencies. The concept described here is being evaluated Hardware Layer system on our experimental robot ROAMER. The available modules already operate robustly in cluttered office environ- Figure 1: Coarse Architecture of the ROAMER robot ments. 1 Introduction situation, i.e. to detect in what kind of environment and under In this paper we will focus on intelligent, autonomous mobility which task the robot is currently operating and to switch auton- of robots which operate in cluttered, unprepared, a priori fully omously between different behaviors. Therefore, dedicated be- unknown indoor environments. The robot has to perform ac- haviors are integrated in a hierarchically structured architecture tions like mail delivery, delivery of items from one desk to an- (Fig. 1). It makes use of deliberative and reactive planners, de- other one, security patrols, etc. The target price of our robot tectors which classify the competence of behaviors for doing system will be comparable to that of a well equipped PC. certain things, and an overall global scheduler. Evidently, these low-cost requirements imply challenging re- The detectors together with the (local) behaviors will be de- strictions in terms of available sensor equipment and process- scribed in section 3. The planners and the intelligent versions ing power. We make use of sonar sensors and a PC to do all the computation. However, relying on sonar sensors implies prob- lems like specular reflections, cross talk, bad angular resolu- tion, etc. The tricycle-like kinematic requires special naviga- tion mechanisms which are able to deal with nonholonomic constraints. We have overcome these problems by using im- proved sonar data fusion mechanisms and sophisticated real- time obstacle avoiding methods. They will be described in sec- tion 2. For performing tasks like delivery of items from one desk to another we also have to care about local behaviors like move from one position to another one, follow a wall, or follow a hallway. It is, however, important to keep an eye on the execu- tion speed of those routines. For motion in cluttered rooms a fair robot speed (-30 c d s ) is adequate. Hallways allow higher speeds but require a more specialized steering method. Moving in unprepared environments which may dynamically change requires that the robot software is able to adapt to the Figure 2: ROAMER Robot 1708</td>
</tr>
<tr id="bib_407627" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{407627,
  author = {U. Wienkop and G. Lawitzky and W. Feiten},
  title = {Intelligent low-cost mobility},
  booktitle = {Intelligent Robots and Systems '94. 'Advanced Robotic Systems and the Real World', IROS '94. Proceedings of the IEEE/RSJ/GI International Conference on},
  year = {1994},
  volume = {3},
  pages = {1708-1715 vol.3},
  doi = {http://dx.doi.org/10.1109/IROS.1994.407627}
}
</pre></td>
</tr>
<tr id="Xia2016" class="entry">
	<td>Xia, C. and El Kamel, A.</td>
	<td>Neural inverse reinforcement learning in autonomous navigation <p class="infolinks">[<a href="javascript:toggleInfo('Xia2016','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Xia2016','bibtex')">BibTeX</a>]</p></td>
	<td>2016</td>
	<td>Robotics and Autonomous Systems<br/>Vol. 84, pp. 1–14&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.robot.2016.06.003">DOI</a> <a href="http://dx.doi.org/10.1016/j.robot.2016.06.003">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Xia2016" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Designing intelligent and robust autonomous navigation systems remains a great challenge in mobile robotics. Inverse reinforcement learning (IRL) offers an efficient learning technique from expert demonstrations to teach robots how to perform specific tasks without manually specifying the reward function. Most of existing IRL algorithms assume the expert policy to be optimal and deterministic, and are applied to experiments with relatively small-size state spaces. However, in autonomous navigation tasks, the state spaces are frequently large and demonstrations can hardly visit all the states. Meanwhile the expert policy may be non-optimal and stochastic. In this paper, we focus on IRL with large-scale and high-dimensional state spaces by introducing the neural network to generalize the expert’s behaviors to unvisited regions of the state space and an explicit policy representation is easily expressed by neural network, even for the stochastic expert policy. An efficient and convenient algorithm, Neural Inverse Reinforcement Learning (NIRL), is proposed. Experimental results on simulated autonomous navigation tasks show that a mobile robot using our approach can successfully navigate to the target position without colliding with unpredicted obstacles, largely reduce the learning time, and has a good generalization performance on undemonstrated states. Hence prove the robot intelligence of autonomous navigation transplanted from limited demonstrations to completely unknown tasks.</td>
</tr>
<tr id="bib_Xia2016" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Xia2016,
  author = {Xia, Chen and El Kamel, Abdelkader},
  title = {Neural inverse reinforcement learning in autonomous navigation},
  journal = {Robotics and Autonomous Systems},
  publisher = {Elsevier BV},
  year = {2016},
  volume = {84},
  pages = {1–14},
  url = {http://dx.doi.org/10.1016/j.robot.2016.06.003},
  doi = {http://dx.doi.org/10.1016/j.robot.2016.06.003}
}
</pre></td>
</tr>
<tr id="Yayan2014a" class="entry">
	<td>Yayan, U., Yucel, H. and Yazıcı, A.</td>
	<td>A Low Cost Ultrasonic Based Positioning System for the Indoor Navigation of Mobile Robots <p class="infolinks">[<a href="javascript:toggleInfo('Yayan2014a','bibtex')">BibTeX</a>]</p></td>
	<td>2014</td>
	<td>Journal of Intelligent &amp; Robotic Systems<br/>Vol. 78(3-4), pp. 541–552&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1007/s10846-014-0060-7">DOI</a> <a href="http://dx.doi.org/10.1007/s10846-014-0060-7">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Yayan2014a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Yayan2014a,
  author = {Yayan, Ugur and Yucel, Hikmet and Yazıcı, Ahmet},
  title = {A Low Cost Ultrasonic Based Positioning System for the Indoor Navigation of Mobile Robots},
  journal = {Journal of Intelligent &amp; Robotic Systems},
  publisher = {Springer Nature},
  year = {2014},
  volume = {78},
  number = {3-4},
  pages = {541–552},
  url = {http://dx.doi.org/10.1007/s10846-014-0060-7},
  doi = {http://dx.doi.org/10.1007/s10846-014-0060-7}
}
</pre></td>
</tr>
<tr id="6739458" class="entry">
	<td>Zhiwei, S., Yiyan, W., Changjiu, Z. and Yi, Z.</td>
	<td>A new sensor fusion framework to deal with false detections for low-cost service robot localization <p class="infolinks">[<a href="javascript:toggleInfo('6739458','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('6739458','review')">Review</a>] [<a href="javascript:toggleInfo('6739458','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>2013 IEEE International Conference on Robotics and Biomimetics (ROBIO), pp. 197-202&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://dx.doi.org/10.1109/ROBIO.2013.6739458">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_6739458" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract:<br>The popularization of service robots requires that robots are not expensive and can work very well in human daily living environment. Due to lighting condition and/or cluttered background, there are false detections occasionally for landmark-based robot localization with low-cost color camera or infrared sensors. However, traditional frequently used methods, such as Extended Kalman Filter (EKF) and Particle Filter (PF), can't cope with the problem of false detection. A novel sensor fusion framework is proposed in this paper for robot localization, which is capable of dealing with the problem of false detection. It has been tested in a real receptionist robot equipped with an infrared camera and wheel encoders. Experiments illustrate that the proposed method has a better performance than EKF and PF when false detections occur, while maintaining almost same performance during other times.</td>
</tr>
<tr id="rev_6739458" class="review noshow">
	<td colspan="6"><b>Review</b>: Proceeding of the IEEE International Conference on Robotics and Biomimetics (ROBIO) Shenzhen, China, December 2013 A New Sensor Fusion Framework to Deal with False Detections for Low-cost Service Robot Localization Song Zhiwei, Member, IEEE, Wang Yiyan, Zhou Changjiu, and Zhou Yi Abstract— The popularization of service robots requires that particles and updates their weights when an observation robots are not expensive and can work very well in human comes. The output is the weighted average of all particles daily living environment. Due to lighting condition and/or including those resampled from false observation. It could cluttered background, there are false detections occasionally for landmark-based robot localization with low-cost color cam- happen that the false observation dominates the particles era or infrared sensors. However, traditional frequently used when the robot moves around the false detected landmark methods, such as Extended Kalman Filter (EKF) and Particle for a while. Apart from these methods, it is another story Filter (PF), can’t cope with the problem of false detection. A that expensive stereo vision system is used to reduce the novel sensor fusion framework is proposed in this paper for false detection [9], [10]. It is beyond our consideration on robot localization, which is capable of dealing with the problem of false detection. It has been tested in a real receptionist low-cost robot solution. robot equipped with an infrared camera and wheel encoders. In this paper, a novel sensor fusion framework is proposed Experiments illustrate that the proposed method has a better for robot localization. This method has the capability to performance than EKF and PF when false detections occur, deal with the problem of false detection, and it is also while maintaining almost same performance during other times. comparable to EKF and PF for common situations. Two types of data are fused together in our algorithm, which are I. INTRODUCTION global data for absolute position and local data for relative Mobile intelligent service robot has been a hot research changes. Each type of data can be from one or more sensors. topic in decade years, such as robots delivering medical This algorithm has been tested on a real receptionist robot materials in hospital [1], shopping assistant robots in market equipped with an infrared camera for global position data and [2], and personal service robots for the elderly and disabled at wheel encoders for local changes data. Experiments illustrate home [3]. An accurate localization, figuring out its own po- that our method has a better performance than EKF and PF sition and orientation precisely in the environment, is a basic when false detections occur, while maintaining almost same premise that the robot is to be intelligent or autonomous. At performance during other times. the same time, the popularization of service robots requires The remainder of this paper is organized as follows. First, that they are not expensive and can work very well in the background of the problem of false detection is described human daily living environment. Thus, there is a dilemma in section II with discussion of why traditional methods between precision and cost. Generally, the cheaper sensor, don’t work. Next, section III presents our new sensor fusion the less accurate. For example, landmark-based localization framework and discusses the different situations in real appli- with low-cost color camera or infrared sensor is the cheaper cation. Then, our experiments and the comparison with other solution than RFID-based [4] and laser-based [5] localiza- methods are illustrated in section IV. Finally, conclusion and tion, however, there are false detections occasionally due future work are listed in section V. to lighting condition and/or cluttered background for color camera or infrared sensors. II. BACKGROUND &amp; TRADITIONAL METHODS Traditional frequently used methods for robot localization Our research focus on developing a low-cost mobile ser- are Extended Kalman Filter (EKF), Particle Filter (PF), and vice robot works with people in human living environment. their extensions [6], [7], [8]. However, these methods can’t In term of low-cost, we choose inexpensive sensors for robot cope with the problem of false detection. EKF supposes localization, such as color camera and infrared camera, rather that the noise model follows the Gaussian distribution. This than expensive laser scanner or RFID device. Contrary to in- assumption may work when there is no false detection. door environment features based localization [11], landmark- Definitely, the error couldn’t be a Gaussian noise when a based localization is more accurate and practical [12], [13]. landmark is considered as another one. Particle filter is a kind The landmarks can be deployed on the ceiling such that no of sequential Monte Carlo method, which samples/resamples one could notice them and people’s living environment would not be affected. The only issue of this solution is that the This work is supported by Translational and Innovation Fund under grant accurate detection of landmarks is subject to the lighting MOE2011-TIF-1-G-050 from Ministry of Education, Singapore. Song Z.W., Wang Y.Y., and Zhou C.J. are with the Advanced Robotics condition, which could be changed by weather or a specific and Intelligent Control Centre, Singapore Polytechnic, 500 Dover Road, angle of the sight. Singapore 139651 (e-mail: songzw,wangyiyan,zhoucj@sp.edu.sg). Previous work assumes that the lighting condition could be Zhou Y. is with the Engineering Product Development, Singapore Univer- sity of Technology and Design, 20 Dover Drive, Singapore 138682 (e-mail: kept at the same level during robot working after calibration zhou yi@sutd.edu.sg) [12], [13]. It might work in a small place but can not work 978-1-4799-2744-9/13/$31.00 ©2013 IEEE 197<p></td>
</tr>
<tr id="bib_6739458" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{6739458,
  author = {S. Zhiwei and W. Yiyan and Z. Changjiu and Z. Yi},
  title = {A new sensor fusion framework to deal with false detections for low-cost service robot localization},
  booktitle = {2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  year = {2013},
  pages = {197-202},
  doi = {http://dx.doi.org/10.1109/ROBIO.2013.6739458}
}
</pre></td>
</tr>
<tr id="Zhu2013" class="entry">
	<td>Zhu, Y., Zhang, T., Song, J. and Li, X.</td>
	<td>A hybrid navigation strategy for multiple mobile robots <p class="infolinks">[<a href="javascript:toggleInfo('Zhu2013','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Zhu2013','bibtex')">BibTeX</a>]</p></td>
	<td>2013</td>
	<td>Robotics and Computer-Integrated Manufacturing<br/>Vol. 29(4), pp. 129–141&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.rcim.2012.11.007">DOI</a> <a href="http://dx.doi.org/10.1016/j.rcim.2012.11.007">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Zhu2013" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract A hybrid navigation strategy is proposed in this paper for solving the navigation problem of multiple mobile robots. The proposed strategy integrates three algorithms that represent three different types of existing methods in a layered system. The bottom-up architecture of this system is the main contribution of this paper. This architecture pursues reliable low-level layers that can independently work in as much cases as possible, and the high-level layer is used only when it is necessary for guaranteeing convergence in complex situations. The simulation results show that the proposed strategy has well combined the algorithms of different types from the perspective of pursuing reactivity in the premise of ensuring convergence. Compared with the traditional top-down hybrid architecture, the bottom-up architecture proposed in this paper is more suitable for multi-robot navigation since it can better utilize the advantages of different algorithms to deal with different situations. The experiments on real robots have further verified the applicability of the proposed strategy.</td>
</tr>
<tr id="bib_Zhu2013" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Zhu2013,
  author = {Zhu, Yi and Zhang, Tao and Song, Jingyan and Li, Xiaqin},
  title = {A hybrid navigation strategy for multiple mobile robots},
  journal = {Robotics and Computer-Integrated Manufacturing},
  publisher = {Elsevier BV},
  year = {2013},
  volume = {29},
  number = {4},
  pages = {129–141},
  url = {http://dx.doi.org/10.1016/j.rcim.2012.11.007},
  doi = {http://dx.doi.org/10.1016/j.rcim.2012.11.007}
}
</pre></td>
</tr>
<tr id="Zhu2012" class="entry">
	<td>Zhu, Y., Zhang, T., Song, J. and Li, X.</td>
	<td>A new hybrid navigation algorithm for mobile robots in environments with incomplete knowledge <p class="infolinks">[<a href="javascript:toggleInfo('Zhu2012','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Zhu2012','bibtex')">BibTeX</a>]</p></td>
	<td>2012</td>
	<td>Knowledge-Based Systems<br/>Vol. 27, pp. 302–313&nbsp;</td>
	<td>article</td>
	<td><a href="http://dx.doi.org/10.1016/j.knosys.2011.11.009">DOI</a> <a href="http://dx.doi.org/10.1016/j.knosys.2011.11.009">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Zhu2012" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract Focusing on the navigation problem of mobile robots in environments with incomplete knowledge, a new hybrid navigation algorithm is proposed. The novel system architecture in the proposed algorithm is the main contribution of this paper. Unlike most existing hybrid navigation systems whose deliberative layers usually play the dominant role while the reactive layers are only simple executors, a more independent reactive layer that can guarantee convergence without the assistance of a deliberative layer is pursued in the proposed architecture, which brings two benefits. First, the burden of the deliberative layer is released, which is beneficial to guaranteeing real-time property and decreasing resource requirement. Second, some possible layer conflicts in the traditional architecture can be resolved, which improves the system stability. The convergence of the new algorithm has been proved. The simulation results show that compared with three traditional algorithms based on different architectures, the new hybrid navigation algorithm proposed in this paper performs more reliable in terms of escaping from traps, resolving conflicts between layers and decreasing the computational time for avoiding time out of the control cycle. The experiments on a real robot further verify the validity and applicability of the new algorithm.</td>
</tr>
<tr id="bib_Zhu2012" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Zhu2012,
  author = {Zhu, Yi and Zhang, Tao and Song, Jingyan and Li, Xiaqin},
  title = {A new hybrid navigation algorithm for mobile robots in environments with incomplete knowledge},
  journal = {Knowledge-Based Systems},
  publisher = {Elsevier BV},
  year = {2012},
  volume = {27},
  pages = {302–313},
  url = {http://dx.doi.org/10.1016/j.knosys.2011.11.009},
  doi = {http://dx.doi.org/10.1016/j.knosys.2011.11.009}
}
</pre></td>
</tr>
<tr id="Zou2006" class="entry">
	<td>Zou, A.-M., Hou, Z.-G., Fu, S.-Y. and Tan, M.</td>
	<td>Neural Networks for Mobile Robot Navigation: A Survey <p class="infolinks">[<a href="javascript:toggleInfo('Zou2006','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Zou2006','bibtex')">BibTeX</a>]</p></td>
	<td>2006</td>
	<td>Advances in Neural Networks - ISNN 2006: Third International Symposium on Neural Networks, Chengdu, China, May 28 - June 1, 2006, Proceedings, Part II, pp. 1218-1226&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://dx.doi.org/10.1007/11760023_177">DOI</a> <a href="http://dx.doi.org/10.1007/11760023_177">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Zou2006" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. Nowadays, mobile robots have attracted more and more at- tention from researchers due to their extensive applications. Mobile robots need to have the capabilities of autonomy and intelligence, and they pose a challenge to researchers, which is to design algorithms that allow the robots to function autonomously in unstructured, dynamic, partially observable, and uncertain environments [1]. Navigation is the key to the relative technologies of mobile robots and neural networks are widely used in the field of mobile robot navigation due to their prop- erties such as nonlinear mapping, ability to learn from examples, good generalization performance, massively parallel processing, and capability to approximate an arbitrary function given sufficient number of neurons. This paper surveys the developments in the last few years of the neural networks with applications to mobile robot navigation.</td>
</tr>
<tr id="bib_Zou2006" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Zou2006,
  author = {Zou, An-Min and Hou, Zeng-Guang and Fu, Si-Yao and Tan, Min},
  title = {Neural Networks for Mobile Robot Navigation: A Survey},
  booktitle = {Advances in Neural Networks - ISNN 2006: Third International Symposium on Neural Networks, Chengdu, China, May 28 - June 1, 2006, Proceedings, Part II},
  publisher = {Springer Berlin Heidelberg},
  year = {2006},
  pages = {1218--1226},
  url = {http://dx.doi.org/10.1007/11760023_177},
  doi = {http://dx.doi.org/10.1007/11760023_177}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 22/11/2016.</small>
</footer>
<!-- file generated by JabRef -->
</body>
</html>